// -*- Doc -*-
// vim: set syntax=asciidoc:

//
// Copyright (c) 2005-2011 Gemini Mobile Technologies, Inc.  All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

= Hibari Application Developer's Guide *DRAFT - IN PROGRESS*
:Date: 2011/01/30
:Revision: 0.1.6
:Copyright: Copyright (C) 2006-2011 Gemini Mobile Technologies, Inc.  All rights reserved.

<<<
== Introduction
_Under Construction_

// - _Dave S. to write, drawing from various materials._
// - _Will solicit info and review from Dev and Marketing as needed._

=== Why NoSQL?
_to be added_

=== Why Hibari?
_to be added_

=== How Hibari Works

==== Data Model
_to be added_

==== Partitioning Across Chains
_to be added_

==== Replication Within Chains
_to be added_

==== RAM and Disk Storage
_to be added_

==== Admin Server
_to be added_


== Getting Started
_Under Construction_

// - _KK Dev to provide initial content._
// - _Dave S. to review, edit, and solicit additional info as needed._

=== Requirements

==== System Requirements
_to be added_

==== Required Software

- OpenSSL - http://www.openssl.org/
  * _required for Erlang's crypto module_

=== Downloading Hibari

A Hibari pre-built release has 2 files:

- a tarball package "hibari-X.Y.Z-DIST-ARCH-WORDSIZE.tgz"
- a md5sum file "hibari-X.Y.Z-DIST-ARCH-WORDSIZE-md5sum.txt"

_X.Y.Z_ is the release version, _DIST_ is the release distribution,
_ARCH_ is the release architecture, and _WORDSIZE_ is the release
wordsize.

Hibari pre-built releases are not available for download yet.  See
<<HibariBuildingSource>> for instructions to build Hibari from source
for your target platform.

=== Installing Hibari

==== Single Node

. Create directory for running Hibari
+
------
$ mkdir running-directory-name
------
+
. Untar release files
+
------
$ tar -C running-directory-name -xvf hibari-X.Y.Z-DIST-ARCH-WORDSIZE.tgz
------

==== Multi Node

Cluster is a simple tool for installing, configuring, and
bootstrapping a cluster of Hibari nodes. The cluster tool requires one
installer node and one or more target nodes for the Hibari cluster.
The installer node can be a different node or can be one of the target
nodes.  The cluster tool requires an installing user (that is you) and
it must be different than the user for Hibari on the target nodes.

NOTE: This tool should meet the needs of most users.  However, this
tool's "target node" recipe is currently Linux-centric (e.g. useradd,
userdel, ...).  Patches and contributions for other OS and platforms
are welcome.  For non-Linux deployments, the cluster tool is rather
simple so installation can be done manually by following the tool's
recipe.

Your Hibari installer node must have following tools/environments
ready.  For further information and help for related tools, please
refer to the following links:

- Bash - http://www.gnu.org/software/bash/
- Expect - http://www.nist.gov/el/msid/expect.cfm
- Git - http://git-scm.com/
  * *Git 1.5.4 or newer*
  * _required for GitHub_
- Perl - http://www.perl.org/
- SSH (client) - http://www.openssh.com/

Your Hibari target nodes must have following tools/environments ready.
For further information and help for related tools, please refer to
the following links:

- SSH (server) - http://www.openssh.com/

So far, there are no "known" version requirements for Bash, Expect,
Perl, and SSH.

===== Prerequisites and Assumptions

A. 1 installer node
   * Bash, Expect, Git, Perl, Python, and SSH (client) is installed
     on installer node
   * Your login account ($USER) exists on installer node with ssh
     private/public keys and ssh agent setup to enable password-less
     ssh login
   * /etc/hosts file on installer node contains entries for all
     target nodes
B. 1 or more cluster target nodes (e.g. dev1, dev2, dev3)
   * Your login account ($USER) exists on target nodes
   * Your login account ($USER) is enabled with password-less sudo
     access on target nodes
   * Your login account ($USER) is accessible with password-less ssh
     login on target nodes
   * SSH (server) is installed on target nodes
   * /etc/hosts file on target nodes contains entries for all target
     nodes
   * Network A and Network B is setup and active (see note below)
C. Cluster configuration file. This will show up as hibari.config in
   latter explanation.  You have to manually create it on installer
   node and later provide it's location as an input to the cluster
   tool.
   * Hibari Admin nodes
   * Hibari Brick nodes
   * Hibari Bricks per Chain value (i.e. replication factor)
   * All Hibari nodes (union of Admin and Brick nodes)
   * All Hibari nodes Network A and Network B ip addresses plus
     Network broadcast addresses and Network A tiebreaker address
   * All Heartbeat UDP ports
+
Example configuration file (hibari.config) for a three node cluster
that uses the same physical network for Network A and Network B (see
note below):
+
------
ADMIN_NODES=(dev1 dev2 dev3)
BRICK_NODES=(dev1 dev2 dev3)
BRICKS_PER_CHAIN=2

ALL_NODES=(dev1 dev2 dev3)
ALL_NETA_ADDRS=("10.181.165.230" "10.181.165.231" "10.181.165.232")
ALL_NETB_ADDRS=("10.181.165.230" "10.181.165.231" "10.181.165.232")
ALL_NETA_BCAST="10.181.165.255"
ALL_NETB_BCAST="10.181.165.255"
ALL_NETA_TIEBREAKER="10.181.165.1"

ALL_HEART_UDP_PORT="63099"
ALL_HEART_XMIT_UDP_PORT="63100"
------
+
Example /etc/hosts file entries for above configuration:
+
------
10.181.165.230  dev1.your-domain.com    dev1
10.181.165.231  dev2.your-domain.com    dev2
10.181.165.232  dev3.your-domain.com    dev3
------
+
NOTE: See
http://hibari.github.com/hibari-doc/hibari-sysadmin-guide.en.html#partition-detector
for further information regarding the network partition detector
application, Network A, and Network B.  Additional information for the
application's configuration is embedded in the partition-detector's
OTP application source file
(https://github.com/hibari/partition-detector/raw/master/src/partition_detector.app.src).
+
CAUTION: In a production setting, Network A and Network B should be
physically different networks and network interfaces.  However, the
same network can be used (as in this example) for Network A and
Network B for testing and development purposes.
+
CAUTION: Currently hostname must not contain "-" (minus).  If hostname
contain "-", like dev-1 for example, your Hibari cluster will not
startup. This will be fixed in future release and this sentence will
be deleted at that time. Thanks for your patience.

===== Example how to prepare installing user

Setup your user (i.e. your login - $USER) on all Hibari nodes if not
already existing.  This user will only be used for Hibari installation
purposes.

1. As root user, add your user to all of the Hibari nodes and grant
   sudo access for your user.
+
------
$ useradd $USER
$ passwd $USER
$ visudo
# append the following line and save it
$USER  ALL=(ALL)       NOPASSWD: ALL
------
+
NOTE: If you get "sudo: sorry, you must have a tty to run sudo" error
while testing 'sudo', consider to comment out following line inside of
the /etc/sudoers file:
+
------
$ visudo
Defaults    requiretty
------
+
2. Create a new ssh private/public key for your user on the installer
   node.
+
------
$ ssh-keygen
# enter your password for the private key
$ eval `ssh-agent`
$ ssh-add ~/.ssh/id_rsa
# re-enter your password for the private key
------
+
3. Append an entry for the installer node to your \~/.ssh/known_hosts
   file on each of the Hibari nodes and append an entry to your
   ~/.ssh/authorized_keys file on all of the Hibari nodes for your
   public ssh key.
+
------
$ ssh-copy-id -i ~/.ssh/id_rsa.pub $USER@dev1
$ ssh-copy-id -i ~/.ssh/id_rsa.pub $USER@dev2
$ ssh-copy-id -i ~/.ssh/id_rsa.pub $USER@dev3
------
+
NOTE: If your installer node will be one of the Hibari cluster nodes,
make sure that you ssh-copy-id to the installer node also.
+
4. Confirm password-less access to the each of the Hibari nodes works
as expected.
+
------
$ ssh $USER@dev1
$ ssh $USER@dev2
$ ssh $USER@dev3
------

TIP: If needed, check
http://inside.mines.edu/~gmurray/HowTo/sshNotes.html for further SSH
setup help.

===== Example how to prepare installer node

1. Configure your e-mail and name for Git
+
------
$ git config --global user.email "you@example.com"
$ git config --global user.name "Your Name"
------
+
2. Create working directory
+
------
$ mkdir working-directory-name
------
+
3. Download cluster tool's Git repository
+
------
$ cd working-directory-name
$ git clone git://github.com/hibari/clus.git
------
+
4. Place a copy of the Hibari pre-built release and your hibari.config
   file into the working directory.
+
------
$ cd working-directory-name
$ ls -1
clus
hibari-X.Y.Z-DIST-ARCH-WORDSIZE-md5sum.txt
hibari-X.Y.Z-DIST-ARCH-WORDSIZE.tgz
hibari.config
$
------

===== Example how to create all Hibari nodes

All of the operations below are run on the installer node via two Bash
scripts (i.e. clus.sh and clus-hibari.sh).

1. Create (or re-create) "hibari" user on all Hibari nodes
+
NOTE: If your ssh private key is protected by a password, please make
sure your private key is registered with the ssh agent before
proceeding.
+
------
$ cd working-directory-name
$ for i in dev1 dev2 dev3 ; do ./clus/priv/clus.sh -f init hibari $i ; done
hibari@dev1
hibari@dev2
hibari@dev3
------
+
CAUTION: The -f option will forcefully delete and then re-create
the "hibari" user on the target node.
+
2. Copy pre-built release to all Hibari nodes and then setup Hibari
   package on all Hibari nodes via the "hibari" user.
+
------
$ cd working-directory-name
$ ./clus/priv/clus-hibari.sh -f init hibari hibari.config hibari-X.Y.Z-DIST-ARCH-WORDSIZE.tgz
hibari@dev1
hibari@dev2
hibari@dev3
------

TIP: As described in the next section, the clus-hibari.sh script can
be used for starting and stopping of a Hibari multi node cluster even
after it's creation.

=== Deploying a Simple Hibari System

==== Single Node

===== Basic Configuration
_to be added_

===== Starting a Single Node Cluster

. Start Hibari
+
------
$ running-directory-name/hibari/bin/hibari start
------
+
. Bootstrap Hibari
+
------
$ running-directory-name/hibari/bin/hibari-admin bootstrap
------
+
The Hibari bootstrap process starts Hibari's Admin server on the
single node and creates a single table "tab1" serving as Hibari's
default table.

===== Verifying Your System

A few simple operations to verify system is set up properly.

. Open "Hibari Web Administration" page
+
------
$ your-favorite-browser http://127.0.0.1:23080
------
+
. Ping node to check the health.
+
------
$ running-directory-name/hibari/bin/hibari ping
------

_to be added_

===== Creating Other Tables
_to be added_

===== Stopping a Single Node Cluster

. Stop Hibari
+
------
$ running-directory-name/hibari/bin/hibari stop
------

==== Multi Node

===== Basic Configuration
_to be added_

===== Starting a Multi Node Cluster

. Start Hibari on all Hibari nodes via the "hibari" user
+
------
$ cd working-directory-name
$ ./clus/priv/clus-hibari.sh -f start hibari hibari.config
hibari@dev1
hibari@dev2
hibari@dev3
------
+
. Bootstrap Hibari on first Hibari admin node via the "hibari" user
+
------
$ cd working-directory-name
$ ./clus/priv/clus-hibari.sh -f bootstrap hibari hibari.config
hibari@dev1 => hibari@dev1 hibari@dev2 hibari@dev3
------
+
The Hibari bootstrap process starts Hibari's admin server on the first
admin node and creates a single table "tab1" serving as Hibari's
default table.
+
NOTE: If bootstrapping fails due to "another_admin_server_running"
error, please stop the other Hibari cluster(s) running on the network
or repeat the installation from the beginning with udp ports
(i.e. ALL_HEART_UDP_PORT and ALL_HEART_XMIT_UDP_PORT) that are not in
use by other applications or another Hibari cluster.

===== Verifying Your System

A few simple operations to verify system is set up properly.

. Open "Hibari Web Administration" page
+
------
$ your-favorite-browser http://dev1:23080
------
+
. Ping each of the nodes to check the health.
+
------
$ cd working-directory-name
$ ./clus/priv/clus-hibari.sh -f ping hibari hibari.config
hibari@dev1 ... pong
hibari@dev2 ... pong
hibari@dev3 ... pong
------

_to be added_

===== Creating Other Tables
_to be added_

===== Stopping a Multi Node Cluster

. Stop Hibari on all Hibari nodes via the "hibari" user
+
------
$ cd working-directory-name
$ ./clus/priv/clus-hibari.sh -f stop hibari hibari.config
ok
ok
ok
hibari@dev1
hibari@dev2
hibari@dev3
------


== Client API: Native Erlang

=== Overview

As a key-value database, Hibari provides a simple client API with primitive operations for inserting, retrieving, and deleting data. Within certain restrictions, the API also supports compound operations that optionally can be executed as all-or-nothing transactions.

More specifically, Hibari's client API supports the operations listed below. For details on the native Erlang API for each operation, follow the links.

*Data Insertion*

 - Add a key-value pair that does not yet exist, along with optional flags:
  * link:#brick-simple-add[brick_simple:add/6]
 - Assign a new value and/or new flags to a key that already exists:
  * link:#brick-simple-replace[brick_simple:replace/6]
 - Set a key-value pair and optional flags regardless of whether the key yet exists:
  * link:#brick-simple-set[brick_simple:set/6]

*Data Retrieval*

 - Retrieve a key and optionally its associated value and flags:
  * link:#brick-simple-get[brick_simple:get/4]
 - Retrieve multiple lexicographically contiguous keys and optionally their associated values and flags:
  * link:#brick-simple-get-many[brick_simple:get_many/5]

*Data Deletion*

 - Delete a key-value pair and associated flags:
  * link:#brick-simple-delete[brick_simple:delete/4]

*Compound Operations*

 - Execute a specified list of operations, optionally as an all-or-nothing transaction:
  * link:#brick-simple-do[brick_simple:do/4]

If desired, clients can apply a "test 'n set" logic to data insertion, retrieval, and deletion operations so that the operation will be executed only if the target key has the exact timestamp specified in the request.

==== Erlang Basic Data Types

The following provides a high level introduction to Erlang basic data types that are referenced in this chapter. This material is excerpted with minor modifications from the http://www.erlang.org/doc/reference_manual/data_types.html[official Erlang documentation on data types]. For further information, see the official Erlang documentation.

IMPORTANT: All Erlang commands must conclude with a period (.).

Term:: A piece of data of any data type is called a *term*.

Number:: There are two types of numeric literals, *integers* and *floats*.

Atom:: An *atom* is a literal, a constant with name. An atom should be enclosed in single quotes (') if it does not begin with a lower-case letter or if it contains other characters than alphanumeric characters, underscore (_), or @. Optionally, any atom can be enclosed in single quotes. For example:
+
-----
hello
phone_number
'Monday'
'phone number'
'hello'
'phone_number'
-----

Bit String and Binary:: A *bit string* is used to store an area of untyped memory. Bit strings are expressed using http://www.erlang.org/doc/reference_manual/expressions.html#bit_syntax[Erlang bit syntax]. A bit string that consists of a number of bits that is evenly divisible by eight is called a *binary*. For example:
+
-----
<<10,20>>
<<"ABC">>
-----

Tuple:: A *tuple* is a compound data type with a fixed number of terms, enclosed by braces:
+
-----
{Term1,...,TermN}
-----

List:: A *list* is a compound data type with a variable number of terms, enclosed by square brackets:
+
-----
[Term1,...,TermN]
-----

String:: Strings are enclosed in double quotes ("), but are not a true data type in Erlang. Instead a string "hello" is shorthand for the list [$h,$e,$l,$l,$o], that is [104,101,108,108,111].

Boolean:: There is no Boolean data type in Erlang. Instead the atoms `true` and `false` are used to denote Boolean values.


[[brick-simple-add]]
=== brick_simple:add/6

SYNOPSIS

 ::
*brick_simple:add(Tab, Key, Value, ExpTime, Flags, Timeout).*

DESCRIPTION

 ::
Add `Key` and `Value` pair (and optional `Flags`) to the table `Tab` if the key does not already exist.  The operation will fail if `Key` already exists.

PARAMETERS

 ::
*Tab*

- Name of the table to which to add the key-value pair.
- Mandatory.
- Type:
  * `Tab = table()`
  * `table() = atom()`
 
 ::
*Key*

- Key to add to the table, in association with a paired value.
- Mandatory.
- Type: 
  * `Key = key()`
  * `key() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
+
NOTE: While the `Key` may be specified as either `iolist()` or `binary()`, it will be converted into binary before operation execution. The same is true of `Value`.
+

 ::
*Value*

- Value to associate with the key.
- Mandatory.
- Type:
  * `Value = val()`
  * `val() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`

 ::
*ExpTime*

- Time at which the key will expire, expressed as a Unix time_t().
- Optional; defaults to 0 (no expiration).
- Type:
  * `ExpTime = exp_time()`
  * `exp_time() = time_t()`
  * `time_t() = integer()`

 ::
*Flags*

- List of operational flags to apply to the `add' operation, and/or custom property flags to associate with the key-value pair in the database. Heavy use of custom property flags is discouraged due to RAM-based storage.
- Optional; defaults to empty list.
- Type:
  * `Flags = flags_list()`
  * `flags_list() = [do_op_flag() | property()]`
  * `do_op_flag() = 'value_in_ram'`
  * `property() = atom() | {term(), term()}`
- Operational flag usage
  * `'value_in_ram'`
    ** Store the value blob in RAM, overriding the default storage location of the brick.  
+
NOTE: This flag has not yet been extensively tested by Gemini QA.
+

 ::
*Timeout*

- Operation timeout in milliseconds.
- Optional; defaults to 15000.
- Type:
  * `Timeout = timeout()`
  * `timeout() = integer() | 'infinity'`

RETURNS

 ::
Success return

- `'ok'`

 ::
Error returns

- `{'key_exists',timestamp()}`
  * The operation failed because the key already exists.
  * `timestamp() = integer()`
- `'invalid_flag_present'`
  * The operation failed because an invalid `do_op_flag()` was found in the `Flags` argument.
- `'brick_not_available'`
  * The operation failed because the chain that is responsible for this key is currently length zero and therefore unavailable.
- `{{'nodedown',node()},{'gen_server','call',term()}}`
  * The operation failed because the server brick handling the request has crashed or else a network partition has occurred between the client and server. The client should resend the query after a short delay, on the assumption that the Admin Server will have detected the failure and taken steps to repair the chain.
  * `node() = atom()`

ALIASES

 ::
- brick_simple:add/3
  * `brick_simple:add(Tab, Key, Value).`
- brick_simple:add/4
  * `brick_simple:add(Tab, Key, Value, Flags).`
  * `brick_simple:add(Tab, Key, Value, Timeout).`

EXAMPLES

 ::
Successful adding of a new key-value pair:
+
------
> brick_simple:add(tab1, <<"foo">>, <<"Hello, world!">>).
ok
------
+

 ::
Failed attempt to add a key that already exists:
+
------
> brick_simple:add(tab1, <<"foo">>, <<"Goodbye, world!">>).
{key_exists,1271542959131192}
------
+

 ::
Successful adding of a new key-value pair, with value to be stored in RAM regardless of brick's default storage setting:
+
------
> brick_simple:add(tab1, "foo1", "this is value1", ['value_in_ram']).
ok
------
+

 ::
Successful adding of a new key-value pair, using a non-default operation timeout:
+
------
> brick_simple:add(tab1, "foo2", "this is value2", 20000).
ok
------

[[brick-simple-replace]]
=== brick_simple:replace/6

SYNOPSIS

 ::
*brick_simple:replace(Tab, Key, Value, ExpTime, Flags, Timeout).*

DESCRIPTION

 ::
Replace `Key` and `Value` pair (and optional `Flags`) in the table `Tab` if the key already exists.  The operation will fail if `Key` does not already exist.

PARAMETERS

 ::
*Tab*

- Name of the table in which to replace the key-value pair.
- Mandatory.
- Type:
  * `Tab = table()`
  * `table() = atom()`
 
 ::
*Key*

- Key to replace in the table, in association with a new paired value.
- Mandatory.
- Type: 
  * `Key = key()`
  * `key() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
+
NOTE: While the `Key` may be specified as either `iolist()` or `binary()`, it will be converted into binary before operation execution. The same is true of `Value`.
+

 ::
*Value*

- New value to associate with the key.
- Mandatory.
- Type:
  * `Value = val()`
  * `val() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`

 ::
*ExpTime*

- Time at which the key will expire, expressed as a Unix time_t().
- Optional; defaults to 0 (no expiration).
- Type:
  * `ExpTime = exp_time()`
  * `exp_time() = time_t()`
  * `time_t() = integer()`

 ::
*Flags*

- List of operational flags to apply to the `replace' operation, and/or custom property flags to associate with the key-value pair in the database. Heavy use of custom property flags is discouraged due to RAM-based storage.
- Optional; defaults to empty list.
- Type:
  * `Flags = flags_list()`
  * `flags_list() = [do_op_flag() | property()]`
  * `do_op_flag() = {'testset', timestamp()} |'value_in_ram'`
  * `timestamp() = integer()`
  * `property() = atom() | {term(), term()}`
- Operational flag usage
  * `{'testset', timestamp()}`
    ** Fail the operation if the existing key's timestamp is not exactly equal to `timestamp()`.  If used inside a link:#brick-simple-do[micro-transaction], abort the transaction if the key's timestamp is not exactly equal to `timestamp()`.  
  * `'value_in_ram'`
    ** Store the value blob in RAM, overriding the default storage location of the brick.
+
NOTE: This flag has not yet been extensively tested by Gemini QA.
+

 ::
*Timeout*

- Operation timeout in milliseconds.
- Optional; defaults to 15000.
- Type:
  * `Timeout = timeout()`
  * `timeout() = integer() | 'infinity'`

RETURNS

 ::
Success return

- `'ok'`

 ::
Error returns

- `'key_not_exist'`
  * The operation failed because the key does not exist.
- `{'ts_error', timestamp()}`
  * The operation failed because the `{'testset', timestamp()}` flag was used and there was a timestamp mismatch. The `timestamp()` in the return is the current value of the existing key's timestamp.
  * `timestamp() = integer()`
- `'invalid_flag_present'`
  * The operation failed because an invalid `do_op_flag()` was found in the `Flags` argument.
- `'brick_not_available'`
  * The operation failed because the chain that is responsible for this key is currently length zero and therefore unavailable.
- `{{'nodedown',node()},{'gen_server','call',term()}}`
  * The operation failed because the server brick handling the request has crashed or else a network partition has occurred between the client and server. The client should resend the query after a short delay, on the assumption that the Admin Server will have detected the failure and taken steps to repair the chain.
  * `node() = atom()`

ALIASES

 ::
- brick_simple:replace/3
  * `brick_simple:replace(Tab, Key, Value).`
- brick_simple:replace/4
  * `brick_simple:replace(Tab, Key, Value, Flags).`
  * `brick_simple:replace(Tab, Key, Value, Timeout).`

EXAMPLES

 ::
Successful replacement of a key-value pair:
+
------
> brick_simple:replace(tab1, <<"foo">>, <<"Goodbye, world!">>).
ok
------
+

 ::
Failed attempt to replace a key that does not yet exist:
+
------
> brick_simple:replace(tab1, <<"key3">>, <<"new and improved value">>).
key_not_exist
------
+

 ::
Successful replacement of a key-value pair, with value to be stored in RAM regardless of brick's default storage setting:
+
------
> brick_simple:replace(tab1, "foo", "You again, world!", ['value_in_ram']).
ok
------
+

 ::
Failed attempt to replace a key for which we have incorrectly specified its current timestamp:
+
------
> brick_simple:replace(tab1, "foo", "Whole new value", [{'testset', 12345}]).
{ts_error,1271543165272987}
------
+

 ::
Successful replacement of a key-value pair for which we have correctly specified its current timestamp:
+
------
> brick_simple:replace(tab1, "foo", "Whole new value", [{'testset', 1271543165272987}]).
ok
------
+

 ::
Successful replacement of a key-value pair, using a non-default operation timeout:
+
------
> brick_simple:replace(tab1, "foo", "Foo again?", 30000).
ok
------

[[brick-simple-set]]
=== brick_simple:set/6

SYNOPSIS

 ::
*brick_simple:set(Tab, Key, Value, ExpTime, Flags, Timeout).*

DESCRIPTION

 ::
Set `Key` and `Value` pair (and optional `Flags`) in the table `Tab`, regardless of whether or not the key already exists.

PARAMETERS

 ::
*Tab*

- Name of the table in which to set the key-value pair.
- Mandatory.
- Type:
  * `Tab = table()`
  * `table() = atom()`
 
 ::
*Key*

- Key to set in the table, in association with a paired value.
- Mandatory.
- Type: 
  * `Key = key()`
  * `key() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
+
NOTE: While the `Key` may be specified as either `iolist()` or `binary()`, it will be converted into binary before operation execution. The same is true of `Value`.
+

 ::
*Value*

- Value to associate with the key.
- Mandatory.
- Type:
  * `Value = val()`
  * `val() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`

 ::
*ExpTime*

- Time at which the key will expire, expressed as a Unix time_t().
- Optional; defaults to 0 (no expiration).
- Type:
  * `ExpTime = exp_time()`
  * `exp_time() = time_t()`
  * `time_t() = integer()`

 ::
*Flags*

- List of operational flags to apply to the `set' operation, and/or custom property flags to associate with the key-value pair in the database. Heavy use of custom property flags is discouraged due to RAM-based storage.
- Optional; defaults to empty list.
- Type:
  * `Flags = flags_list()`
  * `flags_list() = [do_op_flag() | property()]`
  * `do_op_flag() = {'testset', timestamp()} |'value_in_ram'`
  * `timestamp() = integer()`
  * `property() = atom() | {term(), term()}`
- Operational flag usage
  * `{'testset', timestamp()}`
    ** Fail the operation if the existing key's timestamp is not exactly equal to `timestamp()`.  If used inside a link:#brick-simple-do[micro-transaction], abort the transaction if the key's timestamp is not exactly equal to `timestamp()`. Using this flag with `set` will result in an error if the key does not already exist or if the key exists but has a non-matching timestamp. 
  * `'value_in_ram'`
    ** Store the value blob in RAM, overriding the default storage location of the brick.
+
NOTE: This flag has not yet been extensively tested by Gemini QA.
+

 ::
*Timeout*

- Operation timeout in milliseconds.
- Optional; defaults to 15000.
- Type:
  * `Timeout = timeout()`
  * `timeout() = integer() | 'infinity'`

RETURNS

 ::
Success return

- `'ok'`

 ::
Error returns

- `'key_not_exist'`
  * The operation failed because the `{'testset', timestamp()}` flag was used and the key does not exist.
- `{'ts_error', timestamp()}`
  * The operation failed because the `{'testset', timestamp()}` flag was used and there was a timestamp mismatch. The `timestamp()` in the return is the current value of the existing key's timestamp.
  * `timestamp() = integer()`
- `'invalid_flag_present'`
  * The operation failed because an invalid `do_op_flag()` was found in the `Flags` argument.
- `'brick_not_available'`
  * The operation failed because the chain that is responsible for this key is currently length zero and therefore unavailable.
- `{{'nodedown',node()},{'gen_server','call',term()}}`
  * The operation failed because the server brick handling the request has crashed or else a network partition has occurred between the client and server. The client should resend the query after a short delay, on the assumption that the Admin Server will have detected the failure and taken steps to repair the chain.
  * `node() = atom()`

ALIASES

 ::
- brick_simple:set/3
  * `brick_simple:set(Tab, Key, Value).`
- brick_simple:set/4
  * `brick_simple:set(Tab, Key, Value, Flags).`
  * `brick_simple:set(Tab, Key, Value, Timeout).`

EXAMPLES

 ::
Successful setting of a key-value pair:
+
------
> brick_simple:set(tab1, <<"key4">>, <<"cool value">>).
ok
------
+

 ::
Successful setting of a key-value pair, with value to be stored in RAM regardless of brick's default storage setting:
+
------
> brick_simple:set(tab1, "goo", "value6", ['value_in_ram']).
ok
------
+

 ::
Failed attempt to set a key-value pair, when we have used the `testset` flag but the key does not yet exist:
+
------
> brick_simple:set(tab1, "boo", "hoo", [{'testset', 1271543165272987}]).
key_not_exist
------
+

 ::
Successful setting of a key-value pair, when we have used the `testset` flag and the key does already exist and its timestamp matches our specified timestamp:
+
------
> brick_simple:set(tab1, "goo", "value7", [{'testset', 1271543165272432}]).
ok
------

[[brick-simple-get]]
=== brick_simple:get/4

SYNOPSIS

 ::
*brick_simple:get(Tab, Key, Flags, Timeout).*

DESCRIPTION

 ::
From table `Tab`, retrieve `Key` and specified attributes of the key (as determined by `Flags`).

PARAMETERS

 ::
*Tab*

- Name of the table from which to retrieve the key.
- Mandatory.
- Type:
  * `Tab = table()`
  * `table() = atom()`
 
 ::
*Key*

- Key to retrieve from the table.
- Mandatory.
- Type: 
  * `Key = key()`
  * `key() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
+
NOTE: While the `Key` may be specified as either `iolist()` or `binary()`, it will be converted into binary before operation execution.
+

 ::
*Flags*

- List of operational flags to apply to the `get' operation, and/or custom property flags.
- Optional; defaults to empty list.
- Type:
  * `Flags = flags_list()`
  * `flags_list() = [do_op_flag() | property()]`
  * `do_op_flag() = 'get_all_attribs' | 'witness' | {'testset', timestamp()} | 'must_exist' | 'must_not_exist'`
  * `timestamp() = integer()`
  * `property() = atom() | {term(), term()}`
- Operational flag usage
  * `'get_all_attribs'`
    ** Return all attributes of the key. May be used in combination with the `witness` flag.
  * `'witness'`
    ** Do not return the value blob in the result. This flag will guarantee that the brick does not require disk access to satisfy this request.
  * `{'testset', timestamp()}`
    ** Fail the operation if the key's timestamp is not exactly equal to `timestamp()`. If used inside a link:#brick-simple-do[micro-transaction], abort the transaction if the key's timestamp is not exactly equal to `timestamp()`.
  * `'must_exist'`
    ** For use inside a link:#brick-simple-do[micro-transaction]: abort the transaction if the key does not exist.
  * `'must_not_exist'`
    ** For use inside a link:#brick-simple-do[micro-transaction]: abort the transaction if the key exists.

 ::
*Timeout*

- Operation timeout in milliseconds.
- Optional; defaults to 15000.
- Type:
  * `Timeout = timeout()`
  * `timeout() = integer() | 'infinity'`

RETURNS

 ::
Success returns

- `{'ok', timestamp(), val()}`
  * Success return when the get request uses neither the `'witness'` flag nor the `'get_all_attribs'` flag.
  * `timestamp() = integer()`
  * `val() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
- `{'ok', timestamp()}`
  * Success return when the get uses `'witness'` but not `'get_all_attribs'`.
- `{'ok', timestamp(), proplist()}`
  * Success return when the get uses both `'witness'` and `'get_all_attribs'`.
  * `proplist() = [property()]`
  * `property() = atom() | {term(), term()}`
- `{'ok', timestamp(), val(), exp_time(), proplist()}`
  * Success return when the get uses `'get_all_attribs'` but not `'witness'`.
  * `exp_time() = time_t()`
+
NOTE: When a `proplist()` is returned, one of the properties in the list will always be `{val_len,Size::integer()}`, where `Size` is the size of the value blob in bytes.
+

 ::
Error returns

- `'key_not_exist'`
  * The operation failed because the key does not exist.
- `{'ts_error', timestamp()}`
  * The operation failed because the `{'testset', timestamp()}` flag was used and there was a timestamp mismatch. The `timestamp()` in the return is the current value of the existing key's timestamp.
- `'invalid_flag_present'`
  * The operation failed because an invalid `do_op_flag()` was found in the `Flags` argument.
- `'brick_not_available'`
  * The operation failed because the chain that is responsible for this key is currently length zero and therefore unavailable.
- `{{'nodedown',node()},{'gen_server','call',term()}}`
  * The operation failed because the server brick handling the request has crashed or else a network partition has occurred between the client and server. The client should resend the query after a short delay, on the assumption that the Admin Server will have detected the failure and taken steps to repair the chain.
  * `node() = atom()`

ALIASES

 ::
- brick_simple:get/2
  * `brick_simple:get(Tab, Key).`
- brick_simple:get/3
  * `brick_simple:get(Tab, Key, Flags).`
  * `brick_simple:get(Tab, Key, Timeout).`

EXAMPLES

 ::
Successful retrieval of a key-value pair:
+
------
> brick_simple:get(tab1, "goo").
{ok,1271543165272432,<<"value7">>}
------
+

 ::
Successful retrieval of a key without its associated value blob:
+
------
> brick_simple:get(tab1, "goo", ['witness']).
{ok,1271543165272432}
------
+

 ::
Failed attempt to retrieve a key that does not exist:
+
------
> brick_simple:get(tab1, "moo").
key_not_exist
------

[[brick-simple-get-many]]
=== brick_simple:get_many/5

SYNOPSIS

 ::
*brick_simple:get_many(Tab, Key, MaxNum, Flags, Timeout).*

DESCRIPTION

 ::
Get many `Key` and `Value` pairs from a single chain in the table `Tab`, up to a maximum of `MaxNum`. Keys are returned in lexicographic sorting order. The key `Key` is the starting point: if there is a key `KeyNext` that follows `Key` (in lexicographic order), and if the `boolean()` value in the return is `true`, then `KeyNext` will be the first key's info in the `get_many_res_list()`.
+
IMPORTANT: The `get_many()` function call cannot be used to find all keys in all chains in a Hibari table. The consistent hash of `Key` will send the `get_many` operation to the tail brick in a single chain; all keys returned will come from that single brick only.
+

PARAMETERS

 ::
*Tab*

- Name of the table from which to retrieve the keys.
- Mandatory.
- Type:
  * `Tab = table()`
  * `table() = atom()`
 
 ::
*Key*

- Key at which to start the `get_many` retrieval, proceeding in lexicographic order.
- Mandatory.
- Type: 
  * `Key = key()`
  * `key() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
+
NOTE: While the `Key` may be specified as either `iolist()` or `binary()`, it will be converted into binary before operation execution.
+

 ::
*MaxNum*

- Maximum number of keys to return.
- Mandatory.
- Type:
  * `MaxNum = integer()`

 ::
*Flags*

- List of operational flags to apply to the `get_many' operation, and/or custom property flags.
- Optional; defaults to empty list.
- Type:
  * `Flags = flags_list()`
  * `flags_list() = [do_op_flag() | property()]`
  * `do_op_flag() = 'get_all_attribs' | 'witness' | {'binary_prefix', binary()} | {'max_bytes', integer()}`
  * `property() = atom() | {term(), term()}`
- Operational flag usage
  * `'get_all_attribs'`
    ** Return all attributes of each key. May be used in combination with the `witness` flag.
  * `'witness'`
    ** Do not return the value blobs in the result. This flag will guarantee that the brick does not require disk access to satisfy this request.
  * `{'binary_prefix', binary()}`
    ** Return only keys that have a
binary prefix that is exactly equal to `binary()`.
  * `{'max_bytes', integer()}`
    ** Return only as many keys as the sum of the sizes of their corresponding value blobs does not exceed `integer()` bytes.

 ::
*Timeout*

- Operation timeout in milliseconds.
- Optional; defaults to 15000.
- Type:
  * `Timeout = timeout()`
  * `timeout() = integer() | 'infinity'`

RETURNS

 ::
Success returns

- `{ok, {[{key(), timestamp(), val()}], boolean()}}`
  * Success return when the `get_many` request uses neither the `'witness'` flag nor the `'get_all_attribs'` flag.
  * `timestamp() = integer()`
  * `val() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
- `{ok, {[{key(), timestamp()}], boolean()}}`
  * Success return when the `get_many` uses `'witness'` but not `'get_all_attribs'`.
- `{ok, {[{key(), timestamp(), proplist()}], boolean()}}`
  * Success return when the `get_many` uses both `'witness'` and `'get_all_attribs'`.
  * `proplist() = [property()]`
  * `property() = atom() | {term(), term()}`
- `{ok, {[{key(), timestamp(), val(), exp_time(), proplist()}], boolean()}}`
  * Success return when the `get_many` uses `'get_all_attribs'` but not `'witness'`.
  * `exp_time() = time_t()`
+
NOTE: When a `proplist()` is returned, one of the properties in the list will always be `{val_len,Size::integer()}`, where `Size` is the size of the value blob in bytes.
+

 ::
Error returns

- `'invalid_flag_present'`
  * The operation failed because an invalid `do_op_flag()` was found in the `Flags` argument.
- `'brick_not_available'`
  * The operation failed because the chain that is responsible for this key is currently length zero and therefore unavailable.
- `{{'nodedown',node()},{'gen_server','call',term()}}`
  * The operation failed because the server brick handling the request has crashed or else a network partition has occurred between the client and server. The client should resend the query after a short delay, on the assumption that the Admin Server will have detected the failure and taken steps to repair the chain.
  * `node() = atom()`

ALIASES

 ::
- brick_simple:get_many/3
  * `brick_simple:get_many(Tab, Key, MaxNum).`
- brick_simple:get_many/4
  * `brick_simple:get_many(Tab, Key, MaxNum, Flags).`
  * `brick_simple:get_many(Tab, Key, MaxNum, Timeout).`

EXAMPLES

 ::
Successful retrieval of all keys from a table that currently has only two keys. The boolean `false' indicates that there are no keys following the `foo` key:
+
------
> brick_simple:get_many(tab1, "", 5).
{ok,{[{<<"another">>,1271543102911775,<<"yes!">>},
      {<<"foo">>,1271543165272987,<<"Foo again?">>}],
     false}}
------
+

 ::
Successful retrieval of all keys from a table that currently has only two keys, using the `witness` flag in the request.
+
------
> brick_simple:get_many(tab1, "", 5, ['witness']).
{ok,{[{<<"another">>,1271543102911775},
      {<<"foo">>,1271543165272987}],
     false}}
------

 ::
Successful retrieval of all keys from a table that currently has only two keys, using the `get_all_attribs` flag in the request.
+
------
> brick_simple:get_many(tab1, "", 5).
{ok,{[{<<"another">>,1271543102911775,<<"yes!">>,0,
       [{val_len,4}]},
      {<<"foo">>,1271543165272987,<<"Foo again?">>,0,[{val_len,6}]}],
     false}}
------

[[brick-simple-delete]]
=== brick_simple:delete/4

SYNOPSIS

 ::
*brick_simple:delete(Tab, Key, Flags, Timeout).*

DESCRIPTION

 ::
Delete key `Key` from the table `Tab`.

PARAMETERS

 ::
*Tab*

- Name of the table from which to delete the key and its associated value.
- Mandatory.
- Type:
  * `Tab = table()`
  * `table() = atom()`
 
 ::
*Key*

- Key to delete from the table.
- Mandatory.
- Type: 
  * `Key = key()`
  * `key() = iodata()`
  * `iodata() = iolist() | binary()`
  * `iolist()  = [char() | binary() | iolist()]`
+
NOTE: While the `Key` may be specified as either `iolist()` or `binary()`, it will be converted into binary before operation execution.
+

 ::
*Flags*

- List of operational flags to apply to the `delete' operation, and/or custom property flags.
- Optional; defaults to empty list.
- Type:
  * `Flags = flags_list()`
  * `flags_list() = [do_op_flag() | property()]`
  * `do_op_flag() = {'testset', timestamp()} |'must_exist' | 'must_not_exist'`
  * `timestamp() = integer()`
  * `property() = atom() | {term(), term()}`
- Operational flag usage
  * `{'testset', timestamp()}`
    ** Fail the operation if the existing key's timestamp is not exactly equal to `timestamp()`.  If used inside a link:#brick-simple-do[micro-transaction], abort the transaction if the key's timestamp is not exactly equal to `timestamp()`. Using this flag with `set` will result in an error if the key does not already exist or if the key exists but has a non-matching timestamp. 
  * `'must_exist'`
    ** For use inside a link:#brick-simple-do[micro-transaction]: abort the transaction if the key does not exist.
  * `'must_not_exist'`
    ** For use inside a link:#brick-simple-do[micro-transaction]: abort the transaction if the key exists.

 ::
*Timeout*

- Operation timeout in milliseconds.
- Optional; defaults to 15000.
- Type:
  * `Timeout = timeout()`
  * `timeout() = integer() | 'infinity'`

RETURNS

 ::
Success return

- `'ok'`

 ::
Error returns

- `'key_not_exist'`
  * The operation failed because the key does not exist.
- `{'ts_error', timestamp()}`
  * The operation failed because the `{'testset', timestamp()}` flag was used and there was a timestamp mismatch. The `timestamp()` in the return is the current value of the existing key's timestamp.
  * `timestamp() = integer()`
- `'invalid_flag_present'`
  * The operation failed because an invalid `do_op_flag()` was found in the `Flags` argument.
- `'brick_not_available'`
  * The operation failed because the chain that is responsible for this key is currently length zero and therefore unavailable.
- `{{'nodedown',node()},{'gen_server','call',term()}}`
  * The operation failed because the server brick handling the request has crashed or else a network partition has occurred between the client and server. The client should resend the query after a short delay, on the assumption that the Admin Server will have detected the failure and taken steps to repair the chain.
  * `node() = atom()`

ALIASES

 ::
- brick_simple:delete/2
  * `brick_simple:delete(Tab, Key).`
- brick_simple:delete/3
  * `brick_simple:delete(Tab, Key, Flags).`
  * `brick_simple:delete(Tab, Key, Timeout).`

EXAMPLES

 ::
Successful deletion of a key and its associated value and attributes:
+
------
> brick_simple:delete(tab1, <<"foo">>).
ok
------
+

 ::
Failed attempt to delete a key that does not exist:
+
------
> brick_simple:delete(tab1, "key6").
key_not_exist
------
+

 ::
Failed attempt to delete a key for which we have incorrectly specified its current timestamp:
+
------
> brick_simple:delete(tab1, "goo", [{'testset', 12345}]).
{ts_error,1271543165272987}
------
+

 ::
Successful deletion of a key for which we have correctly specified its current timestamp:
+
------
> brick_simple:delete(tab1, "goo", [{'testset', 1271543165272987}]).
ok
------
+

 ::
Successful deletion of a key, using a non-default operation timeout:
+
------
> brick_simple:delete(tab1, "key3", 30000).
ok
------

[[brick-simple-do]]
=== brick_simple:do/4

SYNOPSIS

 ::
*brick_simple:do(Tab, OpList, OpFlags, Timeout).*

DESCRIPTION

 ::
Send a list of primitive operations to the table `Tab`. They will be executed at the same time by a Hibari brick. If the first item in the `OpList` is `brick_server:make_txn()` then the list of operations is executed in the context of a micro-transaction: either all operations will be executed successfully or none will be executed. We term these "micro"-transactions because they are subject to certain limitations that apply to all operations that use the `brick_simple:do()` API:
* All impacted keys must be in the same table.
* All impacted keys must be in the same chain.
* All operations in the transaction must be sent in a single `brick_simple:do()` call. Unlike some other databases, it is not possible to request a transaction handle and to add operations to that transaction in an one-by-one, "ad hoc" manner.

 ::
For further information about micro-transactions, see link:hibari-sysadmin-guide.en.html#micro-transactions[Hibari System Administrator's Guide, "Micro-Transactions" section].

PARAMETERS

 ::
*Tab*

- Name of the table in which to perform the operations.
- Mandatory.
- Type:
  * `Tab = table()`
  * `table() = atom()`
 
 ::
*OpList*

- List of primitive operations to perform. Each primitive is invoked using the `brick_server:make_*()` API. 
- Mandatory.
- Type: 
  * `OpList = do_op_list()`
  * `do_op_list() = [do1_op()]`
  * `do1_op() =`
    ** `brick_server:make_add(Key, Value, ExpTime, Flags)`
    ** `brick_server:make_replace(Key, Value, ExpTime, Flags)`
    ** `brick_server:make_set(Key, Value, ExpTime, Flags)`
    ** `brick_server:make_get(Key, Flags)`
    ** `brick_server:make_get_many(Key, Flags)`
    ** `brick_server:make_delete(Key, Flags)`
    ** `brick_server:make_txn()`
       *** Include `brick_server:make_txn()` as the first item in your `OpList` if you want the `do` operation to be executed as an all-or-nothing transaction.
    ** Note that the arguments for each primitive are the same as those for the primitives when they are executed on their own, with the exclusion of the `Tab` and `Timeout` arguments, both of which serve as arguments to the overall `do` operation rather than as arguments to the primitives. For example, an `add` on its own is `brick_simple:add(Tab, Key, Value, ExpTime, Flags, Timeout)`, whereas in the context of a `do` operation an `add` primitive is `brick_server:make_add(Key, Value, ExpTime, Flags)`. 
    ** For further information about each primitive, see link:#brick-simple-add[brick_simple:add/6], link:#brick-simple-replace[brick_simple:replace/6], link:#brick-simple-set[brick_simple:set/6], link:#brick-simple-get[brick_simple:get/4], link:#brick-simple-get-many[brick_simple:get_many/5], and link:#brick-simple-delete[brick_simple:delete/4].

 ::
*OpFlags*

- List of operational flags to apply to the overall `do' operation.
- Optional; defaults to empty list.
- Type:
  * `OpFlags = do_flags_list()`
  * `do_flags_list() = [do_flag()]`
  * `do_flag() = 'fail_if_wrong_role' | 'ignore_role'`
- Operational flag usage
  * `'fail_if_wrong_role'`
    ** _description to be added_
  * `'ignore_role'`
    ** _description to be added_

 ::
*Timeout*

- Operation timeout in milliseconds.
- Optional; defaults to 15000.
- Type:
  * `Timeout = timeout()`
  * `timeout() = integer() | 'infinity'`

RETURNS

 ::
Success return

- `[do1_res_ok]`
  * List of `do1_res_ok`, one for each primitive operation specified in the `do` request. Return list order corresponds to the order in which primitive operations are listed in the request's `OpList`. Note that if the `do` request does not use transaction semantics, then some individual primitive operations may fail without the overall `do` operation failing.
  * Within the return list, possible `do1_res_ok` returns to each individual primitive operation are the same as the possible returns that the primitive operation type could generate if it were executed on its own. For example, within the `do` operation's success return list, the possible returns for a primitive `add` operation are the same as the returns described in the link:#brick-simple-add[brick_simple:add/6] section; potential returns to a primitive `replace` operation are the same as those described in the link:#brick-simple-replace[brick_simple:replace/6] section; and likewise for link:#brick-simple-set[set], link:#brick-simple-get[get], link:#brick-simple-get-many[get_many], and link:#brick-simple-delete[delete].

 ::
Error returns

- `{txn_fail, [{integer(), do1_res_fail()}]}`
  * Operation failed because transaction semantics were used in the `do` request and one or more primitive operations within the transaction failed. The `integer()` identifies the failed primitive operation by its position within the request's `OpList`. For example, a 2 indicates that the second primitive listed in the request's `OpList` failed. Note that this position identifier does not count the `txn()` specifier at the start of the `OpList`.
  * `do1_res_fail()` indicates the type of failure for the failed primitive operation. Possibilities are:
    ** `{'key_exists', timestamp()}`
       *** `timestamp() = integer()`
    ** `'key_not_exist'`
    ** `{'ts_error', timestamp()}`
    ** `'invalid_flag_present'`
- `'invalid_flag_present'`
  * The operation failed because an invalid `do_flag()` was found in the `do` request's `OpFlags` argument. Note this is a different error than an invalid flag being found within an individual primitive.
- `'brick_not_available'`
  * The operation failed because the chain that is responsible for this key is currently length zero and therefore unavailable.
- `{{'nodedown',node()},{'gen_server','call',term()}}`
  * The operation failed because the server brick handling the request has crashed or else a network partition has occurred between the client and server. The client should resend the query after a short delay, on the assumption that the Admin Server will have detected the failure and taken steps to repair the chain.
  * `node() = atom()`

ALIASES

 ::
- brick_simple:do/2
  * `brick_simple:do(Tab, OpList).`
- brick_simple:do/3
  * `brick_simple:do(Tab, OpList, Timeout).`

EXAMPLES

 ::
Successful `do` operation adding two new keys to table `tab1`, without transaction semantics:
+
------
> brick_simple:do(tab1, [brick_server:make_add("foo3", "bar3"),brick_server:make_add("foo4", "bar4")]).
[ok,ok]
------
+

 ::
Successful creation of two `get` primitives `Do1` and `Do2`, and their subsequent combination into a `do` request, without transaction semantics:
+
------
> Do1 = brick_server:make_get("foo").
{get,<<"foo">>,[]}
> Do2 = brick_server:make_get("foo2").
{get,<<"foo2">>,[]}
> brick_simple:do(tab1, [Do1, Do2]).
[{ok,1271543102911775,<<"Foo again?">>},key_not_exist]
------
+

 ::
Failed operation with transaction semantics. Because transaction semantics are used, the failure of the primitive `Do2b` causes the entire operation to fail.
+
------
> Do1b = brick_server:make_get("foo").
{get,<<"foo">>,[]}
> Do2b = brick_server:make_get("foo2", [must_exist]).
{get,<<"foo2">>,[must_exist]}
> brick_simple:do(tab1, [brick_server:make_txn(), Do1b, Do2b]).
{txn_fail,[{2,key_not_exist}]}
------


== Client API: UBF and Thrift
_Under Construction_

// - _Dave to import content from pre-existing "Developer's Guide", review and revise as needed._
// - _Will solicit info and review from Dev as needed._


== Developer Utilities
_Under Construction_

// - _KK Dev to provide initial content._
// - _Dave to review, edit, and solicit additional info as needed._

=== Basho Bench
_to be added_

=== Yahoo! Cloud Serving Benchmark
_to be added_


[[HibariBuildingSource]]
== Building Hibari from Source
_Under Construction_

// - _KK Dev to provide initial content._
// - _Dave to review, edit, and solicit additional info as needed._

This section describes the basic recipes to build the following items:

- Hibari Release Package
- Hibari Documentation
- Erlang/OTP System

Before getting started, review this checklist of tools and software.
Please install and setup as needed.

Git (Mandatory)::
- Git - http://git-scm.com/
  * *Git 1.5.4 or newer, Git 1.7.3.4 has been tested recently*
  * _required for Repo and GitHub_
- GitHub - https://github.com
  * Anonymous read-only access using the GIT protocol is default.
  * Team members having read-write access should add his/her ssh
    public key under your GitHub account.
Erlang/OTP (Mandatory)::
- OpenSSL - http://www.openssl.org/
  * _required for Erlang's crypto module_
- Erlang - http://www.erlang.org/
  * *R13B04 or newer*
  * *R14B01 has been tested most recently*
  * If needed, see <<ErlangOTP>> for instructions to build Erlang/OTP
    from source.
Python (Mandatory)::
- Python - http://www.python.org
  * *Python 2.4 or newer, Python 2.7 has been tested most recently
     (CAUTION: Python 3.x might be too new)*
  * _required for Repo and AsciiDoc_
AsciiDoc (Optional)::
- AsciiDoc - http://www.methods.co.nz/asciidoc/index.html
  * *asciidoc 8.6.1 and asciidoc 9.6.3 have been tested most recently*
  * plus the following tools:
    ** ImageMagick - http://www.imagemagick.org/
    ** graphviz - http://www.graphviz.org/
    ** mscgen - http://www.mcternan.me.uk/mscgen/
  * Mandatory for building Hibari's documentation. See
    <<HibariAsciiDoc>> for further details.
- docbook - http://www.docbook.org/
  * Optional for building _pdf_ version of Hibari's documentation
- xmlto - https://fedorahosted.org/xmlto/
  * Optional for building _text_ version of Hibari's documentation

In addition to the above list, Hibari also depends on two tools to
automate the downloading and the packaging steps.

- Repo - http://source.android.com/source/git-repo.html
- Rebar - https://github.com/basho/rebar/wiki

Instructions for downloading the Repo tool are described next.  The
Rebar tool is included in Hibari's git repositories so there is no
need to download it separately.  Please refer to the above sites for
further information regarding the usage of these tools.

The first step is to download the Git repositories from GitHub.

. Downloading _basic recipe_
  .. Configure your e-mail and name for Git
+
------
$ git config --global user.email "you@example.com"
$ git config --global user.name "Your Name"
------
+
  .. Install Repo
+
------
$ mkdir -p ~/bin
$ wget -O - http://android.git.kernel.org/repo > ~/bin/repo
$ chmod a+x ~/bin/repo
------
+
  .. Create working directory
+
------
$ mkdir working-directory-name
$ cd working-directory-name
$ repo init -u git://github.com/hibari/manifests.git -m hibari-default.xml
------
+
NOTE: Your "Git" identity is needed during the init step.  Please
enter the name and email of your GitHub account if you have one.  Team
members having read-write access are recommended to use "repo init -u
git@github.com:hibari/manifests.git -m hibari-default-rw.xml".
+
  .. Download Git repositories
+
------
$ cd working-directory-name
$ repo sync
------
+

The working directory has the following layout structure:

-----
<working-directory-name>
  |- hibari/
    |- .git/
    |- .gitignore
    |- Makefile
    |- dialyze-ignore-warnings.txt
    |- dialyze-nospec-ignore-warnings.txt
    |- lib/                             <1>
      |- <application_name>/
        |- .git/
        |- .gitignore
        |- ebin/
        |- include/
          |- *.hrl
        |- priv/
        |- rebar.config
        |- src/
          |- <application_name>.app.src
          |- *.erl
        |- test/
          |- eunit/
            |- *.erl
          |- eqc/
            |- *.erl
      :
    |- rebar
    |- rebar.config
    |- rel/                             <2>
      |- files/
        |- app.config
        |- erl
        |- hibari
        |- hibari-admin
        |- nodetool
        |- nodetool-admin
        |- vm.args
      |- hibari/
        :
        |- releases/
          |- <release_vsn>/
            :
          :
        :
      |- reltool.config
  |- hibari-doc/                        <3>
    :
  |- manifests/                         <4>
    :
  |- patches/                           <5>
    :
  |- rebar/                             <6>
    :
  |- .repo/
    :
-----

<1> Applications
<2> Releases
<3> Documentation
<4> Manifests
<5> Patches
<6> Rebar

=== Hibari Release Package

This section is the first step to build, to _eunit_ test, and to
package your own Hibari.

. Building _basic recipe_
+
------
$ cd working-directory-name/hibari
$ make
------
+
TIP: If the response is "make: erl: Command not found", please make
sure Erlang/OTP is installed and "otp-installing-directory-name/bin"
is added to your $PATH environment.
+
. Release Packaging _basic recipe_
+
------
$ cd working-directory-name/hibari
$ make package
------
+
NOTE: A release package tarball "hibari-X.Y.Z-dev-ARCH-WORDSIZE.tgz"
and md5sum file "hibari-X.Y.Z-dev-ARCH-WORDSIZE-md5sum.txt" is written
to working-directory-name.

[[HibariAsciiDoc]]
=== Hibari Documentation

This section is the first step to download and to build your own
Hibari documentation.

. Building Hibari's "Guides" _basic recipe_
+
------
$ cd working-directory-name/hibari-doc/src/hibari
$ make clean -OR- make realclean
$ make
------
+
. Building Hibari's "Website" _basic recipe_
+
------
$ cd working-directory-name/hibari-doc/src/hibari/website
$ make clean -OR- make realclean
$ make
------
+
NOTE: HTML documentation is written in the "./public_html" directory.

Hibari's documentation is authored using AsciiDoc and a few auxillary
tools:

- ImageMagick
- docbook
- graphviz
- mscgen
- xmlto

Hibari's documentation is generated with asciidoc 8.6.3 and a manually
modified version of the a2x tool.

------
$ diff -u /usr/local/Cellar/asciidoc/8.6.3/bin/a2x{.orig,}
--- /usr/local/Cellar/asciidoc/8.6.3/bin/a2x.orig	2011-01-02 18:09:35.000000000 +0900
+++ /usr/local/Cellar/asciidoc/8.6.3/bin/a2x	2011-01-02 18:11:19.000000000 +0900
@@ -156,7 +156,10 @@
 def shell_copy(src, dst):
     verbose('copying "%s" to "%s"' % (src,dst))
     if not OPTIONS.dry_run:
-        shutil.copy(src, dst)
+        try:
+            shutil.copy(src, dst)
+        except shutil.Error:
+            return

 def shell_rm(path):
     if not os.path.exists(path):
------

[[ErlangOTP]]
=== Erlang/OTP System

This section is the first step to download, to build, and to install
your own Erlang/OTP system.

. Downloading _basic recipe_
  .. Please make sure to have the 'openssl-devel' package installed on
     your system.  OpenSSL is required by Hibari (and before
     configuring and building of your Erlang/OTP system).
  .. Get and install Git
+
  .. Download the source code for your Erlang/OTP system
+
------
$ cd working-directory-name
$ wget http://www.erlang.org/download/otp_src_R14B01.tar.gz
------
+
  .. Untar the source code for your Erlang/OTP system.
+
------
$ cd working-directory-name
$ tar -xzf otp_src_R14B01.tar.gz
------
+
. Building _basic recipe_
  .. Change to your working directory and configure Erlang/OTP
+
------
$ cd working-directory-name/otp_src_R14B01
$ ./configure --prefix=otp-installing-directory-name
------
+
  .. Build Erlang/OTP
+
------
$ cd working-directory-name/otp_src_R14B01
$ make
------
+
. Installing _basic recipe_
+
------
$ cd working-directory-name/otp_src_R14B01
$ sudo make install
------

CAUTION: Please make sure "otp-installing-directory-name/bin" is added
to your $PATH environment.


== Sample Application
_Under Construction_

// - _KK Dev to provide initial content._
// - _Likely deferred to future date._

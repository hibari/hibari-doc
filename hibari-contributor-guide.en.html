<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Hibari Contributor’s Guide DRAFT - IN PROGRESS</title><link rel="stylesheet" href="docbook-xsl.css" type="text/css" /><meta name="generator" content="DocBook XSL Stylesheets V1.75.2" /></head><body><div xml:lang="en" class="article" title="Hibari Contributor&#x2019;s Guide DRAFT - IN PROGRESS" lang="en"><div class="titlepage"><div><div><h2 class="title"><a id="id36104937"></a>Hibari Contributor’s Guide  <span class="strong"><strong>DRAFT - IN PROGRESS</strong></span></h2></div><div><div class="revhistory"><table border="1" width="100%" summary="Revision history"><tr><th align="left" valign="top" colspan="2"><b>Revision History</b></th></tr><tr><td align="left">Revision 0.5.1</td><td align="left">2011/01/07</td></tr></table></div></div></div><hr /></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="section"><a href="#_introduction">1. Introduction</a></span></dt><dd><dl><dt><span class="section"><a href="#_topics_covered">1.1. Topics Covered</a></span></dt><dt><span class="section"><a href="#_reading_the_systems_administrator_guide_is_strongly_recommended">1.2. Reading the Systems Administrator Guide Is Strongly Recommended</a></span></dt><dt><span class="section"><a href="#_copyright_notices">1.3. Copyright Notices</a></span></dt></dl></dd><dt><span class="section"><a href="#_contributing_to_hibari">2. Contributing to Hibari</a></span></dt><dd><dl><dt><span class="section"><a href="#_github_git_and_repo">2.1. GitHub, Git, and Repo</a></span></dt><dt><span class="section"><a href="#_code_branch_and_version_management">2.2. Code, Branch, and Version Management</a></span></dt><dt><span class="section"><a href="#_documentation">2.3. Documentation</a></span></dt><dt><span class="section"><a href="#_submitting_patches">2.4. Submitting Patches</a></span></dt></dl></dd><dt><span class="section"><a href="#_getting_started_with_hibari_and_erlang">3. Getting Started with Hibari and Erlang</a></span></dt><dd><dl><dt><span class="section"><a href="#_downloading_and_compiling_hibari">3.1. Downloading and Compiling Hibari</a></span></dt><dt><span class="section"><a href="#ntp-reminder">3.2. Reminder: Configure NTP (Network Time Protocol)</a></span></dt><dt><span class="section"><a href="#starting-hibari-1st-time">3.3. Starting Hibari for the first time</a></span></dt><dt><span class="section"><a href="#_bootstrapping_the_hibari_cluster_on_your_local_machine">3.4. Bootstrapping the Hibari "cluster" on your local machine</a></span></dt><dt><span class="section"><a href="#_starting_hibari_for_the_second_and_following_times">3.5. Starting Hibari for the second and following times</a></span></dt><dt><span class="section"><a href="#data-model">3.6. The Data Model</a></span></dt><dt><span class="section"><a href="#_setting_getting_and_deleting_keys">3.7. Setting, Getting, and Deleting Keys</a></span></dt><dt><span class="section"><a href="#_creating_new_tables">3.8. Creating New Tables</a></span></dt><dt><span class="section"><a href="#changing-chain-length">3.9. Changing Chain Length</a></span></dt><dt><span class="section"><a href="#changing-chains-example">3.10. Creating New/Deleting Current/Reweighting/Rehashing Chains</a></span></dt></dl></dd><dt><span class="section"><a href="#client-api-erlang">4. Client API: Native Erlang</a></span></dt><dd><dl><dt><span class="section"><a href="#erlang-data-types-single">4.1. Erlang data types for single-operation <code class="literal">brick_simple</code> API</a></span></dt><dt><span class="section"><a href="#erlang-data-types-multi">4.2. Erlang data types for multi-operation API</a></span></dt><dt><span class="section"><a href="#notes-on-operation-flags">4.3. Notes on Operation Flags</a></span></dt><dt><span class="section"><a href="#notes-on-return-values">4.4. Notes on Return Values</a></span></dt><dt><span class="section"><a href="#_single_operation_api">4.5. Single-Operation API</a></span></dt></dl></dd><dt><span class="section"><a href="#client-api-ubf">5. Client API: UBF</a></span></dt><dd><dl><dt><span class="section"><a href="#hibari-server-impl-of-ubf-proto-stack">5.1. The Hibari Server’s Implementation of the UBF Protocol Stack</a></span></dt><dt><span class="section"><a href="#ubf-representation-of-strings">5.2. UBF representation of strings vs. binaries</a></span></dt><dt><span class="section"><a href="#using-ubf-in-any-language">5.3. Steps for Using a UBF-based Protocol in Any Language</a></span></dt><dt><span class="section"><a href="#the-hibari-ubf-protocol-contract">5.4. The Hibari UBF Protocol Contract</a></span></dt><dt><span class="section"><a href="#using-ubf-erlang-client">5.5. Using the UBF Client Library for Erlang</a></span></dt><dt><span class="section"><a href="#using-ubf-java-client">5.6. Using the UBF Client Library for Java</a></span></dt><dt><span class="section"><a href="#using-ubf-python-client">5.7. Using the EBF Client Library for Python</a></span></dt></dl></dd><dt><span class="section"><a href="#client-api-tbf">6. Client API: TBF</a></span></dt><dd><dl><dt><span class="section"><a href="#_the_hibari_thrift_api">6.1. The Hibari Thrift API</a></span></dt><dt><span class="section"><a href="#_mapping_ubf_contract_types_to_thrift_types">6.2. Mapping UBF Contract Types to Thrift Types</a></span></dt><dt><span class="section"><a href="#_mapping_ubf_contract_to_thrift_service">6.3. Mapping UBF Contract to Thrift Service</a></span></dt><dt><span class="section"><a href="#_examples_of_using_a_thrift_client">6.4. Examples of using a thrift client</a></span></dt><dt><span class="section"><a href="#_mapping_tbf_contract_responses_from_thrift_client">6.5. Mapping TBF Contract Responses From Thrift Client</a></span></dt></dl></dd><dt><span class="section"><a href="#client-api-json-rpc">7. Client API: JSON-RPC</a></span></dt><dd><dl><dt><span class="section"><a href="#client-language-support-for-json-rpc">7.1. Client Language Support for JSON-RPC</a></span></dt><dt><span class="section"><a href="#mapping-ubf-contract-types-to-json">7.2. Mapping UBF Contract Types to JSON Types</a></span></dt><dt><span class="section"><a href="#mapping-ubf-contract-requests-to-json-rpc">7.3. Mapping UBF Contract Requests to JSON-RPC</a></span></dt><dt><span class="section"><a href="#mapping-ubf-contract-responses-from-json-rpc">7.4. Mapping UBF Contract Responses From JSON-RPC</a></span></dt><dt><span class="section"><a href="#_using_the_json_rpc_client_library_for_erlang">7.5. Using the JSON-RPC Client Library for Erlang</a></span></dt><dt><span class="section"><a href="#_pointer_to_the_hibari_ubf_contract">7.6. Pointer to the Hibari UBF contract</a></span></dt></dl></dd><dt><span class="section"><a href="#client-api-json-over-tcp">8. Client API: JSON over TCP</a></span></dt><dd><dl><dt><span class="section"><a href="#client-language-support-for-json-over-tcp">8.1. Client Language Support for JSON over TCP</a></span></dt><dt><span class="section"><a href="#mapping-ubf-contract-types-to-json-2">8.2. Mapping UBF Contract Types to JSON Types</a></span></dt><dt><span class="section"><a href="#mapping-ubf-contract-requests-to-json-rpc-2">8.3. Mapping UBF Contract Requests to JSON and Server Responses to JSON</a></span></dt><dt><span class="section"><a href="#_examples_of_using_the_json_over_tcp_protocol">8.4. Examples of using the JSON over TCP protocol</a></span></dt><dt><span class="section"><a href="#_using_the_json_over_tcp_client_library_for_erlang">8.5. Using the JSON over TCP Client library for Erlang</a></span></dt><dt><span class="section"><a href="#_pointer_to_the_hibari_ubf_contract_2">8.6. Pointer to the Hibari UBF contract</a></span></dt></dl></dd><dt><span class="section"><a href="#_managing_hibari_api_overview">9. Managing Hibari: API overview</a></span></dt><dd><dl><dt><span class="section"><a href="#add-a-new-table">9.1. Add a New Table: brick_admin:add_table()</a></span></dt><dt><span class="section"><a href="#delete-a-table">9.2. Delete a Table</a></span></dt><dt><span class="section"><a href="#change-a-chain-add-remove-bricks">9.3. Change a Chain: Add or Remove Bricks</a></span></dt><dt><span class="section"><a href="#change-a-table-add-remove-chains">9.4. Change a Table: Add/Remove Chains</a></span></dt><dt><span class="section"><a href="#change-a-table-chain-chain-weighting">9.5. Change a Table: Change Chain Weighting</a></span></dt><dt><span class="section"><a href="#admin-server-api">9.6. Admin Server API</a></span></dt><dt><span class="section"><a href="#scoreboard-api">9.7. Scoreboard API</a></span></dt><dt><span class="section"><a href="#chain-monitor-api">9.8. Chain Monitor API</a></span></dt></dl></dd><dt><span class="section"><a href="#_hibari_internals_the_source_module_by_module">10. Hibari Internals: The Source, Module by Module</a></span></dt><dd><dl><dt><span class="section"><a href="#major-subsystems">10.1. Major subsystems</a></span></dt><dt><span class="section"><a href="#admin-server-crash-recovery">10.2. Admin Server notes: crash-recovery design</a></span></dt><dt><span class="section"><a href="#module-by-module-commentary">10.3. Module-By-Module Commentary</a></span></dt><dt><span class="section"><a href="#debugging-hibari-using-tracing">10.4. Debugging Hibari (clients and servers) using tracing</a></span></dt></dl></dd><dt><span class="section"><a href="#_appendix_troubleshooting">11. Appendix: Troubleshooting</a></span></dt><dd><dl><dt><span class="section"><a href="#problem-multiple-hibari-apps">11.1. Problem: Cannot run multiple Hibari apps on the same physical machine</a></span></dt></dl></dd><dt><span class="section"><a href="#_appendix_known_warts_problems_inefficiencies_refactoring_opportunities_etc">12. Appendix: Known Warts, Problems, Inefficiencies, Refactoring Opportunities, etc.</a></span></dt></dl></div><p></p><div class="section" title="1.&#xA0;Introduction"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_introduction"></a>1. Introduction</h2></div></div></div><div class="caution" title="Caution" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Caution"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Caution]" src="images/icons/caution.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>This document is under re-construction - beware!</p></td></tr></table></div><p>This document’s goal is to describe the software architecture of the
Hibari key-value database, discuss parts of its implementation, and to
document the Hibari client APIs.</p><p>At a minimum, application developers need to know how to use the
various Hibari client APIs.  Hibari is a key-value database, which
almost by definition have a small API.  Learning the basics isn’t too
difficult.  To be really effective, however, application developers
also need to have a good overall understanding of how Hibari works.</p><p>For developers interested in working on Hibari itself, the source code
is the ultimate documentation.  But like most software developed in an
industrial setting, Hibari grew at times quite quickly and at times
sat on the shelf, waiting for customer demand.  Anyone who works with
the software, including Hibari’s original developers, need
documentation to understand not only how something works but also why
certain choices were made … and what parts need more work.</p><div class="section" title="1.1.&#xA0;Topics Covered"><div class="titlepage"><div><div><h3 class="title"><a id="_topics_covered"></a>1.1. Topics Covered</h3></div></div></div><p>This document is divided into five major sections:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
Contributing to Hibari
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
GitHub, Git, and Repo
</li><li class="listitem">
Code, Branch, and Version Management
</li><li class="listitem">
Documentation
</li><li class="listitem">
Submitting Patches
</li></ul></div></li><li class="listitem"><p class="simpara">
Introduction for application developers via the Erlang shell
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
This document assumes that many early users of Hibari will be
   developing some or all of their applications in Erlang.  If that
   is not true for you, then you might jump to the next section…
</li><li class="listitem">
… but we hope you will skim this section anyway.  Don’t worry
   about many of the Erlang-specific details.  Erlang’s syntax is
   usually simple enough that anyone familiar with another programming
   language can understand what’s going on.
</li></ul></div></li><li class="listitem"><p class="simpara">
Using the Hibari client APIs
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
This section will describe the nitty-gritty details of all of the
   major Hibari APIs, via the native Erlang interface and also the
   various protocols supported by the server.
</li></ul></div></li><li class="listitem"><p class="simpara">
Hibari APIs for the rest of the system: cluster management, table
  management and reconfiguration, etc.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Until there is an HTTP interface that handles all of Hibari’s
   management API, the work must be done via the Erlang shell.  This
   section will discuss how to use the Hibari management API in
   enough explanation that non-Erlang users should feel comfortable
   using the API.
</li></ul></div></li><li class="listitem"><p class="simpara">
Discussion of Hibari’s implementation
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
The audience for this section is developers who wish to understand
   Hibari’s implementation at a deeper level and add new features, fix
   bugs, or just generally tinker with and experiment on the system.
</li></ul></div></li></ul></div></div><div class="section" title="1.2.&#xA0;Reading the Systems Administrator Guide Is Strongly Recommended"><div class="titlepage"><div><div><h3 class="title"><a id="_reading_the_systems_administrator_guide_is_strongly_recommended"></a>1.2. Reading the Systems Administrator Guide Is Strongly Recommended</h3></div></div></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>To avoid a lot of cut-and-paste text, many of the
operational details that a developer should know or must know about
Hibari are found in the <a class="ulink" href="hibari-sysadmin-guide.en.html" target="_top">Hibari System
Administrator’s Guide</a>.  This document assumes that a developer has
already skimmed the System Administrator’s Guide and is willing to jump
over to that guide when necessary.</p></td></tr></table></div><p></p></div><div class="section" title="1.3.&#xA0;Copyright Notices"><div class="titlepage"><div><div><h3 class="title"><a id="_copyright_notices"></a>1.3. Copyright Notices</h3></div></div></div><p>Copyright © 2005-2011 Gemini Mobile Technologies, Inc.  All rights
reserved.</p><p>Gemini Mobile® and HyperScale® are registered trademarks of Gemini
Mobile Technologies, Inc. in the United States and other countries.</p><p>Portions of Gemini products include third-party technology used under
license.</p><pre class="screen">Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</pre><p></p></div></div><div class="section" title="2.&#xA0;Contributing to Hibari"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_contributing_to_hibari"></a>2. Contributing to Hibari</h2></div></div></div><div class="section" title="2.1.&#xA0;GitHub, Git, and Repo"><div class="titlepage"><div><div><h3 class="title"><a id="_github_git_and_repo"></a>2.1. GitHub, Git, and Repo</h3></div></div></div><p><span class="emphasis"><em>to be added</em></span></p><p>List the working directories for all of Hibari’s "projects":</p><pre class="screen">$ repo forall -c "pwd"</pre><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Each project has a corresponding Git repository and (default)
revision.  Check the "manifests/hibari-default.xml" file for details.</p></td></tr></table></div><p>Start a new topic (e.g. new-topic-name) branch:</p><pre class="screen">$ repo start new-topic-name `repo forall -c "pwd" | xargs echo`</pre><p>Abandon an existing topic (e.g. topic-name) branch:</p><pre class="screen">$ repo abandon topic-name `repo forall -c "pwd" | xargs echo`</pre><p>Track and checkout the master branch:</p><pre class="screen">$ repo forall -c "git branch --track master github/master"
$ repo forall -c "git checkout master"</pre><p>Track and checkout the dev (i.e. Development) branch:</p><pre class="screen">$ repo forall -c "git branch --track dev github/dev"
$ repo forall -c "git checkout dev"</pre></div><div class="section" title="2.2.&#xA0;Code, Branch, and Version Management"><div class="titlepage"><div><div><h3 class="title"><a id="_code_branch_and_version_management"></a>2.2. Code, Branch, and Version Management</h3></div></div></div><p><span class="emphasis"><em>to be added</em></span></p></div><div class="section" title="2.3.&#xA0;Documentation"><div class="titlepage"><div><div><h3 class="title"><a id="_documentation"></a>2.3. Documentation</h3></div></div></div><p><span class="emphasis"><em>to be added</em></span></p></div><div class="section" title="2.4.&#xA0;Submitting Patches"><div class="titlepage"><div><div><h3 class="title"><a id="_submitting_patches"></a>2.4. Submitting Patches</h3></div></div></div><p><span class="emphasis"><em>to be added</em></span></p></div></div><div class="section" title="3.&#xA0;Getting Started with Hibari and Erlang"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_getting_started_with_hibari_and_erlang"></a>3. Getting Started with Hibari and Erlang</h2></div></div></div><p>All readers, familiar with Erlang or not, should have little
difficulty following the examples in this section.  If you’re new to
Erlang, just consider it a little domain-specific language (DSL) to
experiment with.</p><div class="section" title="3.1.&#xA0;Downloading and Compiling Hibari"><div class="titlepage"><div><div><h3 class="title"><a id="_downloading_and_compiling_hibari"></a>3.1. Downloading and Compiling Hibari</h3></div></div></div><p>Application developers who aren’t using Erlang can skip this section.
You’ve already read the
<a class="ulink" href="hibari-sysadmin-guide.en.html" target="_top">Hibari System Administrator’s Guide</a>
and know how to download the Hibari package, install it, start the
Hibari daemon, and bootstrap the Admin server.  So skip ahead to
<a class="xref" href="#data-model" title="3.6.&#xA0;The Data Model">Section 3.6, “The Data Model”</a>.</p><p><span class="emphasis"><em>Under Construction</em></span></p></div><div class="section" title="3.2.&#xA0;Reminder: Configure NTP (Network Time Protocol)"><div class="titlepage"><div><div><h3 class="title"><a id="ntp-reminder"></a>3.2. Reminder: Configure NTP (Network Time Protocol)</h3></div></div></div><p>Please see
<a class="ulink" href="hibari-sysadmin-guide.en.html#ntp-config-strongly-recommended" target="_top">Hibari
Sysadmin Guide, "NTP configuration of all Hibari server and client
nodes" section</a>.  It is strongly recommended that all Hibari client
and server nodes have NTP configured and running.  If your client
application experiences frequent inexplicable timeout errors, client
vs. server clock skew is likely the cause.</p></div><div class="section" title="3.3.&#xA0;Starting Hibari for the first time"><div class="titlepage"><div><div><h3 class="title"><a id="starting-hibari-1st-time"></a>3.3. Starting Hibari for the first time</h3></div></div></div><p><span class="emphasis"><em>Under Construction</em></span></p></div><div class="section" title="3.4.&#xA0;Bootstrapping the Hibari &quot;cluster&quot; on your local machine"><div class="titlepage"><div><div><h3 class="title"><a id="_bootstrapping_the_hibari_cluster_on_your_local_machine"></a>3.4. Bootstrapping the Hibari "cluster" on your local machine</h3></div></div></div><p>Use this procedure to bootstrap a "cluster" of one machine (i.e. your
local machine).  The following steps will take care of three things at
once:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Define a single "bootstrap" brick, for use by the Admin Server for
  private state management.
</li><li class="listitem">
Start the Admin Server application.
</li><li class="listitem">
Create a single Hibari table called <code class="literal">tab1</code>.  We’ll use the table for
  the rest of our experiments.
</li></ul></div><p>Bootstrapping can be done via your Web browser: fetch the URL
<code class="literal">http://localhost:23080</code>.  If your Web browser is running on a
different machine, change the hostname in the URL.  If you’ve changed
the default Admin Server HTTP TCP port (see
<a class="xref" href="#multiple-hibari-instances-TCP-conflicts" title="Multiple Hibari instances have TCP port conflicts">the section called “Multiple Hibari instances have TCP port conflicts”</a>), change the port
number in the URL.</p><p>You should see something like this:</p><p title="Admin Server top-level page: Admin Server not running"><b>Admin Server top-level page: Admin Server not running. </b>
</p><pre class="screen">Storage Brick Web Administration
================================

Unable to Contact Admin Server

The cluster is not yet configured and running. If you believe that the
cluster's Admin Server has been configured, please wait 30 seconds,
then reload this page to fetch new cluster info.
[...]</pre><p title="Admin Server top-level page: Admin Server not running">
</p><p>Ignore all of the warning messages in the middle of that page.
Instead, do the following:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Scroll down to the bottom of the page.
</li><li class="listitem">
Click the "Bootstrap" button.
</li></ol></div><p>That’s all.  You should see this:</p><p title="Bootstrap was successful"><b>Bootstrap was successful. </b>
</p><pre class="screen">Bootstrap was successful!

Go to the main page to view the cluster. You will be automatically
redirected in 5 seconds.</pre><p title="Bootstrap was successful">
</p><p>After five seconds, your Web browser should be redirected to
<code class="literal">http://localhost:23080/</code> and you’ll see something like this below.
(If not, click your browser’s "Reload" button.)</p><p title="Admin Server top-level page: Admin Server not running"><b>Admin Server top-level page: Admin Server not running. </b>
</p><pre class="screen">Storage Brick Web Administration
================================

Admin Server

The Hibari Admin Server is running on node: hibari1@bb3

The current date and time is: {2010,4,14} {20,2,14}
[...]</pre><p title="Admin Server top-level page: Admin Server not running">
</p><p>Congratulations, your little Hibari cluster is ready to use.</p></div><div class="section" title="3.5.&#xA0;Starting Hibari for the second and following times"><div class="titlepage"><div><div><h3 class="title"><a id="_starting_hibari_for_the_second_and_following_times"></a>3.5. Starting Hibari for the second and following times</h3></div></div></div><p>The next time that you start Hibari in developer interactive mode,
you’ll have to start the Admin Server by hand.  The first two steps
are the same, but there’s an additional mandatory step at the Erlang
shell (the 3rd command)</p><p>The Admin Server is not started as part of the Erlang/OTP <code class="literal">gdss</code> app
because the Admin Server is only run once within a Hibari cluster.
It’s active/standby nature is normally controlled via the Erlang/OTP
application controller, but since we’re not using that controller when
in developer mode, we must start the Admin Server manually.</p><p title="Running Hibari in developer interactive mode and starting the Admin Server"><b>Running Hibari in developer interactive mode and starting the Admin Server. </b>
</p><pre class="screen">  $ cd gdss/src
  $ make run-app1-interactive
  &gt; brick_admin:start_link("Schema.local").</pre><p title="Running Hibari in developer interactive mode and starting the Admin Server">
</p><p>The <code class="literal">Schema.local</code> file contains the bootstrap hint that’s required to
allow the Admin Server to finish bootstrapping itself.</p><p>Once the Admin Server is running, you’ll be able to see the usual
status info at the usual <code class="literal">http://localhost:23080/</code> URL.</p></div><div class="section" title="3.6.&#xA0;The Data Model"><div class="titlepage"><div><div><h3 class="title"><a id="data-model"></a>3.6. The Data Model</h3></div></div></div><p>If a Hibari table were represented within an SQL database, it would
look something like this:</p><p title="SQL-like definition of a Hibari table"><a id="sql-definition-hibari"></a><b>SQL-like definition of a Hibari table. </b>
</p><pre class="screen">CREATE TABLE foo (
    BLOB key;
    BLOB value;
    INTEGER timestamp;                  -- Monotonically increasing
    INTEGER expiration_time;            -- Usually zero
    LIST OF ATOMS_AND_TWO_TUPLES flags; -- Metadata stored in RAM for speed
) PRIMARY KEY key;</pre><p title="SQL-like definition of a Hibari table">
</p><div class="section" title="Hibari table names"><div class="titlepage"><div><div><h4 class="title"><a id="_hibari_table_names"></a>Hibari table names</h4></div></div></div><p>Hibari table names use the Erlang data type “atom”.  The types of
all key-related attributes are presented below.</p></div><div class="section" title="Hibari table key-value attributes"><div class="titlepage"><div><div><h4 class="title"><a id="_hibari_table_key_value_attributes"></a>Hibari table key-value attributes</h4></div></div></div><div class="table"><a id="id36105608"></a><p class="title"><b>Table 1. Types of Hibari table key-value attributes</b></p><div class="table-contents"><table summary="Types of Hibari table key-value attributes" cellpadding="4px" style="border-collapse: collapse;border-top: 3px solid #527bbd; border-bottom: 3px solid #527bbd; border-left: 3px solid #527bbd; border-right: 3px solid #527bbd; "><colgroup><col /><col /><col /><col /></colgroup><thead><tr><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Attribute Name </th><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Erlang data type </th><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Storage Location </th><th style="border-bottom: 1px solid #527bbd; " align="left" valign="top"> Description</th></tr></thead><tbody><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>Key</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>binary</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>RAM</p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>A binary blob of any size, though due to RAM storage the key should be small enough for all keys to fit in RAM.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>Value</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>binary</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>RAM or disk</p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>A binary blob of any size, though practical constraints limit value blobs to 16MB or so.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>Timestamp</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>integer</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>RAM</p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>A monotonically increasing counter, usually (but not always) based on the client’s wall-clock time.  Updating a key with a timestamp smaller than the key’s current timestamp is not permitted.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>Expiration Time</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>integer</p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p>RAM</p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>A UNIX <code class="literal">time_t</code> representing the expiration time for a key.  A value of 0 means no expiration, and no RAM overhead is required.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p>Flags</p></td><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p>list</p></td><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p>RAM</p></td><td style="" align="left" valign="top"><p>This attribute cannot be represented in plain SQL.  It is a list of atoms and/or {atom(), term()} pairs.  Heavy use of this attribute is discouraged due to RAM-based storage.</p></td></tr></tbody></table></div></div><br class="table-break" /><p>"Storage location = RAM" means that, during normal query handling,
data is retrieved from a copy in RAM.  All modifications of any/all
attributes of a key are written to the write-ahead log to prevent data
loss in case of a cluster-wide power failure.  See
<a class="xref" href="#">???</a> for more details.</p><p>"Store location = disk" means that the value of the attribute is not
stored in RAM.  Metadata in RAM contains a pointer to the attribute’s
location:file #, byte offset, and length.  A log sequence file inside
the common log must be opened, call <code class="literal">lseek(2)</code>, and then <code class="literal">read(2)</code> to
retrieve the attribute.</p><div class="variablelist"><dl><dt><span class="term">
Best case
</span></dt><dd>
Zero disk seeks are required to read a key’s value
blob from disk, because all data in question is in the OS’s page
cache.
</dd><dt><span class="term">
Typical case
</span></dt><dd>
One seek and read is required: the file’s inode
info is cached, but the desired file page(s) is not cached.
</dd><dt><span class="term">
Worse case
</span></dt><dd>
The file system will need to perform additional seeks and
reads to read intermediate directory data, inode, and indirect storage
block data within the inode.
</dd></dl></div><p>When using Erlang API, both the “key” and “value” attributes can
use the type <code class="literal">binary()</code> as well as the <code class="literal">iodata()</code> type.  This is
convenient when you need to prepend or append blobs/bytes to existing
blobs/bytes without worrying about flattening your list or creating
new binaries.</p><pre class="screen">iodata() = iolist() | binary()
iolist() = [char() | binary() | iolist()]</pre><p>Other client access protocols are more strict about key and value
blobs: they usually must be a single <code class="literal">binary()</code> or equivalent.</p></div></div><div class="section" title="3.7.&#xA0;Setting, Getting, and Deleting Keys"><div class="titlepage"><div><div><h3 class="title"><a id="_setting_getting_and_deleting_keys"></a>3.7. Setting, Getting, and Deleting Keys</h3></div></div></div><p>As a key-value database, Hibari’s client API has only a few primitive
operations: setting, getting, and deleting keys.</p><div class="section" title="The simplest API, brick_simple"><div class="titlepage"><div><div><h4 class="title"><a id="simplest-api-brick-simple"></a>The simplest API, <code class="literal">brick_simple</code></h4></div></div></div><p>The simplest API functions, located in the Erlang <code class="literal">brick_simple</code>,
provide the following primitives:</p><div class="variablelist"><dl><dt><span class="term">
Set operations
</span></dt><dd><p class="simpara">
Create keys with operations like <code class="literal">set</code> to set a
key/value pair, <code class="literal">add</code> (assume the key does not exist), and
<code class="literal">replace</code> (assume the key does exist).
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_simple:set(TableName, Key, Value)</code>
</li><li class="listitem">
<code class="literal">brick_simple:add(TableName, Key, Value)</code>
</li><li class="listitem">
<code class="literal">brick_simple:replace(TableName, Key, Value)</code>
</li></ul></div></dd><dt><span class="term">
get operations
</span></dt><dd><p class="simpara">
<code class="literal">get</code> a single value, and <code class="literal">get_many</code> to retrieve a
  range of keys.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_simple:get(TableName, Key)</code>
</li><li class="listitem">
<code class="literal">brick_simple:get_many(TableName, StartingKey, MaxNumOfKeys)</code>
</li></ul></div></dd><dt><span class="term">
delete operation
</span></dt><dd><p class="simpara">
<code class="literal">delete</code> a key
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_simple:delete(TableName, Key)</code>
</li></ul></div></dd></dl></div><p>Each example above shows the minimal interface.  In Erlang fashion,
functions with the same name but more arguments are available when the
client wishes to override defaults.  For example, the
<code class="literal">brick_simple:set/3</code> function has defaults for the expiration time
(default = <code class="literal">0</code>), explicit flag list (default = <code class="literal">[]</code>), and explicit
timeout (default = 5000 milliseconds).</p><p>If the client wished to set the key <code class="literal">&lt;&lt;"foo"&gt;&gt;</code> with value
<code class="literal">&lt;&lt;"foovalue"&gt;&gt;</code> in the table <code class="literal">tab1</code> with an expiration time of "Sat
Apr 17 17:09:34 CDT 2010" (<code class="literal">time_t</code> representation is <code class="literal">1271542174</code>), a
single <code class="literal">flags</code> 2-tuple of <code class="literal">{x,42}</code>, and a timeout of 8 seconds,</p><pre class="literallayout">brick_simple:set(tab1, &lt;&lt;"foo"&gt;&gt;, &lt;&lt;"foovalue"&gt;&gt;, 1271542081, [{x, 42}], 8000)</pre><p>For a detailed description of each Erlang client API function and its
arguments, mandatory and optional, see <a class="xref" href="#client-api-erlang" title="4.&#xA0;Client API: Native Erlang">Section 4, “Client API: Native Erlang”</a>.</p></div><div class="section" title="The brick_simple API within the shell"><div class="titlepage"><div><div><h4 class="title"><a id="_the_literal_brick_simple_literal_api_within_the_shell"></a>The <code class="literal">brick_simple</code> API within the shell</h4></div></div></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>TODO Review this section.</p></td></tr></table></div><p>Let’s start by setting our first key.</p><pre class="screen">(hibari1@bb3)1&gt; brick_simple:set(tab1, &lt;&lt;"foo"&gt;&gt;, &lt;&lt;"Hello, world!"&gt;&gt;).
ok</pre><p>Now we’ll try to add two keys.  The first will fail because the key
<code class="literal">&lt;&lt;"foo"&gt;&gt;</code> already exists: the server will tell us the current
timestamp for the key.  Note that the timestamp, <code class="literal">1271542959131192</code>,
wasn’t given explicitly in the <code class="literal">set()</code> operation above.  This
timestamp is generated automatically by the <code class="literal">brick_simple</code> API and is
based on the OS’s system clock (i.e. wall-clock time).</p><pre class="screen">(hibari1@bb3)2&gt; brick_simple:add(tab1, &lt;&lt;"foo"&gt;&gt;, &lt;&lt;"bummer!"&gt;&gt;).
{key_exists,1271542959131192}

(hibari1@bb3)3&gt; brick_simple:add(tab1, "another", "yes!").
ok</pre><p>Now we’ll try using <code class="literal">replace</code>.  The first case will succeed this time,
but the second one will fail because the key doesn’t exist.</p><pre class="screen">(hibari1@bb3)4&gt; brick_simple:replace(tab1, "foo", "Howdy!").
ok

(hibari1@bb3)5&gt; brick_simple:replace(tab1, "not here", "ouch").
key_not_exist</pre><p>Alright, now time to try to fetch some keys.  When we fetch a key,
we’ll also get the timestamp.  Each Hibari key has a monotonically
increasing timestamp.  Clients are not permitted to set a key with a
timestamp that’s less than or equal to the current timestamp.  Most of
the <code class="literal">brick_simple</code> functions create the timestamp for you.</p><pre class="screen">(hibari1@bb3)6&gt; brick_simple:get(tab1, "foo").
{ok,1271543165272987,&lt;&lt;"Howdy!"&gt;&gt;}

(hibari1@bb3)7&gt; brick_simple:get(tab1, "does not exist").
key_not_exist</pre><p>Now we’ll try asking for many keys using the <code class="literal">get_many</code> operation.
The success return value is below.  The</p><pre class="literallayout">Return = {ok, {ListOfKeysAndValues, boolean()}}
ListOfKeysAndValues = {Key, Timestamp, Value, ExpiryTime, FlagsList}</pre><p>There aren’t any keys following the "foo" key, so the boolean returned
is <code class="literal">false</code>.</p><pre class="screen">(hibari1@bb3)8&gt; brick_simple:get_many(tab1, "", 5).
{ok,{[{&lt;&lt;"another"&gt;&gt;,1271543102911775,&lt;&lt;"yes!"&gt;&gt;,0,
       [{val_len,4}]},
      {&lt;&lt;"foo"&gt;&gt;,1271543165272987,&lt;&lt;"Howdy!"&gt;&gt;,0,[{val_len,6}]}],
     false}}</pre></div><div class="section" title="Some optional flags"><div class="titlepage"><div><div><h4 class="title"><a id="_some_optional_flags"></a>Some optional flags</h4></div></div></div><p>A list of flags can be passed to each <code class="literal">brick_simple</code> API function.
For example, if we merely want to check to see if a key has been
updated, without actually fetching the entire value blob (because that
could trigger slow, expensive disk I/O), we can use the <span class="emphasis"><em>witness</em></span>
flag.</p><pre class="screen">(hibari1@bb3)10&gt; brick_simple:get(tab1, "foo", []).
{ok,1271543165272987,&lt;&lt;"Howdy!"&gt;&gt;}

(hibari1@bb3)11&gt; brick_simple:get(tab1, "foo", [witness]).
{ok,1271543165272987}</pre><p>Another useful flag is the <code class="literal">{testset,Timestamp}</code> flag.  With this
flag, an operation can only succeed if the key’s current timestamp is
exactly equal to <code class="literal">Timestamp</code>.  Below is a case were a <code class="literal">delete()</code> call
fails because the client specifies the wrong timestamp; the server
will tell us the current timestamp.  We then resend the delete
command, using the current timestamp.</p><pre class="screen">(hibari1@bb3)12&gt; brick_simple:delete(tab1, "foo", [{testset, 4321}]).
{ts_error,1271543165272987}

(hibari1@bb3)13&gt; brick_simple:delete(tab1, "foo", [{testset, 1271543165272987}]).
ok</pre></div><div class="section" title="The do API via brick_simple"><div class="titlepage"><div><div><h4 class="title"><a id="do-api-via-brick-simple"></a>The <code class="literal">do</code> API via <code class="literal">brick_simple</code></h4></div></div></div><p>A Hibari client can send a list of primitive ops in the same API call.
They will be executed at the same time by a Hibari brick.  If the
client requests micro-transaction semantics, then all operations in
the list will be executed with transaction semantics: either all
operations will be executed successfully or none will be executed.</p><p>All Hibari operations using <code class="literal">brick_simple:do()</code> API must follow
certain rules:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
All operations manipulate keys in the same table
</li><li class="listitem">
All operations manipulate keys within the same chain
</li><li class="listitem">
All operations in the transaction must be sent in a single
  <code class="literal">brick_simple:do()</code> call.  Unlike many other databases, it is not
  possible to request a transaction handle and to add operations to
  that transaction in an one-by-one, "ad hoc" manner.
</li></ul></div><p>See the
<a class="ulink" href="hibari-sysadmin-guide.en.html#chain-lifecycle-fsm" target="_top">Hibari Sysadmin
Guide, "Chain Lifecycle Finite State Machine" section</a>
for chain replication implementation details and limits.</p><p>In truth, the calls demonstrated above such as <code class="literal">brick_simple:set()</code>
use the <code class="literal">brick_simple:do()</code> API function: they have a hard-coded
operation list that is exactly one operation long.  However, it’s
possible for clients to create their own operation lists when needed.</p><p>For each basic brick operation, there is a corresponding function in
the <code class="literal">brick_server</code> module to create a <code class="literal">do()</code> operation primitive:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_server:make_set(Key, Value)</code>
</li><li class="listitem">
<code class="literal">brick_server:make_add(Key, Value)</code>
</li><li class="listitem">
<code class="literal">brick_server:make_replace(Key, Value)</code>
</li><li class="listitem">
<code class="literal">brick_server:make_get(Key)</code>
</li><li class="listitem">
<code class="literal">brick_server:make_get_many(StartingKey, MaxNumOfKeys)</code>
</li><li class="listitem">
<code class="literal">brick_server:make_delete(Key)</code>
</li></ul></div><p title="Example do() call with two primitive operations"><a id="example-complex-do-call"></a><b>Example <code class="literal">do()</code> call with two primitive operations. </b>
</p><pre class="screen">(hibari1@bb3)16&gt; Do1 = brick_server:make_get("another").
{get,&lt;&lt;"another"&gt;&gt;,[]}
(hibari1@bb3)17&gt; Do2 = brick_server:make_get("not exist").
{get,&lt;&lt;"not exist"&gt;&gt;,[]}
(hibari1@bb3)18&gt; brick_simple:do(tab1, [Do1, Do2]).
[{ok,1271543102911775,&lt;&lt;"yes!"&gt;&gt;},key_not_exist]</pre><p title="Example do() call with two primitive operations">
</p></div><div class="section" title="Making a micro-transaction request"><div class="titlepage"><div><div><h4 class="title"><a id="micro-transaction-request-example"></a>Making a micro-transaction request</h4></div></div></div><p>The <code class="literal">brick_simple:do()</code> API must be used to request a
micro-transaction.  (There isn’t a need to have micro-transaction
semantics for most of the <code class="literal">brick_simple</code> API functions, because they
only support a single operation.)  If the first operation in the
<code class="literal">do()</code> function’s operation list is <code class="literal">brick_server:make_txn()</code>, then
the remainder of the list will execute as a transaction.</p><p>Here is a simple example:</p><pre class="screen">(hibari1@bb3)16&gt; Do1 = brick_server:make_get("another").
{get,&lt;&lt;"another"&gt;&gt;,[]}
(hibari1@bb3)17&gt; Do2 = brick_server:make_get("not exist").
{get,&lt;&lt;"not exist"&gt;&gt;,[]}
(hibari1@bb3)18&gt; brick_simple:do(tab1, [Do1, Do2]).
[{ok,1271543102911775,&lt;&lt;"yes!"&gt;&gt;},key_not_exist]</pre><p>The key "not exist" doesn’t exist, but that will not abort the
transaction.  If we include an operation flag that can cause a
micro-transaction to abort, then we’ll see a very different return
result.</p><pre class="screen">(hibari1@bb3)20&gt; Do2b = brick_server:make_get("not exist", [must_exist]).
{get,&lt;&lt;"not exist"&gt;&gt;,[must_exist]}
(hibari1@bb3)21&gt; brick_simple:do(tab1, [brick_server:make_txn(), Do1, Do2b]).
{txn_fail,[{2,key_not_exist}]}</pre><p>In this example, we requested a full transaction.  The server told us
that operation #2 (i.e. the second operation after the <code class="literal">make_txn()</code>
operation) failed because the key doesn’t exist.</p><p>For a detailed description of the per-operation flags and their
effects within micro-transactions, see <a class="xref" href="#client-api-erlang" title="4.&#xA0;Client API: Native Erlang">Section 4, “Client API: Native Erlang”</a>.</p></div></div><div class="section" title="3.8.&#xA0;Creating New Tables"><div class="titlepage"><div><div><h3 class="title"><a id="_creating_new_tables"></a>3.8. Creating New Tables</h3></div></div></div><p>Creating a new table is easiest via the Admin Server’s HTTP status
page: see the "Add a table" link at the bottom of <code class="literal">http://localhost:23080/</code></p><div class="variablelist"><dl><dt><span class="term">
Local (boolean)
</span></dt><dd>
If true, all bricks will be created on the local node, i.e. the node
that’s running the Admin Server.  If false, then the "NodeList" field
is used to specify which cluster nodes the new bricks should use.
</dd><dt><span class="term">
BigData (boolean)
</span></dt><dd>
If true, value blobs will be stored on disk.
</dd><dt><span class="term">
DiskLogging (boolean)
</span></dt><dd>
If true, all updates will be written to the write-ahead log for
persistence.  If false, bricks will run faster but at the expense of
data loss in a cluster-wide power failure.
</dd><dt><span class="term">
SyncWrites (boolean)
</span></dt><dd>
If true, all writes to the write-ahead log will be flushed to stable
storage via the <code class="literal">fsync(2)</code> system call.  If false, bricks will run
faster but at the expense of data loss in a cluster-wide power
failure.
</dd><dt><span class="term">
VarPrefix (boolean)
</span></dt><dd><p class="simpara">
If true, then a variable-length prefix of the key will be used as
input for the consistent hashing function.  If false, the entire key
will be used.
</p><p class="simpara">Many applications can benefit from using a variable-length of
fixed-length prefix hashing scheme.  As an example, consider an
application that maintains state for various users.  The app wishes to
use micro-transactions to update various keys (in the same table)
related to that user.  The table can be created to use
<code class="literal">VarPrefix=true</code>, together with <code class="literal">VarPrefixSeparator=47</code> (ASCII 47 is
the forward slash character) and
<code class="literal">VarPrefixNumSeparator=2</code>, to create a hashing scheme that will
guarantee that keys <code class="literal">/FooUser/summary</code> and <code class="literal">/FooUser/thing1</code> and
<code class="literal">/FooUser/thing9</code> are all stored by the same chain.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The HTTP interface for creating tables does not expose the
fixed-length key prefix scheme.  The Erlang API must be used in this
case.</p></td></tr></table></div></dd><dt><span class="term">
VarPrefixSeparator (integer)
</span></dt><dd>
Define the character used for variable-length key prefix calculation.
Note that the default value of ASCII 47 (the "/" character), or any
other character, does not imply any UNIX/POSIX style file or directory
semantics.
</dd><dt><span class="term">
VarPrefixNumSeparators (integer)
</span></dt><dd>
Define the number of <code class="literal">VarPrefixSeparator</code> bytes, and all bytes in
between, used for consistent hashing.  If <code class="literal">VarPrefixSeparator=47</code> and
<code class="literal">VarPrefixNumSeparators=3</code>, then for a key such as <code class="literal">/foo/bar/baz</code>, the
prefix used for consistent hashing will be <code class="literal">/foo/bar/</code>.
</dd><dt><span class="term">
Bricks (integer)
</span></dt><dd>
If <code class="literal">Local=true</code> (see above), then this integer defines the total
number of logical bricks that will be created on the local node.  This
value is ignored if <code class="literal">Local=false</code>.
</dd><dt><span class="term">
BPC (integer)
</span></dt><dd><p class="simpara">
Define the number of bricks per chain.
</p><p class="simpara">The algorithm used for creating chain → brick mapping is based on a
"striping" principle: enough chains are laid across bricks in a
stripe-wise manner so that all nodes (aka physical bricks) will have
the same number of logical bricks in head, middle, and tail roles.
See the example in the Hibari Sysadmin Guide of
<a class="ulink" href="hibari-sysadmin-guide.en.html#3-chains-striped-across-3-bricks" target="_top">3
chains striped across three nodes</a>.</p><p class="simpara">The Erlang API must be used to create tables with other chain layout
patterns.</p></dd><dt><span class="term">
NodeList (comma-separated string)
</span></dt><dd>
If <code class="literal">Local=false</code>, specify the list of nodes that will run logical
bricks for the new table.  Each node in the comma-separated list
should take the form <code class="literal">NodeName@HostName</code>.  For example,
use <code class="literal">hibari1@machine-a, hibari1@machine-b, hibari1@machine-c</code> to specify
three nodes.
</dd><dt><span class="term">
NumNodesPerBlock (integer)
</span></dt><dd><p class="simpara">
If <code class="literal">Local=false</code>, then this integer will affect the striping behavior
of the default chain striping algorithm.  This value must be
zero (i.e. this parameter is ignored) or a multiple of the <code class="literal">BPC</code> parameter.
</p><p class="simpara">For example, if <code class="literal">NodeList</code>
contains nodes A, B, C, D, E, and F, then the
following striping patterns would be used:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">NumNodesPerBlock=0</code> would stripe across all 6 nodes for 6 chains
    total.
</li><li class="listitem">
<code class="literal">NumNodesPerBlock=2</code> and <code class="literal">BPC=2</code> would stripe 2 chains across nodes
    A &amp; B, 2 chains across C &amp; D, and 2 chains across E &amp; F.
</li><li class="listitem">
<code class="literal">NumNodesPerBlock=3</code> and <code class="literal">BPC=3</code> would stripe 3 chains across nodes
    A &amp; B &amp; C and 3 chains across D &amp; E &amp; F.
</li></ul></div></dd><dt><span class="term">
BlockMultFactor (integer)
</span></dt><dd><p class="simpara">
If <code class="literal">Local=false</code>, then this integer will affect the striping behavior
of the default chain striping algorithm.  This value must be
zero (i.e. this parameter is ignored) or greater than zero.
</p><p class="simpara">For example, if <code class="literal">NodeList</code>
contains nodes A, B, C, D, E, and F, then the
following striping patterns would be used:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">NumNodesPerBlock=0</code> and <code class="literal">BlockMultFactor=0</code> would stripe across
    all 6 nodes for 6 chains total.
</li><li class="listitem">
<code class="literal">NumNodesPerBlock=2</code> and <code class="literal">BlockMultFactor=5</code> and <code class="literal">BPC=2</code> would
    stripe 2*5=10 chains across nodes A &amp; B, 2*5=10 chains across C &amp;
    D, and 2*5=10 chains across E &amp; F, for a total of 30 chains.
</li><li class="listitem">
<code class="literal">NumNodesPerBlock=3</code> and <code class="literal">BlockMultFactor=4</code> and <code class="literal">BPC=3</code> would
    stripe 3*4=12 chains across nodes A &amp; B &amp; C and 3*4=12 chains across
    D &amp; E &amp; F, for a total of 24 chains.
</li></ul></div></dd></dl></div></div><div class="section" title="3.9.&#xA0;Changing Chain Length"><div class="titlepage"><div><div><h3 class="title"><a id="changing-chain-length"></a>3.9. Changing Chain Length</h3></div></div></div><p>The Admin Server’s basic definition of a chain: the chains name, and
the list of bricks.  In turn, each brick is defined by a 2-tuple of
brick name and node name.</p><pre class="screen">Chain definition = {ChainName, [BrickDef1, BrickDef2, ...]}
Brick definition = {BrickName, NodeName}

Example chain definition, chain length=1
    {tab1_ch1, [{tab1_ch1_b1, hibari1@bb3}]}</pre><p>The function <code class="literal">brick_admin:get_table_chain_list/1</code> will retrieve the
active chain definition list for a table.  For example, we retrieve the
chain definition list for the table <code class="literal">tab1</code>.  The node <code class="literal">bb3</code> is the
hostname of my laptop.</p><pre class="screen">(hibari1@bb3)23&gt; {ok, Tab1ChList} = brick_admin:get_table_chain_list(tab1).
{ok,[{tab1_ch1,[{tab1_ch1_b1,hibari1@bb3}]}]}

(hibari1@bb3)24&gt; Tab1ChList.
[{tab1_ch1,[{tab1_ch1_b1,hibari1@bb3}]}]</pre><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The <code class="literal">brick_admin:get_table_chain_list/1</code> function will retrieve
the active chain definition list for a table: only bricks that are in
<code class="literal">ok</code> state will be shown.  If a chain has a brick that has crashed,
that brick will not appear in the list returned by this function.  The
<code class="literal">brick_admin:get_table_info()</code> function can fetch the list of all
bricks, in service and crashed, but the API is not as convenient.</p></td></tr></table></div><p><a id="example-change-chain-length"></a>To change the chain length, use the
<code class="literal">brick_admin:change_chain_length/2</code> function.  The arguments are the
chain name and brick list.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Any bricks in the brick list that aren’t in the chain are
automatically started. Any bricks in the current chain that are not in
the new list are halted, <span class="strong"><strong>and their persistent data will be deleted</strong></span>.</p></td></tr></table></div><pre class="screen">(hibari1@bb3)29&gt; brick_admin:change_chain_length(tab1_ch1,
                 [{tab1_ch1_b1,hibari1@bb3}, {tab1_ch1_b2,hibari1@bb3}]).
ok

(hibari1@bb3)30&gt; {ok, Tab1ChList2} = brick_admin:get_table_chain_list(tab1). {ok,[{tab1_ch1,[{tab1_ch1_b1,hibari1@bb3},
                {tab1_ch1_b2,hibari1@bb3}]}]}</pre><p>Now the <code class="literal">tab1_ch1</code> chain has length two.  We’ll shorten it back down
to length 1.</p><pre class="screen">(hibari1@bb3)31&gt; brick_admin:change_chain_length(tab1_ch1, [{tab1_ch1_b2,hibari1@bb3}]).
ok

(hibari1@bb3)32&gt; {ok, Tab1ChList3} = brick_admin:get_table_chain_list(tab1).
{ok,[{tab1_ch1,[{tab1_ch1_b2,hibari1@bb3}]}]}</pre><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>A chain’s new brick list must contain at least one brick from
the current chain’s definition.  If the intersection of old brick list
and new brick list is empty, the command will fail.</p></td></tr></table></div><pre class="screen">(hibari1@bb3)34&gt; brick_admin:change_chain_length(tab1_ch1, [{tab1_ch1_b3,hibari1@bb3}]).
{'EXIT',{error,no_intersection}}</pre></div><div class="section" title="3.10.&#xA0;Creating New/Deleting Current/Reweighting/Rehashing Chains"><div class="titlepage"><div><div><h3 class="title"><a id="changing-chains-example"></a>3.10. Creating New/Deleting Current/Reweighting/Rehashing Chains</h3></div></div></div><p>The procedure for creating new chains, deleting existing chains, and
reweighing existing chains, and rehashing is done using the the
<code class="literal">brick_admin:start_migration()</code> function.  The chain definitions are
specified in the same way as changing chain lengths, see
<a class="xref" href="#changing-chain-length" title="3.9.&#xA0;Changing Chain Length">Section 3.9, “Changing Chain Length”</a> for details.</p><p>The data structure required by <code class="literal">brick_admin:start_migration/2</code> is more
complex than the relatively-simple brick list that
<code class="literal">brick_admin:change_chain_length/2</code> requires.  This section will
demonstrate the creation of this structure, the “local hash record”,
step-by-step.</p><p>First, we create a new chain definition list.  (Refer to
<a class="xref" href="#changing-chain-length" title="3.9.&#xA0;Changing Chain Length">Section 3.9, “Changing Chain Length”</a> if necessary.)  For this example, we’ll
assume that we’ll be modifying the <code class="literal">tab1</code> table and that we’ll be
adding two more chains.  Each chain will be of length one.  We’ll
place each chain on the same node as everything else, <code class="literal">hibari1@bb3</code>
(i.e. my laptop).</p><pre class="screen">(hibari1@bb3)48&gt; brick_admin:get_table_chain_list(tab1).
{ok,[{tab1_ch1,[{tab1_ch1_b1,hibari1@bb3}]}]}

(hibari1@bb3)49&gt; NewCL = [{tab1_ch1, [{tab1_ch1_b1, hibari1@bb3}]},
                 {tab1_ch2, [{tab1_ch2_b1, hibari1@bb3}]},
                 {tab1_ch3, [{tab1_ch3_b1, hibari1@bb3}]}].
[{tab1_ch1,[{tab1_ch1_b1,hibari1@bb3}]},
 {tab1_ch2,[{tab1_ch2_b1,hibari1@bb3}]},
 {tab1_ch3,[{tab1_ch3_b1,hibari1@bb3}]}]</pre><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Any bricks in the brick list that aren’t in a chain are
automatically started.  Any bricks in a current chains that are not in
the chain definition are halted, <span class="strong"><strong>and their persistent data will be
deleted</strong></span>.</p></td></tr></table></div><p>Next, we retrieve the table’s current hashing configuration.  The data
is returned to us in the form of an Erlang property list.  (See the
Erlang/OTP documentation for the <code class="literal">proplists</code> module, located in the
"Basic Applications" area under "stdlib".)  We then pick out several
properties that we’ll need later; we use <code class="literal">lists:keyfind/3</code> instead of
a function in the <code class="literal">proplists</code> module because it will preserve the
properties in 2-tuple form, which will save us some typing effort
later.</p><pre class="screen">(hibari1@bb3)51&gt; {ok, TabInfo} = brick_admin:get_table_info(tab1).
{ok,[{name,tab1},
    ...lots of stuff omitted...

(hibari1@bb3)53&gt; Opts = proplists:get_value(brick_options, TabInfo).
[{hash_init,#Fun&lt;brick_hash.chash_init.3&gt;},
 {old_float_map,[]},
 {new_chainweights,[{tab1_ch1,100}]},
 {hash_init,#Fun&lt;brick_hash.chash_init.3&gt;},
 {prefix_method,var_prefix},
 {prefix_separator,47},
 {num_separators,3},
 {bigdata_dir,"cwd"},
 {do_logging,true},
 {do_sync,true},
 {created_date,{2010,4,17}},
 {created_time,{17,21,58}}]

(hibari1@bb3)58&gt; PrefixMethod = lists:keyfind(prefix_method, 1, Opts).
{prefix_method,var_prefix}

(hibari1@bb3)59&gt; NumSep = lists:keyfind(num_separators, 1, Opts).
{num_separators,3}

(hibari1@bb3)60&gt; PrefixSep = lists:keyfind(prefix_separator, 1, Opts).
{prefix_separator,47}

(hibari1@bb3)61&gt; OldCWs = proplists:get_value(new_chainweights, Opts).
[{tab1_ch1,100}]

(hibari1@bb3)62&gt; OldGH = proplists:get_value(ghash, TabInfo).

(hibari1@bb3)63&gt; OldFloatMap = brick_hash:chash_extract_new_float_map(OldGH).</pre><p>Next, we create a new property list.</p><pre class="screen">(hibari1@bb3)71&gt; NewCWs = OldCWs ++ [{tab1_ch2, 100}, {tab1_ch3, 100}].
[{tab1_ch1,100},{tab1_ch2,100},{tab1_ch3,100}]

(hibari1@bb3)72&gt; NewOpts = [PrefixMethod, NumSep, PrefixSep,
                               {new_chainweights, NewCWs},
                               {old_float_map, OldFloatMap}].
[{prefix_method,var_prefix},
 {num_separators,3},
 {prefix_separator,47},
 {new_chainweights,[{tab1_ch1,100},
                    {tab1_ch2,100},
                    {tab1_ch3,100}]}
 {old_float_map, []}]</pre><p>Next, we use the chain definition list, <code class="literal">NewCL</code>, and the table options
list, <code class="literal">NewOpts</code>, to create a “local hash” record.  This record will
contain all of the configuration information required to change a
table’s consistent hashing characteristics.</p><pre class="screen">(hibari1@bb3)73&gt; NewLH = brick_hash:chash_init(via_proplist, NewCL, NewOpts).
{hash_r,chash,brick_hash,chash_key_to_chain,
 ...lots of stuff omitted...</pre><p><a id="chash-migration-pre-check"></a>We’re just one step away from changing the <code class="literal">tab1</code> table.  Before we
change the table, however, we’d like to see how the table change will
affect the data in the table.  First, we add 1,000 keys to the <code class="literal">tab1</code>
table.  Then we use the <code class="literal">brick_simple:chash_migration_pre_check/2</code>
function to tell us how many keys will move and to where.</p><pre class="screen">(hibari1@bb3)74&gt; [brick_simple:set(tab1, "foo"++integer_to_list(X), "bar") || X &lt;- lists:seq(1,1000)].
[ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,ok,
 ok,ok,ok,ok,ok,ok,ok,ok,ok,ok|...]

(hibari1@bb3)75&gt; brick_simple:chash_migration_pre_check(tab1, NewLH).
[{keys_before,[{tab1_ch1,1001}]},
 {keys_keep,[{tab1_ch1,348}]},
 {keys_moving,[{tab1_ch2,315},{tab1_ch3,338}]},
 {keys_moving_where,[{tab1_ch1,[{tab1_ch2,315},
                                {tab1_ch3,338}]}]},
 {errors,[]}]</pre><p>The output above shows us that of the 1,001 keys in the <code class="literal">tab1</code> table,
348 will remain in the <code class="literal">tab1_ch1</code> chain, 315 keys will move to the
<code class="literal">tab1_ch2</code> chain, and 338 keys will move to the <code class="literal">tab1_ch3</code> chain.
That looks like what we want, so let’s reconfigure the table and start
the data migration.</p><pre class="screen">brick_admin:start_migration(tab1, NewLH).</pre><p>Immediately, we’ll see a bunch of application messages sent to the
console as new activities start:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A migration monitoring process is started.
</li><li class="listitem">
New brick processes are started.
</li><li class="listitem">
New monitoring processes are started.
</li><li class="listitem">
Data migrations are started and finish
</li><li class="listitem">
The migration monitoring process exits.
</li></ul></div><pre class="screen">=GMT INFO REPORT==== 20-Apr-2010::00:26:40 ===
Migration number 1 is starting with cookie {1271,741200,988900}

=GMT INFO REPORT==== 20-Apr-2010::00:26:41 ===
progress: [{supervisor,{local,brick_mon_sup}},
           {started,
               [{pid,&lt;0.2937.0&gt;},
                {name,chmon_tab1_ch2},
                ...stuff omitted...

[...lines skipped...]
=GMT INFO REPORT==== 20-Apr-2010::00:26:41 ===
Migration monitor: tab1: chains starting

[...lines skipped...]
=GMT INFO REPORT==== 20-Apr-2010::00:26:41 ===
brick_admin: handle_cast: chain tab1_ch2 in unknown state

[...lines skipped...]
=GMT INFO REPORT==== 20-Apr-2010::00:26:52 ===
Migration monitor: tab1: sweeps starting

[...lines skipped...]
=GMT INFO REPORT==== 20-Apr-2010::00:26:54 ===
Migration number 1 finished

[...lines skipped...]
=GMT INFO REPORT==== 20-Apr-2010::00:26:57 ===
Clearing final migration state for table tab1</pre><p>For the sake of demonstration, now let’s see what
<code class="literal">brick_simple:chash_migration_pre_check()</code> would say if we were to
migrate from three chains to four chains.</p><pre class="screen">(hibari_dev@bb3)24&gt; {ok, TabInfo3} = brick_admin:get_table_info(tab1).

(hibari_dev@bb3)25&gt; Opts3 = proplists:get_value(brick_options, TabInfo3).

(hibari_dev@bb3)26&gt; GH3 = proplists:get_value(ghash, TabInfo3).

(hibari_dev@bb3)28&gt; OldFloatMap = brick_hash:chash_extract_new_float_map(GH3).

(hibari_dev@bb3)31&gt; NewOpts4 = [PrefixMethod, NumSep, PrefixSep,
                    {new_chainweights, NewCWs4}, {old_float_map, OldFloatMap}].

(hibari_dev@bb3)35&gt; NewCL4 = [ {tab1_ch1, [{tab1_ch1_b1, hibari1@bb3}]},
                               {tab1_ch2, [{tab1_ch2_b1, hibari1@bb3}]},
                               {tab1_ch3, [{tab1_ch3_b1, hibari1@bb3}]},
                               {tab1_ch4, [{tab1_ch4_b1, hibari1@bb3}]} ].
(hibari_dev@bb3)36&gt; NewLH4 = brick_hash:chash_init(via_proplist, NewCL4, NewOpts4).

(hibari_dev@bb3)37&gt; brick_simple:chash_migration_pre_check(tab1, NewLH4).
[{keys_before,[{tab1_ch1,349},
               {tab1_ch2,315},
               {tab1_ch3,337}]},
 {keys_keep,[{tab1_ch1,250},{tab1_ch2,232},{tab1_ch3,232}]},
 {keys_moving,[{tab1_ch4,287}]},
 {keys_moving_where,[{tab1_ch1,[{tab1_ch4,99}]},
                     {tab1_ch2,[{tab1_ch4,83}]},
                     {tab1_ch3,[{tab1_ch4,105}]}]},
 {errors,[]}]</pre><p>The output tells us that chain <code class="literal">tab1_ch1</code> will lose 99 keys,
<code class="literal">tab1_ch2</code> will lose 83 keys, and <code class="literal">tab1_ch3</code> will lose 105 keys.  The
final key distribution across the four chains would be 250, 232, 232,
and 287 keys, respectively.</p></div></div><div class="section" title="4.&#xA0;Client API: Native Erlang"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="client-api-erlang"></a>4. Client API: Native Erlang</h2></div></div></div><div class="variablelist"><dl><dt><span class="term">
Data types
</span></dt><dd>
See <a class="xref" href="#erlang-data-types-single" title="4.1.&#xA0;Erlang data types for single-operation brick_simple API">Section 4.1, “Erlang data types for single-operation <code class="literal">brick_simple</code> API”</a> and
  <a class="xref" href="#erlang-data-types-multi" title="4.2.&#xA0;Erlang data types for multi-operation API">Section 4.2, “Erlang data types for multi-operation API”</a>
</dd><dt><span class="term">
Insert operations
</span></dt><dd>
See <a class="xref" href="#brick-simple-add" title="brick_simple:add()">the section called “brick_simple:add()”</a>, <a class="xref" href="#brick-simple-replace" title="brick_simple:replace()">the section called “brick_simple:replace()”</a>,
  <a class="xref" href="#brick-simple-set" title="brick_simple:set()">the section called “brick_simple:set()”</a>
</dd><dt><span class="term">
Retrieve operations
</span></dt><dd>
See <a class="xref" href="#brick-simple-get" title="brick_simple:get()">the section called “brick_simple:get()”</a> and
  <a class="xref" href="#brick-simple-get-many" title="brick_simple:get_many()">the section called “brick_simple:get_many()”</a>
</dd><dt><span class="term">
Delete operation
</span></dt><dd>
See <a class="xref" href="#brick-simple-delete" title="brick_simple:delete()">the section called “brick_simple:delete()”</a>
</dd><dt><span class="term">
Multiple operations
</span></dt><dd>
See <a class="xref" href="#brick-simple-do" title="brick_simple:do(), with or without transaction">the section called “brick_simple:do(), with or without transaction”</a>
</dd><dt><span class="term">
Micro-transactions
</span></dt><dd>
See <a class="xref" href="#brick-simple-do" title="brick_simple:do(), with or without transaction">the section called “brick_simple:do(), with or without transaction”</a>
</dd></dl></div><div class="section" title="4.1.&#xA0;Erlang data types for single-operation brick_simple API"><div class="titlepage"><div><div><h3 class="title"><a id="erlang-data-types-single"></a>4.1. Erlang data types for single-operation <code class="literal">brick_simple</code> API</h3></div></div></div><p>The data types defined in this section are cumulative, meaning that
they may refer to a type defined in an earlier section.  For example,
<a class="xref" href="#erlang-data-types-single-call" title="Data types for Hibari client single-operation call arguments">Data types for Hibari client single-operation call arguments</a> refers to the <code class="literal">proplist()</code> type
that is defined in <a class="xref" href="#erlang-data-types-single-return" title="Data types used for Hibari client single-operation return values">Data types used for Hibari client single-operation return values</a>.</p><p title="Data types for Hibari client single-operation call arguments"><a id="erlang-data-types-single-call"></a><b>Data types for Hibari client single-operation call arguments. </b>
</p><pre class="screen">do_flag()      = 'fail_if_wrong_role' |
                 'ignore_role'
do_op_flag()   = {'binary_prefix', binary()} |
                 'get_all_attribs' |
                 {'max_bytes', integer()} |
                 {'max_num', integer()} |
                 'must_exist' |
                 'must_not_exist' |
                 {'testset', timestamp()} |
                 'value_in_ram' |
                 'witness'
expiry()       = time_t()
flags_list()   = [do_op_flag() | property()]
iodata()       = iolist() | binary()
iolist()       = [char() | binary() | iolist()]
key()          = iodata()
proplist()     = [property()]
property()     = atom() |
                 {term(), term()}
table()        = atom()
time_t()       = integer()
timeout()      = integer() |
                 'infinity'
timestamp()    = integer()
val()          = iodata()</pre><p title="Data types for Hibari client single-operation call arguments">
</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Key/Value are erlang binary or iolist type.
But they are converted into binary before actual data API operation.</p><p>For example, followings have same effect.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">Key = "key1"</code>
</li><li class="listitem">
<code class="literal">Key = ["key", "1"]</code>
</li><li class="listitem">
<code class="literal">Key = &lt;&lt;"key1"&gt;&gt;</code>
</li><li class="listitem">
<code class="literal">Key = [&lt;&lt;"key"&gt;&gt;, &lt;&lt;"1"&gt;&gt;]</code>
</li><li class="listitem">
<code class="literal">Key = ["ke", [&lt;&lt;"y"&gt;&gt;, "1"]]</code>
</li></ul></div></td></tr></table></div><p title="Data types used for Hibari client single-operation return values"><a id="erlang-data-types-single-return"></a><b>Data types used for Hibari client single-operation return values. </b>
</p><pre class="screen">do1_res_ok()   = 'ok' |
                 'key_exists' |
                 'key_not_exist' |
                 {ok, val()} |
                 {ok, ts()} |
                 {ok, ts(), val()} |
                 {ok, ts(), proplist()} |
                 {ok, ts(), val(), time_t(), proplist()} |
                 {ok, {[{key(), ts()}], boolean()}} |
                 {ok, {[{key(), ts(), proplist()}], boolean()}} |
                 {ok, {[{key(), ts(), val(), time_t(), proplist()}], boolean()}}
do1_otherres() = 'invalid_flag_present' |
                 'brick_not_available' |
                 {{'nodedown',node()},{'gen_server','call',term()}};
do1_res_fail() = {'key_exists', ts()} |
                 'key_not_exist' |
                 {'ts_error', ts()} |
                 do1_otherres();</pre><p title="Data types used for Hibari client single-operation return values">
</p></div><div class="section" title="4.2.&#xA0;Erlang data types for multi-operation API"><div class="titlepage"><div><div><h3 class="title"><a id="erlang-data-types-multi"></a>4.2. Erlang data types for multi-operation API</h3></div></div></div><p>The types for the <code class="literal">do()</code> call differ from the single-operation API.
The client creates a list of <code class="literal">do</code> primitive operations and then sends
the entire list in a single <code class="literal">do()</code> call.</p><p>In response, the server will (normally) return a list of
<code class="literal">do1_res_ok()</code> and <code class="literal">do1_res_fail()</code> types, one for each of the
primitive operations in the client’s call.  See
<a class="xref" href="#example-complex-do-call" title="Example do() call with two primitive operations">Example <code class="literal">do()</code> call with two primitive operations</a> that returns a list of two
<code class="literal">do1_res_ok()</code> responses.</p><p title="Data types for Hibari client multi-operation call arguments"><a id="erlang-data-types-multi-call"></a><b>Data types for Hibari client multi-operation call arguments. </b>
</p><pre class="screen">%% Primitive ops created by:
%% brick_server:make_add(), brick_server:make_delete(), et al.
add()          = {'add',      key(), ts(), val(), expiry(),   flags_list()}
delete()       = {'delete',   key(),                          flags_list()}
get()          = {'get',      key(),                          flags_list()}
get_many()     = {'get_many', key(),                          flags_list()}
replace()      = {'replace',  key(), ts(), val(), expiry(),   flags_list()}
set()          = {'set',      key(), ts(), val(), expiry(),   flags_list()}
txn()          = 'txn'

do1_op()       = add() | delete() | get() | get_many() | replace() | set()

do_flags_list()= [do_flag()]
do_op_list()   = [do1_op()]
do_res()       = [do1_res_ok() |
                  do1_res_fail()] |
                 do_res_fail()
do_res_fail    = {txn_fail, [{integer(), do1_res_fail()}]}</pre><p title="Data types for Hibari client multi-operation call arguments">
</p></div><div class="section" title="4.3.&#xA0;Notes on Operation Flags"><div class="titlepage"><div><div><h3 class="title"><a id="notes-on-operation-flags"></a>4.3. Notes on Operation Flags</h3></div></div></div><p>The meaning of each of the elements in the <code class="literal">do_op_flag()</code> type are
described below.</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">{binary_prefix, Bin::binary()}</code>
</span></dt><dd>
For use with the <code class="literal">get_many</code> operation, return only keys that have a
binary prefix that is exactly equal to <code class="literal">Bin</code>.
</dd><dt><span class="term">
<code class="literal">get_all_attribs</code>
</span></dt><dd>
For use with the <code class="literal">get</code> and <code class="literal">get_many</code> operations, return all
attributes of the key, including expiration time.  May be used in
combination with the <code class="literal">witness</code> flag.
</dd><dt><span class="term">
<code class="literal">{max_bytes, Max::integer()}</code>
</span></dt><dd>
For use with the <code class="literal">get_many</code> operation, return only as many keys as the
sum of the sizes of their corresponding value blobs exceeds <code class="literal">Max</code>.
</dd><dt><span class="term">
<code class="literal">{max_num, Num::integer()}</code>
</span></dt><dd>
For use with the <code class="literal">get_many</code> operation, return at most <code class="literal">Num</code> keys.
</dd><dt><span class="term">
<code class="literal">must_exist</code>
</span></dt><dd>
For use with <code class="literal">get</code> and <code class="literal">delete</code> operations inside a micro-transaction,
abort the transaction if the key exists.
</dd><dt><span class="term">
<code class="literal">must_not_exist</code>
</span></dt><dd>
For use with <code class="literal">get</code> and <code class="literal">delete</code> operations inside a micro-transaction,
abort the transaction if the key does not exist.
</dd><dt><span class="term">
<code class="literal">{testset, TS::timestamp()}</code>
</span></dt><dd>
For use with all operations except <code class="literal">get_many</code>, fail the operation if
the existing key’s timestamp is not exactly equal to <code class="literal">TS</code>.  If used
inside a micro-transaction, abort the transaction if the timestamp is
not exactly equal to <code class="literal">TS</code>.
</dd><dt><span class="term">
<code class="literal">value_in_ram</code>
</span></dt><dd>
For use with the <code class="literal">add</code>, <code class="literal">replace</code>, and <code class="literal">set</code> operations, store the
value blob in RAM, overriding the default storage location of the
brick.  NOTE: This flag has not yet been extensively testing and
evaluated by Gemini QA.
</dd><dt><span class="term">
<code class="literal">witness</code>
</span></dt><dd>
For use with the <code class="literal">get</code> and <code class="literal">get_many</code> operations, do not return the
value blob in the result.  This flag will guarantee that the brick
does not require disk access to satisfy this request.
</dd></dl></div></div><div class="section" title="4.4.&#xA0;Notes on Return Values"><div class="titlepage"><div><div><h3 class="title"><a id="notes-on-return-values"></a>4.4. Notes on Return Values</h3></div></div></div><div class="variablelist"><dl><dt><span class="term">
<code class="literal">brick_not_available</code>
</span></dt><dd>
The operation failed because the chain that is responsible for this
key is currently length zero and therefore unavailable.
</dd><dt><span class="term">
<code class="literal">invalid_flag_present</code>
</span></dt><dd>
The operation failed because an invalid <code class="literal">do_op_flag()</code> was found in
the <code class="literal">DoFlags</code> argument.
</dd><dt><span class="term">
<code class="literal">key_exists</code>
</span></dt><dd>
The operation failed because the key already exists.
</dd><dt><span class="term">
<code class="literal">key_not_exist</code>
</span></dt><dd>
The operation failed because the key does not exist.
</dd><dt><span class="term">
<code class="literal">{{'nodedown',node()},{'gen_server','call',term()}}</code>
</span></dt><dd>
The operation failed because the server brick handling the request has
crashed or else a network partition has occurred between the client
and server.  The client should resend the the query after a short
delay, on the assumption that the Admin Server will have detected the
failure and taken steps to repair the chain.
</dd><dt><span class="term">
<code class="literal">ok</code> and tuples with <code class="literal">ok</code> atoms in their first position
</span></dt><dd>
The operation was successful.
</dd><dt><span class="term">
<code class="literal">{ts_error, TS}</code>
</span></dt><dd>
The operation failed because of a timestamp error.  The integer <code class="literal">TS</code>
is the current value of the key’s timestamp.
</dd></dl></div></div><div class="section" title="4.5.&#xA0;Single-Operation API"><div class="titlepage"><div><div><h3 class="title"><a id="_single_operation_api"></a>4.5. Single-Operation API</h3></div></div></div><div class="section" title="brick_simple:add()"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-add"></a>brick_simple:add()</h4></div></div></div><pre class="screen">add(Tab, Key, Value)
  Equivalent to add(Tab, Key, Value, 0, [], 15000)

add(Tab, Key, Value, Flags) when is_list(Flags)
  Equivalent to add(Tab, Key, Value, 0, Flags, 15000)

add(Tab, Key, Value, Timeout)
  Equivalent to add(Tab, Key, Value, 0, [], Timeout)

add(Tab::table(), Key::key(), Value::val(), ExpTime::expiry(),
    Flags::flags_list(), Timeout::timeout())
-&gt; 'ok' |
   'key_exists' | do1_otherres()</pre><p title="Description"><b>Description. </b>Add <code class="literal">Key</code> and <code class="literal">Value</code> pair (and <code class="literal">Flags</code>) to the table <code class="literal">Tab</code> if the key
does not already exist.  The operation will fail if <code class="literal">Key</code> already
exists.</p><p>See also <a class="xref" href="#notes-on-operation-flags" title="4.3.&#xA0;Notes on Operation Flags">Section 4.3, “Notes on Operation Flags”</a> and
<a class="xref" href="#notes-on-return-values" title="4.4.&#xA0;Notes on Return Values">Section 4.4, “Notes on Return Values”</a>.</p></div><div class="section" title="brick_simple:replace()"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-replace"></a>brick_simple:replace()</h4></div></div></div><pre class="screen">replace(Tab, Key, Value)
  equivalent to replace(Tab, Key, Value, 0, [], 15000)

replace(Tab, Key, Value, Flags) when is_list(Flags)
 equivalent to replace(Tab, Key, Value, 0, Flags, 15000)

replace(Tab, Key, Value, Timeout)
 equivalent to replace(Tab, Key, Value, 0, [], Timeout)

replace(Tab::table(), Key::key(), Value::val(), ExpTime::expiry(),
        Flags::flags_list(), Timeout::timeout())
-&gt; 'ok' |
   'key_not_exist' | {'ts_error', CurrentTS::timestamp()} |
   do1_otherres()</pre><p title="Description"><b>Description. </b>Replace <code class="literal">Key and `Value</code> pair (and <code class="literal">Flags</code>) in the table <code class="literal">Tab</code> if the
key already exists.  The operation will fail if <code class="literal">Key</code> does not already
exist.</p><p>See also <a class="xref" href="#notes-on-operation-flags" title="4.3.&#xA0;Notes on Operation Flags">Section 4.3, “Notes on Operation Flags”</a> and
<a class="xref" href="#notes-on-return-values" title="4.4.&#xA0;Notes on Return Values">Section 4.4, “Notes on Return Values”</a>.</p></div><div class="section" title="brick_simple:set()"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-set"></a>brick_simple:set()</h4></div></div></div><pre class="screen">set(Tab, Key, Value)
  equivalent to set(Tab, Key, Value, 0, [], 15000)

set(Tab, Key, Value, Flags) when is_list(Flags)
 equivalent to set(Tab, Key, Value, 0, Flags, 15000)

set(Tab, Key, Value, Timeout)
 equivalent to set(Tab, Key, Value, 0, [], Timeout)

set(Tab::table(), Key::key(), Value::val(), ExpTime::expiry(),
        Flags::flags_list(), Timeout::timeout())
-&gt; 'ok' |
   'key_not_exist' | {'ts_error', CurrentTS::timestamp()} |
   do1_otherres()</pre><p title="Description"><b>Description. </b>Set the <code class="literal">Key and `Value</code> pair (and <code class="literal">Flags</code>) in the table <code class="literal">Tab</code>.  This
operation is unconditional, unlike the <code class="literal">add()</code> and <code class="literal">replace()</code>
operations.  However, the operation can still fail for the
<code class="literal">key_not_exist</code> or <code class="literal">{ts_error,TS}</code> reasons if the operation includes
the <code class="literal">{testset, TS}</code> flag.</p><p>See also <a class="xref" href="#notes-on-operation-flags" title="4.3.&#xA0;Notes on Operation Flags">Section 4.3, “Notes on Operation Flags”</a> and
<a class="xref" href="#notes-on-return-values" title="4.4.&#xA0;Notes on Return Values">Section 4.4, “Notes on Return Values”</a>.</p></div><div class="section" title="brick_simple:get()"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-get"></a>brick_simple:get()</h4></div></div></div><pre class="screen">get(Tab, Key)
  equivalent to get(Tab, Key, [], 15000)

get(Tab, Key, Flags) when is_list(Flags)
  equivalent to get(Tab, Key, Flags, 15000)

get(Tab, Key, Timeout)
  equivalent to get(Tab, Key, [], Timeout)

get(Tab::table(), Key::key(), Flags::flags_list(), Timeout::timeout())
-&gt; {'ok', ts()} | {'ok', ts(), val()} | {'ok', ts(), proplist()} |
   {'ok', ts(), val(), time_t(), proplist()} |
   'key_not_exist' | {'ts_error', ts()} |
   do1_otherres()</pre><p title="Description"><b>Description. </b>Get <code class="literal">Key</code> and some other attributes (depending on the op flags) of the key.</p><pre class="screen">header,witness,get_all_attribs,return
,no,no,"&amp;`{'ok', ts(), val()}`"
,yes,no,"&amp;`{'ok', ts()}`"
,no,yes,"&amp;`{'ok', ts(), val(), time_t(), proplist()}`"
,yes,yes,"&amp;`{'ok', ts(), proplist()}`"</pre><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>When a <code class="literal">proplist()</code> is returned, one of the properties in the
list will always be <code class="literal">{val_len,Size::integer()}</code>, where <code class="literal">Size</code> is the
size of the value blob in bytes.</p></td></tr></table></div><p>See also <a class="xref" href="#notes-on-operation-flags" title="4.3.&#xA0;Notes on Operation Flags">Section 4.3, “Notes on Operation Flags”</a> and
<a class="xref" href="#notes-on-return-values" title="4.4.&#xA0;Notes on Return Values">Section 4.4, “Notes on Return Values”</a>.</p></div><div class="section" title="brick_simple:get_many()"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-get-many"></a>brick_simple:get_many()</h4></div></div></div><pre class="screen">get_many(Tab, Key, MaxNum)
  equivalent to get_many(Tab, Key, MaxNum, [], 15000)

get_many(Tab, Key, MaxNum, Flags) when is_list(Flags)
  equivalent to get_many(Tab, Key, MaxNum, Flags, DefaultTimeout)

get_many(Tab, Key, MaxNum, Timeout)
  equivalent to get_many(Tab, Key, MaxNum, [], Timeout)

get_many(Tab::table(), Key::key(), MaxNum::integer(), Flags::flags_list(),
        Timeout::timeout())
-&gt; {ok, {get_many_res_list(), boolean()}} |
   do1_otherres()

get_many_res_list() = [{key(), ts()}] |
                      [{key(), ts()}, val()] |
                      [{key(), ts(), proplist()}] |
                      [{key(), ts(), val(), time_t(), proplist()}]</pre><p title="Description"><b>Description. </b>Get many <code class="literal">Key</code> and <code class="literal">Value</code> pairs from single chain in the table <code class="literal">Tab</code>,
up to a maximum of <code class="literal">MaxNum</code>.  The key <code class="literal">Key</code> is the starting point: if
there is a key <code class="literal">KeyNext</code> that follows <code class="literal">Key</code> (in lexicographic sorting
order), and if the <code class="literal">boolean()</code> value is <code class="literal">true</code>, then <code class="literal">KeyNext</code> will be
the first key’s info in the <code class="literal">get_many_res_list()</code>.</p><p>All keys are returned in lexicographic sorting order.</p><pre class="screen">header,witness,get_all_attribs,get_many_res_list
,no,no,"&amp;`{key(), ts(), val()}`"
,yes,no,"&amp;`{key(), ts()}`"
,no,yes,"&amp;`{key(), ts(), val(), time_t(), flags_list()}`"
,yes,yes,"&amp;`{key(), ts(), flags_list()}`"</pre><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>When a <code class="literal">proplist()</code> is returned, one of the properties in the
list will always be <code class="literal">{val_len,Size::integer()}</code>, where <code class="literal">Size</code> is the
size of the value blob in bytes.</p></td></tr></table></div><p>See also <a class="xref" href="#notes-on-operation-flags" title="4.3.&#xA0;Notes on Operation Flags">Section 4.3, “Notes on Operation Flags”</a> and
<a class="xref" href="#notes-on-return-values" title="4.4.&#xA0;Notes on Return Values">Section 4.4, “Notes on Return Values”</a>.</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The <code class="literal">get_many()</code> function call cannot be used to find all
keys in all chains in a Hibari table.  The consistent hash of <code class="literal">Key</code>
will send the <code class="literal">get_many</code> operation to the tail/standalone brick in a
single chain; all keys returned will come from that single brick only.</p></td></tr></table></div></div><div class="section" title="brick_simple:delete()"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-delete"></a>brick_simple:delete()</h4></div></div></div><pre class="screen">delete(Tab, Key)
  equivalent to delete(Tab, Key, [], 15000)

delete(Tab, Key, Flags)
  equivalent to delete(Tab, Key, Flags, 15000)

delete(Tab, Key, Timeout)
  equivalent to delete(Tab, Key, [], Timeout)

delete(Tab:;table(), Key::key(), Flags::flags_list(),
       Timeout::timeout())
-&gt; 'ok' |
   'key_not_exist' | {'ts_error', ts()} |
   do1_otherres()</pre><p>Delete <code class="literal">Key</code> from table <code class="literal">Tab</code>.</p><p>See also <a class="xref" href="#notes-on-operation-flags" title="4.3.&#xA0;Notes on Operation Flags">Section 4.3, “Notes on Operation Flags”</a> and
<a class="xref" href="#notes-on-return-values" title="4.4.&#xA0;Notes on Return Values">Section 4.4, “Notes on Return Values”</a>.</p></div><div class="section" title="brick_simple:do(), with or without transaction"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-do"></a>brick_simple:do(), with or without transaction</h4></div></div></div><pre class="screen">do(Tab, OpList)
  equivalent to do(Tab, OpList, [], 15000)

do(Tab, OpList, Timeout)
  equivalent to do(Tab, OpList, [], Timeout)

do(Tab::table(), OpList::do_op_list(), OpFlags::do_flags_list(),
   Timeout::timeout)
-&gt; do_res()
do_res()       = [do1_res_ok() |
                  do1_res_fail()] |
                 do_res_fail() |
                 do1_otherres()
do_res_fail    = {txn_fail, [{integer(), do1_res_fail()}]}</pre><p title="Description"><b>Description. </b>Send a list of primitive operations to the table <code class="literal">Tab</code>.  These
primitive operations are created by:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_server:make_add()</code>, <code class="literal">brick_server:make_replace()</code>, <code class="literal">brick_server:make_set()</code>
</li><li class="listitem">
<code class="literal">brick_server:make_get()</code>, <code class="literal">brick_server:make_get_many()</code>
</li><li class="listitem">
<code class="literal">brick_server:make_delete()</code>
</li><li class="listitem">
<code class="literal">brick_server:make_txn()</code>
</li></ul></div><p>If the first item of OpList is <code class="literal">txn</code> then the list of operations is
executed in the context of a micro-transaction.
See <a class="ulink" href="hibari-sysadmin-guide.en.html#micro-transactions" target="_top">Hibari Sysadmin
Guide, "Micro-Transactions" section</a> for a description of
micro-transactions.
See
<a class="xref" href="#micro-transaction-request-example" title="Making a micro-transaction request">the section called “Making a micro-transaction request”</a> for an example of a <code class="literal">do()</code>
call, first without and later with, micro-transaction context.</p></div></div></div><div class="section" title="5.&#xA0;Client API: UBF"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="client-api-ubf"></a>5. Client API: UBF</h2></div></div></div><p><a class="ulink" href="http://github.com/norton/ubf" target="_top">The UBF protocol</a> is a
formally-specified family of protocols that are supported by a large
number of client languages.  This section attempts to describe the
layers of the UBF protocol stack, how to use the UBF client in Erlang
and other languages, and how to use that client to access a Hibari
storage cluster.</p><p>The Hibari source distribution includes UBF/EBF protocol support for the
following languages:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Erlang, see <a class="xref" href="#using-ubf-erlang-client" title="5.5.&#xA0;Using the UBF Client Library for Erlang">Section 5.5, “Using the UBF Client Library for Erlang”</a>
</li><li class="listitem">
Java, see <a class="xref" href="#using-ubf-java-client" title="5.6.&#xA0;Using the UBF Client Library for Java">Section 5.6, “Using the UBF Client Library for Java”</a>
</li><li class="listitem">
Python, see <a class="xref" href="#using-ubf-python-client" title="5.7.&#xA0;Using the EBF Client Library for Python">Section 5.7, “Using the EBF Client Library for Python”</a>
</li></ul></div><div class="section" title="5.1.&#xA0;The Hibari Server&#x2019;s Implementation of the UBF Protocol Stack"><div class="titlepage"><div><div><h3 class="title"><a id="hibari-server-impl-of-ubf-proto-stack"></a>5.1. The Hibari Server’s Implementation of the UBF Protocol Stack</h3></div></div></div><div class="variablelist"><dl><dt><span class="term">
UBF(A): Bottom Layer, transport and session protocol layer
</span></dt><dd><p class="simpara">
This layer plays the same basic role as many other serialized data
transport protocols that use TCP for host-to-host transport, such as
<a class="ulink" href="http://en.wikipedia.org/wiki/Open_Network_Computing_Remote_Procedure_Call" target="_top">ONC-RPC</a>,
<a class="ulink" href="http://en.wikipedia.org/wiki/IIOP" target="_top">CORBA IIOP</a>,
<a class="ulink" href="http://en.wikipedia.org/wiki/Protocol_buffers" target="_top">Protocol Buffers</a>,
and
<a class="ulink" href="http://en.wikipedia.org/wiki/Thrift_(protocol)" target="_top">Thrift</a>.
</p><p class="simpara">Hibari servers support several of these session protocols on top
of a TCP/IP transport protocol.  The choice of session protocol is
a matter of convenience and/or support for the application
developer. Hibari should be as easy for an app developer to use
Ruby and JSON-RPC as it is to use Python and Protocol Buffers.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
UBF(A), Joe Armstrong’s original session layer protocol
</li><li class="listitem">
EBF, the Erlang Binary Format.  The session layer protocol is a
  thin, efficient that uses the Erlang BIFs <code class="literal">term_to_binary()</code> and
  <code class="literal">binary_to_term()</code> to serialize Erlang data terms.  This protocol
  is very closely related to the <a class="ulink" href="http://bert-rpc.org/" target="_top">BERT protocol</a>.
</li><li class="listitem">
JSON over TCP, also called JSF (the JavaScript
  Format).  Erlang terms are encoded as
  <a class="ulink" href="http://en.wikipedia.org/wiki/JSON" target="_top">JSON terms</a>
  and transmitted directly over a TCP transport.  This
  protocol is not in common use but is easy to implement in the UBF
  server framework.
</li><li class="listitem">
HTTP, the <a class="ulink" href="http://en.wikipedia.org/wiki/HTTP" target="_top">Hypertext
  Transfer Protocol</a>.  This protocol is used to support Hibari’s
  <a class="ulink" href="http://en.wikipedia.org/wiki/JSON-RPC" target="_top">JSON-RPC</a> server.
</li><li class="listitem">
<a class="ulink" href="http://en.wikipedia.org/wiki/Thrift_(protocol)" target="_top">Thrift</a>.
  Similar to EBF, except that Thrift’s binary encoding is used for
  the wire protocol instead of UBF(A) or Erlang’s native wire
  formats.
  <span class="strong"><strong>Hibari support is experimental (i.e. not yet implemented).</strong></span>
</li><li class="listitem">
<a class="ulink" href="http://en.wikipedia.org/wiki/Protocol_buffers" target="_top">Protocol Buffers</a>.
  Similar to EBF, except that Google’s Protocol Buffers binary
  encoding is used for the wire protocol instead of UBF(A) or
  Erlang’s native wire formats.
  <span class="strong"><strong>Hibari support is experimental (i.e. not yet implemented).</strong></span>
</li><li class="listitem">
<a class="ulink" href="http://hadoop.apache.org/avro/docs/current/" target="_top">Avro</a>.
  Similar to EBF, except that Avro’s binary encoding is used for the
  wire protocol instead of UBF(A) or Erlang’s native wire formats.
  <span class="strong"><strong>Hibari support is experimental (i.e. not yet implemented).</strong></span>
</li></ul></div></dd><dt><span class="term">
UBF(B): Middle Layer, the "contract"
</span></dt><dd><p class="simpara">
UBF(B) is a programming language for describing types in UBF(A)
and protocols between clients and servers. UBF(B) is roughly
equivalent to to Verified XML, XML-schemas, SOAP and WDSL.
</p><p class="simpara">This layer enforces a protocol "contract", a formal specification of
all data sent by the client and by the server.  Any data that does not
precisely conform to the protocol is rejected by the contract checker
(which is embedded in the server).  If the client wishes, it may also
use the contract checker to validate data sent by the server, though
this not commonly done.</p></dd><dt><span class="term">
UBF( C): Top Layer, the UBF Metaprotocol
</span></dt><dd>
The metaprotocol is used at the beginning of a UBF session to select
one of the UBF(B) contracts that the TCP listener is capable of
offering.  At the moment, Hibari servers support only the "gdss"
contract, but other contracts may be added in the future.
</dd></dl></div></div><div class="section" title="5.2.&#xA0;UBF representation of strings vs. binaries"><div class="titlepage"><div><div><h3 class="title"><a id="ubf-representation-of-strings"></a>5.2. UBF representation of strings vs. binaries</h3></div></div></div><p>The Erlang language does not have a data type specifically for
strings.  Instead, strings are typically represented as lists of
integers (ASCII byte values) and/or binaries.</p><p>A UBF contract makes a distinction between a string, list, and
binary.  In the case of a string, UBF(A) encodes a string using the
notation <code class="literal">{'#S', "Hello, world!"}</code> to represent the string "Hello,
world!".</p><p>This string encoding is cumbersome to use for developers; in Erlang,
the <code class="literal">ubf.hrl</code> header file includes a macro <code class="literal">?S("Hello, world!")</code> as a
slightly less ugly shortcut.  When using other languages, the 2-tuple
and the atom <code class="literal">'#S'</code>  would be created as any other 2-tuple and atom.</p><p>Fortunately, there is only one case where the string type is
necessary: using the <code class="literal">startSession</code> metaprotocol command to start
using the Hibari data server contract.  An example will be shown
below.</p></div><div class="section" title="5.3.&#xA0;Steps for Using a UBF-based Protocol in Any Language"><div class="titlepage"><div><div><h3 class="title"><a id="using-ubf-in-any-language"></a>5.3. Steps for Using a UBF-based Protocol in Any Language</h3></div></div></div><p>The steps to use a UBF-based protocol are the same in any language.</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
Create a connection to the UBF server.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
… or the EBF server, or the JSON-RPC server, or the Thrift
server, or the ….
</li></ul></div></li><li class="listitem">
Use the UBF metaprotocol to start using the <code class="literal">gdss</code> contract,
   i.e. the Hibari server contract.
</li><li class="listitem">
Send one or more Hibari server queries and decode the respective
   server responses.
</li><li class="listitem">
Close the connection to the UBF server.
</li></ol></div></div><div class="section" title="5.4.&#xA0;The Hibari UBF Protocol Contract"><div class="titlepage"><div><div><h3 class="title"><a id="the-hibari-ubf-protocol-contract"></a>5.4. The Hibari UBF Protocol Contract</h3></div></div></div><p>The Hibari UBF Protocol contract can be found in the file
<code class="literal">ubf_gdss_plugin.con</code>.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>See the Hibari source code for the most up-to-date version of
this file.  <a class="ulink" href="./misc-codes/ubf_gdss_plugin.con" target="_top">This documentation has a copy
of <code class="literal">ubf_gdss_plugin.con</code></a>, though it may be slightly out-of-date.</p></td></tr></table></div><p>The names of the UBF types specified in the contract may differ
slightly from the names of the types used in this document’s
<a class="xref" href="#client-api-erlang" title="4.&#xA0;Client API: Native Erlang">Section 4, “Client API: Native Erlang”</a>.  For example, the UBF contract calls the key
expiration time time <code class="literal">exp_time()</code>, while the type system in this
document calls it <code class="literal">expiry()</code>.  However, in all cases of slightly
different names, the fundamental data type that both names use is the
same: e.g. <code class="literal">integer()</code> for expiration time.</p><p>For each command, the UBF contract uses the following naming
conventions:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">CommandName_req()</code> for the request sent from client → server,
  e.g. <code class="literal">set_req()</code> for the <code class="literal">set</code> command.
</li><li class="listitem">
<code class="literal">CommandName_res()</code> for the response sent from server → client,
  e.g. <code class="literal">set_res()</code> for the <code class="literal">set</code> response.
</li></ul></div><p>The general form of a UBF RPC call is a tuple.  The first element in
the tuple is the name of the command, and the following elements are
arguments for that command.  The response can be any Erlang term, but
the Hibari contract will only return the atom or tuple types.</p><p>The following is a mapping of UBF client request type to its Erlang
API function, in alphabetical order.:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">add_req()</code> → <code class="literal">brick_simple:add()</code>, see <a class="xref" href="#brick-simple-add" title="brick_simple:add()">the section called “brick_simple:add()”</a>.
</li><li class="listitem">
<code class="literal">delete_req()</code> → <code class="literal">brick_simple:delete()</code>, see <a class="xref" href="#brick-simple-delete" title="brick_simple:delete()">the section called “brick_simple:delete()”</a>.
</li><li class="listitem">
<code class="literal">do_req()</code> → <code class="literal">brick_simple:do()</code>, see <a class="xref" href="#brick-simple-do" title="brick_simple:do(), with or without transaction">the section called “brick_simple:do(), with or without transaction”</a>.
</li><li class="listitem">
<code class="literal">get_req()</code> → <code class="literal">brick_simple:get()</code>, see <a class="xref" href="#brick-simple-get" title="brick_simple:get()">the section called “brick_simple:get()”</a>.
</li><li class="listitem">
<code class="literal">get_many_req()</code> → <code class="literal">brick_simple:get_many()</code>, see <a class="xref" href="#brick-simple-get-many" title="brick_simple:get_many()">the section called “brick_simple:get_many()”</a>.
</li><li class="listitem">
<code class="literal">replace_req()</code> → `brick_simple:replace(), see <a class="xref" href="#brick-simple-replace" title="brick_simple:replace()">the section called “brick_simple:replace()”</a>.
</li><li class="listitem">
<code class="literal">set_req()</code> → `brick_simple:set(), see <a class="xref" href="#brick-simple-set" title="brick_simple:set()">the section called “brick_simple:set()”</a>.
</li></ul></div><p>The following Erlang API documentation accurately describes the use of
other types in the UBF contract, for example:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
For the <code class="literal">flags_list()</code> contract type, see <a class="xref" href="#notes-on-operation-flags" title="4.3.&#xA0;Notes on Operation Flags">Section 4.3, “Notes on Operation Flags”</a>.
</li><li class="listitem">
For the <code class="literal">do_flags_list()</code> contract type, see <a class="xref" href="#notes-on-return-values" title="4.4.&#xA0;Notes on Return Values">Section 4.4, “Notes on Return Values”</a>.
</li></ul></div></div><div class="section" title="5.5.&#xA0;Using the UBF Client Library for Erlang"><div class="titlepage"><div><div><h3 class="title"><a id="using-ubf-erlang-client"></a>5.5. Using the UBF Client Library for Erlang</h3></div></div></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
When using the Erlang shell for experimentation &amp; prototyping, that
   shell must have the path to the Erlang UBF client
   library in its search path.  The easiest way to do this is to use
   the arguments <code class="literal">-pz /path/to/ubf/library/ebin</code> to your Erlang
   shell’s <code class="literal">erl</code> command.
</li><li class="listitem">
When writing code, the statement <code class="literal">-include("ubf.hrl").</code> at the top
   of your source module to gain access to the <code class="literal">?S()</code> macro.  Due to
   limitations in the Erlang shell, macros cannot be used in the shell.
</li></ol></div></td></tr></table></div><p>As outlined in <a class="xref" href="#using-ubf-in-any-language" title="5.3.&#xA0;Steps for Using a UBF-based Protocol in Any Language">Section 5.3, “Steps for Using a UBF-based Protocol in Any Language”</a>, the first step is to
create a connection to a Hibari server.  If the Hibari cluster has
multiple nodes, then it doesn’t matter which one that you connect to:
all nodes can handle any UBF request and will route the query to the
proper brick.</p><p title="Create a connection to the UBF server (on &quot;localhost&quot; TCP port 7581)"><b>Create a connection to the UBF server (on "localhost" TCP port 7581). </b>
</p><pre class="screen">(asdf@bb3)54&gt; {ok, P1, _} = ubf_client:connect("localhost", 7581, [{proto, ubf}], 5000).
{ok,&lt;0.139.0&gt;,{'#S', "gdss_meta_server"}}</pre><p title="Create a connection to the UBF server (on &quot;localhost&quot; TCP port 7581)">
</p><p>The second step is to use the UBF metaprotocol to select the Hibari
server, contract, called "gdss",
for all further commands for this connection.</p><div class="tip" title="Tip" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/icons/tip.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The Hibari server contract is "stateless".  All replies terms from the
<code class="literal">ubf_client:rpc/2</code> function use the form
<code class="literal">{reply,ServerReply,UBF_StateName}</code>.  Because the Hibari server
contract is stateless, the <code class="literal">UBF_StateName</code> will always be the atom
<code class="literal">none</code>.</p></td></tr></table></div><p title="Use the UBF metaprotocol to request the &quot;gdss&quot; contract"><b>Use the UBF metaprotocol to request the "gdss" contract. </b>
</p><pre class="screen">(asdf@bb3)55&gt; ubf_client:rpc(P1, {startSession, {'#S', "gdss"}, []}).
{reply,{ok,ok},none}</pre><p title="Use the UBF metaprotocol to request the &quot;gdss&quot; contract">
</p><p>Now that the UBF connection is set up, we can use it to set a key "foo".</p><p title="Set the key &quot;foo&quot; in table tab1 with the value &quot;foo val&quot;, no expiration time, no flags, and a timeout of 5 seconds"><b>Set the key "foo" in table <code class="literal">tab1</code> with the value "foo val", no expiration time, no flags, and a timeout of 5 seconds. </b>
</p><pre class="screen">(asdf@bb3)59&gt; ubf_client:rpc(P1, {set, tab1, &lt;&lt;"foo"&gt;&gt;, &lt;&lt;"foo val"&gt;&gt;, 0, [], 5000}).
{reply,ok,none}</pre><p title="Set the key &quot;foo&quot; in table tab1 with the value &quot;foo val&quot;, no expiration time, no flags, and a timeout of 5 seconds">
</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Note that the return value of both the
<code class="literal">set_req()</code> (in the example above) and <code class="literal">get_req()</code> (in the example
below) return the same types described in the <a class="xref" href="#brick-simple-set" title="brick_simple:set()">the section called “brick_simple:set()”</a>
and <a class="xref" href="#brick-simple-get" title="brick_simple:get()">the section called “brick_simple:get()”</a>, respectively.</p><p>The only difference is that the <code class="literal">ubf_client:rpc/2</code> function wraps the
server’s reply in a 3-tuple: <code class="literal">{reply,ServerReply,none}</code>.</p></td></tr></table></div><p title="Get the key &quot;foo&quot; in table tab1, timeout in 5 seconds"><b>Get the key "foo" in table <code class="literal">tab1</code>, timeout in 5 seconds. </b>
</p><pre class="screen">(asdf@bb3)66&gt; ubf_client:rpc(P1, {get, tab1, &lt;&lt;"foo"&gt;&gt;, [], 5000}).
{reply,{ok,1273009092549799,&lt;&lt;"foo val"&gt;&gt;},none}</pre><p title="Get the key &quot;foo&quot; in table tab1, timeout in 5 seconds">
</p><p>If the client sends a request that violates the contract, the server
will tell you, as in this example:</p><p title="Send a contract-violating request"><b>Send a contract-violating request. </b>
</p><pre class="screen">(asdf@bb3)89&gt; ubf_client:rpc(P1, {bbb, 3000}).
{reply,{clientBrokeContract,{bbb,3000},[]},none}</pre><p title="Send a contract-violating request">
</p><p>When you are done with the connection, it is polite to close the
connection explicitly.  The server will quietly clean up its side of
the connection if the client forgets to call or cannot call <code class="literal">stop/1</code>.</p><p title="Close the UBF connection"><b>Close the UBF connection. </b>
</p><pre class="screen">(asdf@bb3)92&gt; ubf_client:stop(P1).
ok</pre><p title="Close the UBF connection">
</p></div><div class="section" title="5.6.&#xA0;Using the UBF Client Library for Java"><div class="titlepage"><div><div><h3 class="title"><a id="using-ubf-java-client"></a>5.6. Using the UBF Client Library for Java</h3></div></div></div><p>The source code for the UBF client library for Java is included in
the UBF source repository at
<a class="ulink" href="http://github.com/norton/ubf" target="_top">http://github.com/norton/ubf</a>, in
the <code class="literal">priv/java</code> subdirectory.</p><div class="section" title="Compiling the UBF client library for Java"><div class="titlepage"><div><div><h4 class="title"><a id="_compiling_the_ubf_client_library_for_java"></a>Compiling the UBF client library for Java</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Please update your UBF client library code to the "master" branch
   for a date after 10 May 2010, or use the Git tag "v1.14" or later.
   Versions of the library before 10 May 2010 and tag "v1.14" have
   several bugs that will prevent the UBF client from working
   correctly.
</li><li class="listitem">
Change directory to the <code class="literal">priv/java</code> directory of the UBF client
   library source distribution.
</li><li class="listitem">
Run <code class="literal">make</code>.
</li><li class="listitem">
(Optional) Copy the class files in the <code class="literal">classes</code> subdirectory to
   a suitable directory for your Java development environment.
</li></ol></div></div><div class="section" title="Compiling the UBF client library test program HibariTest.java"><div class="titlepage"><div><div><h4 class="title"><a id="_compiling_the_ubf_client_library_test_program_hibaritest_java"></a>Compiling the UBF client library test program HibariTest.java</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Change directory to the <code class="literal">gdss-ubf-proto/priv/java</code> subdirectory in
   the Hibari source distribution.
</li><li class="listitem">
Edit the <code class="literal">Makefile</code> to change the <code class="literal">UBF_CLASSES_DIR</code> variable to
   point to the <code class="literal">priv/java/classes</code> subdirectory of the UBF package’s
   source code (or the subdirectory where those classes have been
   formally installed on your system).
</li><li class="listitem"><p class="simpara">
Run the following two <code class="literal">make</code> commands.  The second assumes that the
   Hibari server’s UBF server is on the local machine, "localhost".
</p><pre class="screen">% make HibariTest
% make run-HibariTest</pre></li><li class="listitem">
If the Hibari server is not running on the local machine, then run
   <code class="literal">make -n run-HibariTest</code> to show the <code class="literal">java</code> command that is used to
   run the test program.  Cut-and-paste the command into your shell,
   then edit the last argument to specify the hostname of a Hibari
   server.
</li></ol></div></div><div class="section" title="Examining the HibariTest.java test program"><div class="titlepage"><div><div><h4 class="title"><a id="_examining_the_hibaritest_java_test_program"></a>Examining the HibariTest.java test program</h4></div></div></div><p>The <code class="literal">main()</code> function does three things:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Create a new UBF connection to a Hibari server (hostname/IP address
   is specified in the first command line argument) and requests the
   <code class="literal">gdss</code> contract via the UBF metaprotocol.
</li><li class="listitem">
Run the small test cases in the <code class="literal">test_hibari_basics()</code> method.
</li><li class="listitem">
Close the UBF session and exit.
</li></ol></div><p title="The ubf.HibariTest.main() method"><a id="the-ubf-hibaritest-main-method"></a><b>The ubf.HibariTest.main() method. </b>
</p><pre class="screen">public class HibariTest
{
    public static void main(String[] args)
        throws Exception
    {
        Socket sock = null;
        UBFClient ubf = null;

        try {
            sock = new Socket(args[0], 7581);
            ubf = UBFClient.new_via_sock(new UBFString("gdss"), new UBFList(),
                    new FooHandler(), sock);
        }
        catch (Exception e) {
            System.out.println(e);
            System.exit(1);
        }

        test_hibari_basics(ubf);

        ubf.stopSession();
        System.out.println("Success, it works");
        System.exit(0);
    }
/* ... */
}</pre><p title="The ubf.HibariTest.main() method">
</p><p>The <code class="literal">test_hibari_basics()</code> method performs the same basic UBF
operations as the Python EBF demonstration script described in
<a class="xref" href="#using-ubf-python-client" title="5.7.&#xA0;Using the EBF Client Library for Python">Section 5.7, “Using the EBF Client Library for Python”</a>.  Unlike the Python demo script, the
demo program does not use the Hibari <code class="literal">do()</code> command but rather then
single-operation commands like <code class="literal">get()</code> and <code class="literal">set()</code>.</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
Delete the key <code class="literal">foo</code> from table <code class="literal">tab1</code>.
</p><pre class="screen">    public static void test_hibari_basics(UBFClient ubf)
        throws IOException, UBFException
    {
        // setup
        UBFObject res1 = ubf.rpc(
                UBF.tuple( new UBFAtom("delete"), new UBFAtom("tab1"),
                            new UBFBinary("foo"), new UBFList(),
                            new UBFInteger(4000)));
        System.out.println("Res 1:" + res1.toString());</pre></li><li class="listitem"><p class="simpara">
Add the key <code class="literal">foo</code> to table <code class="literal">tab1</code>.
</p><pre class="screen">        // add - ok
        UBFObject res2 = ubf.rpc(
                UBF.tuple( new UBFAtom("add"), atom_tab1,
                            new UBFBinary("foo"), new UBFBinary("bar"),
                            new UBFInteger(0), new UBFList(),
                            new UBFInteger(4000)));
        System.out.println("Res 2:" + res2.toString());
        if (! res2.equals(atom_ok))
            System.exit(1);</pre></li><li class="listitem"><p class="simpara">
Add the key <code class="literal">foo</code> to table <code class="literal">tab1</code> again, this time expecting a
failure.
</p><pre class="screen">        // add - ng
        UBFObject res3 = ubf.rpc(
                UBF.tuple( new UBFAtom("add"), atom_tab1,
                            new UBFBinary("foo"), new UBFBinary("bar"),
                            new UBFInteger(0), new UBFList(),
                            new UBFInteger(4000)));
        System.out.println("Res 3:" + res3.toString());
        if (! ((UBFTuple)res3).value[0].equals(atom_key_exists))
            System.exit(1);</pre></li><li class="listitem"><p class="simpara">
Get the key <code class="literal">foo</code> from table <code class="literal">tab1</code>.
</p><pre class="screen">        // get - ok
        UBFObject res4 = ubf.rpc(
                UBF.tuple( new UBFAtom("get"), atom_tab1,
                            new UBFBinary("foo"), new UBFList(),
                            new UBFInteger(4000)));
        System.out.println("Res 4:" + res4.toString());
        if (! ((UBFTuple)res4).value[0].equals(atom_ok) ||
            ! ((UBFTuple)res4).value[2].equals("bar"))
            System.exit(1);</pre></li><li class="listitem"><p class="simpara">
Set the key <code class="literal">foo</code> in table <code class="literal">tab1</code> to <code class="literal">bar bar</code>.
</p><pre class="screen">        // set - ok
        UBFObject res5 = ubf.rpc(
                UBF.tuple( new UBFAtom("set"), atom_tab1,
                            new UBFBinary("foo"), new UBFBinary("bar bar"),
                            new UBFInteger(0), new UBFList(),
                            new UBFInteger(4000)));
        System.out.println("Res 5:" + res5.toString());
        if (! res5.equals(atom_ok))
            System.exit(1);</pre></li><li class="listitem"><p class="simpara">
Get <code class="literal">foo</code> again and verify that the value is <code class="literal">bar bar</code>
</p><pre class="screen">        // get - ok
        UBFObject res6 = ubf.rpc(
                UBF.tuple( new UBFAtom("get"), atom_tab1,
                            new UBFBinary("foo"), new UBFList(),
                            new UBFInteger(4000)));
        System.out.println("Res 6:" + res6.toString());
        if (! ((UBFTuple)res6).value[0].equals(atom_ok) ||
            ! ((UBFTuple)res6).value[2].equals("bar bar"))
            System.exit(1);</pre></li></ol></div></div><div class="section" title="The UBF event handler interface"><div class="titlepage"><div><div><h4 class="title"><a id="_the_ubf_event_handler_interface"></a>The UBF event handler interface</h4></div></div></div><p>Each <code class="literal">UBFClient</code> instance uses a separate thread to read data from the
server and do any of the following:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Signal to the other thread that a synchronous RPC response was
received from the server.
</li><li class="listitem">
Run a callback function when an <code class="literal">event_out</code> asynchronous event is
received from the server.
</li><li class="listitem">
The socket was closed unexpectedly.
</li></ol></div><p>In cases #2 and #3, a class that implements the <code class="literal">UBFEventHandler</code>
interface is used to define the action to be taken in those cases.</p><p>The <code class="literal">HibariTest.java</code> contains a sample implementation of callback
functions for asynchronous events.  A real application would probably
want to do something much more helpful than this example does.</p><pre class="screen">    public static class FooHandler implements UBFEventHandler {
        public FooHandler() {
        }
        public void handleEvent(UBFClient client, UBFObject event) {
            System.out.println("Hey, got an event: " + event.toString());
        }
        public void connectionClosed(UBFClient client) {
            System.out.println("Hey, connection closed, ignoring it\n");
        }
    }</pre><div class="tip" title="Tip" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/icons/tip.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>See <a class="xref" href="#the-ubf-hibaritest-main-method" title="The ubf.HibariTest.main() method">The ubf.HibariTest.main() method</a> for an example that
uses this <code class="literal">FooHandler</code> class.</p></td></tr></table></div></div></div><div class="section" title="5.7.&#xA0;Using the EBF Client Library for Python"><div class="titlepage"><div><div><h3 class="title"><a id="using-ubf-python-client"></a>5.7. Using the EBF Client Library for Python</h3></div></div></div><p>The source code for the EBF client library for Python is included in
the UBF source repository at
<a class="ulink" href="http://github.com/norton/ubf" target="_top">http://github.com/norton/ubf</a>, in
the <code class="literal">priv/python</code> subdirectory.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Recall that the EBF protocol is very closely related to UBF.  The
only significant difference is the "layer 5" session protocol layer:
instead of using the UBF(A) protocol, the EBF (Erlang Binary Format)
protocol is used instead.  See
<a class="xref" href="#hibari-server-impl-of-ubf-proto-stack" title="5.1.&#xA0;The Hibari Server&#x2019;s Implementation of the UBF Protocol Stack">Section 5.1, “The Hibari Server’s Implementation of the UBF Protocol Stack”</a> for more details.</p></td></tr></table></div><p>In addition, you will need the "py_interface" package, developed by
Tomas Abrahamsson and others.  "py-interface" is distributed under the
<a class="ulink" href="http://www.fsf.org/licensing/education/licenses/lgpl.html" target="_top">GNU
Library General Public License</a>.  A git repository is hosted at
repo.or.cz. To clone it and build it, use:</p><pre class="screen">git clone git://repo.or.cz/py_interface.git
cd py_interface
autoconf
./configure
make
pwd</pre><p>Use the output of the last command, <code class="literal">pwd</code>, to remember the full
directory path to the "py-interface" library.  The example below
assumes that path is <code class="literal">/tmp/py-interface</code>.</p><p>The <code class="literal">pyebf.py</code> file contains a small unit test that makes several
calls to the Hibari UBF contract’s <code class="literal">do_req()</code> command.  The results of
(almost) every command are verified using the <code class="literal">assert</code> function.</p><pre class="screen">env PYTHONPATH=/path/to/py_interface python pyebf.py</pre><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
Connect to the Hibari server on "localhost" TCP port 7580 and use
the UBF metaprotocol to switch to the <code class="literal">gdss</code> contract.
</p><pre class="screen">    ## login
    ebf.login('gdss', 'gdss_meta_server')</pre></li><li class="listitem"><p class="simpara">
Delete the key <code class="literal">'foo'</code> from table <code class="literal">tab1</code>.
</p><pre class="screen">    ## setup
    req0 = (Atom('do'), Atom('tab1'), [(Atom('delete'), 'foo', [])], [], 1000)
    res0 = ebf.rpc('gdss', req0)</pre></li><li class="listitem"><p class="simpara">
Get the key <code class="literal">'foo'</code> from table <code class="literal">tab1</code>.
</p><pre class="screen">    ## get - ng
    req1 = (Atom('do'), Atom('tab1'), [(Atom('get'), 'foo', [])], [], 1000)
    res1 = ebf.rpc('gdss', req1)
    assert res1[0] == 'key_not_exist'</pre></li><li class="listitem"><p class="simpara">
Add the key <code class="literal">'foo'</code> to table <code class="literal">tab1</code>.  The <code class="literal">do_req()</code> interface
requires managing the timestamp integers explicitly by the client; the
timestamp <code class="literal">1</code> is used here.
</p><pre class="screen">    ## add - ok
    req2 = (Atom('do'), Atom('tab1'), [(Atom('add'), 'foo', 1, 'bar', 0, [])], [
], 1000)
    res2 = ebf.rpc('gdss', req2)
    assert res2[0] == 'ok'</pre></li><li class="listitem"><p class="simpara">
Add the key <code class="literal">'foo'</code> to table <code class="literal">tab1</code>.
</p><pre class="screen">    ## add - ng
    req3 = (Atom('do'), Atom('tab1'), [(Atom('add'), 'foo', 1, 'bar', 0, [])], [
], 1000)
    res3 = ebf.rpc('gdss', req3)
    assert res3[0][0] == 'key_exists'
    assert res3[0][1] == 1</pre></li><li class="listitem"><p class="simpara">
Get the key <code class="literal">'foo'</code> from table <code class="literal">tab1</code>, verifying that the timestamp
is still <code class="literal">1</code> and value is still <code class="literal">'bar'</code>.
</p><pre class="screen">    ## get - ok
    req4 = (Atom('do'), Atom('tab1'), [(Atom('get'), 'foo', [])], [], 1000)
    res4 = ebf.rpc('gdss', req4)
    assert res4[0][0] == 'ok'
    assert res4[0][1] == 1
    assert res4[0][2] == 'bar'</pre></li><li class="listitem"><p class="simpara">
Set the key <code class="literal">'foo'</code> from table <code class="literal">tab1</code>, using a new timestamp <code class="literal">2</code>.
</p><pre class="screen">    ## set - ok
    req5 = (Atom('do'), Atom('tab1'), [(Atom('set'), 'foo', 2, 'baz', 0, [])], [
], 1000)
    res5 = ebf.rpc('gdss', req5)
    assert res5[0] == 'ok'</pre></li><li class="listitem"><p class="simpara">
Get the key <code class="literal">'foo'</code> from table <code class="literal">tab1</code>, verifying both the new
timestamp and new value.
</p><pre class="screen">    ## get - ok
    req6 = (Atom('do'), Atom('tab1'), [(Atom('get'), 'foo', [])], [], 1000)
    res6 = ebf.rpc('gdss', req6)
    assert res6[0][0] == 'ok'
    assert res6[0][1] == 2
    assert res6[0][2] == 'baz'</pre></li></ol></div></div></div><div class="section" title="6.&#xA0;Client API: TBF"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="client-api-tbf"></a>6. Client API: TBF</h2></div></div></div><p>The TBF protocol is a <a class="ulink" href="https://github.com/apache/thrift" target="_top">Thrift
protocol</a> defined by UBF contract
<a class="xref" href="#the-hibari-ubf-protocol-contract" title="5.4.&#xA0;The Hibari UBF Protocol Contract">Section 5.4, “The Hibari UBF Protocol Contract”</a>.  This section attempts to
describe the Hibari Thrift API which allows users to access Hibari with
Thrift clients in any Thrift supported programming languages, and how
to extend the API for application uses.</p><div class="section" title="6.1.&#xA0;The Hibari Thrift API"><div class="titlepage"><div><div><h3 class="title"><a id="_the_hibari_thrift_api"></a>6.1. The Hibari Thrift API</h3></div></div></div><p>The Hibari Thrift API is defined as Hibari Service in
<a class="ulink" href="./misc-codes/hibari.thrift" target="_top">hibari.thrift</a>.  At the time this API
was developed, only Thrift 0.4.0 is available to us.  This version is
our first attempt to adopt Thrift.  Some of the functions and options
are not yet supported.</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The Hibari Thrift API only supports thrift 0.4.0 or above.</p></td></tr></table></div><pre class="screen">service Hibari {

  /**
   * Check connection availability / keepalive
   */
  oneway void keepalive()

  /**
   * Hibari Server Info
   */
  string info()

  /**
   * Hibari Description
   */
  string description()

  /**
   * Hibari Contract
   */
  string contract()

  /**
   * Add
   */
  HibariResponse Add(1: Add request)
      throws (1:HibariException ouch)

  /**
   * Replace
   */
  HibariResponse Replace(1: Replace request)
      throws (1:HibariException ouch)

  /**
   * Set
   */
  HibariResponse Set(1: Set request)
      throws (1:HibariException ouch)

  /**
   * Delete
   */
  HibariResponse Delete(1: Delete request)
      throws (1:HibariException ouch)

  /**
   * Get
   */
  HibariResponse Get(1: Get request)
      throws (1:HibariException ouch)
}</pre><p>For each primitive utility function, it has exactly one input
parameter.  The parameter is an object that has a name matches its
function. The object carries all mandatory and optional parameters to
Hibari. This object could also be used to implement micro-transaction
in the future <a class="xref" href="#micro-transaction-implementation" title="Micro-transaction implementation">the section called “Micro-transaction implementation”</a>.</p></div><div class="section" title="6.2.&#xA0;Mapping UBF Contract Types to Thrift Types"><div class="titlepage"><div><div><h3 class="title"><a id="_mapping_ubf_contract_types_to_thrift_types"></a>6.2. Mapping UBF Contract Types to Thrift Types</h3></div></div></div><p>You can find more details of the UBF / Thrift type conversion in
(<a class="ulink" href="https://github.com/norton/ubf-thrift" target="_top">UBF-Thrift</a>).</p></div><div class="section" title="6.3.&#xA0;Mapping UBF Contract to Thrift Service"><div class="titlepage"><div><div><h3 class="title"><a id="_mapping_ubf_contract_to_thrift_service"></a>6.3. Mapping UBF Contract to Thrift Service</h3></div></div></div><p>Mapping UBF types to thrift primitives is different from mapping UBF
contracts to service. Thrift mainly uses 2 different types to compose
a request (struct and field).</p><p>If you are using Thrift to generate client code, you probably don’t
need to worry about how the request being constructed. Visit
<a class="ulink" href="http://wiki.apache.org/thrift/ThriftGeneration" target="_top">Thrift Wiki</a> for
the instruction to install Thrift and to generate client code.  You
will also need <a class="ulink" href="./misc-codes/hibari.thrift" target="_top">hibari.thrift</a> to get
started.</p><p>If you are interested in the UBF contract, the Hibari NTBF contract
can be found in the file of <code class="literal">ntbf_gdss_plugin.con</code>.</p></div><div class="section" title="6.4.&#xA0;Examples of using a thrift client"><div class="titlepage"><div><div><h3 class="title"><a id="_examples_of_using_a_thrift_client"></a>6.4. Examples of using a thrift client</h3></div></div></div><p>Once you get the generated code, connecting to Hibari is easy.  For
example, adding the key <code class="literal">'fookey'</code> to table <code class="literal">tab1</code> with a value of
<code class="literal">'Hello, world!'</code> in the following 3 languages.</p><p>In Erlang:</p><pre class="screen">  -include("hibari_thrift.hrl").

  % init
  {ok, Client} = thrift_client:start_link("127.0.0.1", 7600, hibari_thrift),

  % create the input parameter object
  Request = #add{table=&lt;&lt;"tab1"&gt;&gt;, key=&lt;&lt;"fookey"&gt;&gt;, value=&lt;&lt;"Hello, world!"&gt;},

  % send request
  try
    HibariResponse = thrift_client:call(Client, 'Add', [Request]),
  catch
    HibariException -&gt;
      HibariException
  end,

  ok = thrift_client:close(Client).</pre><p>In Java:</p><pre class="screen">  import com.hibari.rpc.*;

  // init
  TTransport transport = new TSocket("127.0.0.1", 7600);
  TProtocol proto = new TBinaryProtocol(transport);
  Hibari.Client client = new Hibari.Client(proto);
  transport.open();

  // create the input parameter object
  Add request = new Add("tab1", ByteBuffer.wrap("fookey".getBytes()),
    ByteBuffer.wrap("Hello, world!".getBytes())))

  // send request
  try {
    HibariResponse response = client.Add(request);
  } catch (HibariException e) {
    // ...
  }

  transport.close();</pre><p>In python:</p><pre class="screen">  from hibari import Hibari

  # init
  transport = TSocket.TSocket('localhost', 7600)
  transport.setTimeout(None)
  transport = TTransport.TBufferedTransport(transport)
  protocol = TBinaryProtocol.TBinaryProtocol(transport)
  client = Hibari.Client(protocol)
  transport.open()

  # create the input parameter object
  request = Add()
  request.table = "tab1"
  request.key = b"fookey"
  request.value = b"Hello, world!"

  # send request
  response = client.Add(request)

  transport.close()</pre></div><div class="section" title="6.5.&#xA0;Mapping TBF Contract Responses From Thrift Client"><div class="titlepage"><div><div><h3 class="title"><a id="_mapping_tbf_contract_responses_from_thrift_client"></a>6.5. Mapping TBF Contract Responses From Thrift Client</h3></div></div></div><p>TBF only responses one of two generic types to all functions in Hibari
Thrift API, HibariResponse or HibariException.  One could expect a
HibariResponse in an any successful cases.  Otherwise a
HibariException should be thrown.</p></div></div><div class="section" title="7.&#xA0;Client API: JSON-RPC"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="client-api-json-rpc"></a>7. Client API: JSON-RPC</h2></div></div></div><p>Hibari’s <a class="ulink" href="http://en.wikipedia.org/wiki/JSON-RPC" target="_top">JSON-RPC</a> server
is based on the same UBF contract that is described in
<a class="xref" href="#the-hibari-ubf-protocol-contract" title="5.4.&#xA0;The Hibari UBF Protocol Contract">Section 5.4, “The Hibari UBF Protocol Contract”</a>.  But before we use it, we
need to understand how the mapping from UBF contract data types to
JSON data types is performed.</p><div class="section" title="7.1.&#xA0;Client Language Support for JSON-RPC"><div class="titlepage"><div><div><h3 class="title"><a id="client-language-support-for-json-rpc"></a>7.1. Client Language Support for JSON-RPC</h3></div></div></div><p>Hibari includes a client language support library in Erlang for
the JSON-RPC protocol.  In addition, the application developer is free to
use any programming language and any library that supports
<a class="ulink" href="http://groups.google.com/group/json-rpc/web/json-rpc-1-1-wd" target="_top">JSON-RPC
version 1.1</a></p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The Hibari JSON-RPC implementation only supports JSON-RPC
version 1.1.</p></td></tr></table></div><p>A rough implementation of JSON-RPC in Ruby is included with this
documentation bundle, see
<a class="ulink" href="./misc-codes/ruby-json-rpc-client.rb" target="_top">ruby-json-rpc-client.rb</a>.
This script will send a single JSON-RPC call and decode its response.
See the comments at the top of the file that describe its Ruby "gem"
dependency and the variables that require editing.</p></div><div class="section" title="7.2.&#xA0;Mapping UBF Contract Types to JSON Types"><div class="titlepage"><div><div><h3 class="title"><a id="mapping-ubf-contract-types-to-json"></a>7.2. Mapping UBF Contract Types to JSON Types</h3></div></div></div><p>The basic data types in UBF match the data types of Erlang, with only
one exception: the UBF <code class="literal">string()</code> type does not have an equivalent in
Erlang.</p><p>The difference between UBF types and JSON types is much larger.  JSON
does not have a type to represent <code class="literal">atom()</code> or <code class="literal">tuple()</code>.  We use the
following mapping to convert between the two representations.</p><div class="table"><a id="id36111374"></a><p class="title"><b>Table 2. Mapping of UBF contract types to JSON types</b></p><div class="table-contents"><table summary="Mapping of UBF contract types to JSON types" cellpadding="4px" style="border-collapse: collapse;border-top: 3px solid #527bbd; border-bottom: 3px solid #527bbd; border-left: 3px solid #527bbd; border-right: 3px solid #527bbd; "><colgroup><col /><col /><col /></colgroup><thead><tr><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> UBF Type  </th><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> JSON Type        </th><th style="border-bottom: 1px solid #527bbd; " align="left" valign="top"> Comment</th></tr></thead><tbody><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">true</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">true</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">false</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">false</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">undefined</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">null</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">atom()</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">{"$A" : string }</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>To disambiguate from <code class="literal">string</code> type.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">binary()</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">string</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>Must use appropriate JSON/JavaScript syntax for all non-printable ASCII characters, e.g. <code class="literal">"Two lines\nG clef = \uD834\uDD1E"</code></p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">integer()</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">int</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">list()</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">array</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">string()</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">{"$S" : string }</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="left" valign="top"><p>To disambiguate from <code class="literal">string</code> type.</p></td></tr><tr><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">tuple()</code></p></td><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">{"$T" : array }</code></p></td><td style="" align="left" valign="top"><p>To disambiguate from <code class="literal">array</code> type.</p></td></tr></tbody></table></div></div><br class="table-break" /><p>Some examples appear below:</p><pre class="screen">JSON: {"$A" : "val_len"}  "binary"      {"$S" : "string"}
UBF:  'val_len'           &lt;&lt;"binary"&gt;&gt;  {'#S', "string"}

JSON: [2, 4, 6]      {"$T" : [2, 4, 6]}            (JSON array and object)
UBF:  [2, 4, 6]      {2, 4, 6}                     (UBF list and tuple)</pre></div><div class="section" title="7.3.&#xA0;Mapping UBF Contract Requests to JSON-RPC"><div class="titlepage"><div><div><h3 class="title"><a id="mapping-ubf-contract-requests-to-json-rpc"></a>7.3. Mapping UBF Contract Requests to JSON-RPC</h3></div></div></div><p>All requests to a Hibari UBF contract take the same tuple form:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The request name is the 1st element in the tuple
</li><li class="listitem">
A variable number of arguments are stored in other elements of the
  tuple.
</li></ul></div><p title="The Hibari UBF contract&#x2019;s get_req() request"><b>The Hibari UBF contract’s <code class="literal">get_req()</code> request. </b>
</p><pre class="screen">get_req()         = {get, table(), key(), flags_list(), timeout()};</pre><p title="The Hibari UBF contract&#x2019;s get_req() request">
</p><p>The
<a class="ulink" href="http://groups.google.com/group/json-rpc/web/json-rpc-1-1-wd" target="_top">JSON-RPC
protocol version 1.1</a> requires the following four
properties be present in a JSON object that represents the RPC call:</p><div class="variablelist"><dl><dt><span class="term">
version
</span></dt><dd>
The Hibari JSON-RPC server be the JSON string "1.1".
</dd><dt><span class="term">
id
</span></dt><dd>
The request id can be any JSON type.  It is used to match the
response with the request that the server is replying to.
</dd><dt><span class="term">
method
</span></dt><dd>
A JSON string that names the RPC method to be called.
</dd><dt><span class="term">
params
</span></dt><dd>
A JSON array that contains the arguments for the RPC method.
</dd></dl></div><p>The UBF → JSON-RPC method mapping scheme uses the following rules:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
The JSON-RPC <code class="literal">method</code> property is the 1st element in the UBF request
   tuple.
</li><li class="listitem"><p class="simpara">
The JSON-RPC <code class="literal">params</code> property is a JSON array that contains the
   other elements from the UBF request tuple, in the same order.
</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p><span class="strong"><strong>Named parameters</strong></span>, as described in
<a class="ulink" href="http://groups.google.com/group/json-rpc/web/json-rpc-1-1-wd" target="_top">the
JSON-RPC specification section 6.2.1, "Named and Positional
Parameters"</a>, <span class="strong"><strong>are not supported</strong></span> .  Only the positional parameter
scheme is supported: the <code class="literal">params</code> member must be a JSON array.</p></td></tr></table></div></li></ol></div><p title="JSON-RPC requests for the UBF contract&#x2019;s get_req() and set_req() commands"><b>JSON-RPC requests for the UBF contract’s <code class="literal">get_req()</code> and <code class="literal">set_req()</code> commands. </b>
</p><pre class="screen">%% UBF get_req() instance
{get, tab1, &lt;&lt;"fookey"&gt;&gt;, [], 4000}

%% JSON-RPC equivalent
{ "id": "my id 8",
  "method": "get",
  "version": "1.1",
  "params": [
    {"$A": "tab1"},
    "fookey",
    [],
    4000
  ]}

%% UBF set_req() instance
{set, tab1, &lt;&lt;"fookey"&gt;&gt;, &lt;&lt;"Hello, world!"&gt;&gt;, 0, [{testset, 42}], 7000}

%% JSON-RPC equivalent
{ "id": "my id 22",
  "method": "set",
  "version": "1.1",
  "params": [
    {"$A": "tab1"},
    "fookey",
    "Hello, world!",
    0,
    [{"$T": [{"$A": "testset"}, 42] }],
    7000
  ]}</pre><p title="JSON-RPC requests for the UBF contract&#x2019;s get_req() and set_req() commands">
</p></div><div class="section" title="7.4.&#xA0;Mapping UBF Contract Responses From JSON-RPC"><div class="titlepage"><div><div><h3 class="title"><a id="mapping-ubf-contract-responses-from-json-rpc"></a>7.4. Mapping UBF Contract Responses From JSON-RPC</h3></div></div></div><p>As defined by the JSON-RPC 1.1 specification, the result of a
successful JSON-RPC call is signaled by an HTTP status code 200, and
the details of the call are returned in an JSON object.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
If the call was successful, the object’s <code class="literal">result</code> member contains
  the UBF response term, e.g. the <code class="literal">foo_res()</code> response term for the
  <code class="literal">foo_req()</code> call.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Note that a Hibari operation can fail, but the return result will
   still appear in the JSON reply <code class="literal">result</code> member, e.g. a <code class="literal">set</code>
   operation that fails due to a timestamp error (see
   <a class="xref" href="#json-rpc-response-contract-ok" title="JSON-RPC response to a successful UBF call that failed due to timestamp error">JSON-RPC response to a successful UBF call that failed due to timestamp error</a>).
</li></ul></div></li><li class="listitem"><p class="simpara">
If a fault occurred during processing, the object’s "error" member
  contains an arbitrary term that describes the error.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
The <code class="literal">code</code> member values of 100 and 102 signify that the client’s
   call that violated the UBF contract (see
   <a class="xref" href="#json-rpc-response-contract-error" title="JSON-RPC response to a UBF contract violation by client">JSON-RPC response to a UBF contract violation by client</a>),
</li><li class="listitem">
The <code class="literal">code</code> member values of 101 and 103 signify that the
   server’s response violated the UBF contract.  This type of
   error should not happen — please contact the Hibari development
   team to report this bug.
</li></ul></div></li></ul></div><p title="JSON-RPC response to a successful UBF call that failed due to timestamp error"><a id="json-rpc-response-contract-ok"></a><b>JSON-RPC response to a successful UBF call that failed due to timestamp error. </b>
</p><pre class="screen">{
  "result": { "$T": [ { "$A": "ts_error" }, 1273176376119065 ] },
  "error": null,
  "id": "my id 74",
  "version": "1.1"
}

%% UBF equivalent: {ts_error, 1273176376119065}</pre><p title="JSON-RPC response to a successful UBF call that failed due to timestamp error">
</p><p title="JSON-RPC response to a UBF contract violation by client"><a id="json-rpc-response-contract-error"></a><b>JSON-RPC response to a UBF contract violation by client. </b>
</p><pre class="screen">{
  "result": null,
  "error": [
    { "$T": [ { "$A": "name" }, "JSONRPCError" ] },
    { "$T": [ { "$A": "code" }, 100 ] },
    { "$T": [ { "$A": "message" }, "Parse error (clientBrokeRPC)" ] },
    { ... other data omitted ... }
  ],
  "id": "undefined",
  "version": "1.1"
}

%% UBF equivalent: [{name, "JSONRPCError"},
%%                  {code, 100},
%%                  {message, "Parse error (clientBrokeRPC)"},
%%                  ...]</pre><p title="JSON-RPC response to a UBF contract violation by client">
</p></div><div class="section" title="7.5.&#xA0;Using the JSON-RPC Client Library for Erlang"><div class="titlepage"><div><div><h3 class="title"><a id="_using_the_json_rpc_client_library_for_erlang"></a>7.5. Using the JSON-RPC Client Library for Erlang</h3></div></div></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
When using the Erlang shell for experimentation &amp; prototyping, that
   shell must have the path to the Erlang UBF client
   library in its search path.  The easiest way to do this is to use
   the arguments <code class="literal">-pz /path/to/ubf/library/ebin</code> to your Erlang
   shell’s <code class="literal">erl</code> command.
</li><li class="listitem">
Also, the path to the JSON-RPC library must be properly configured.
   The easiest way to do this is to use
   the arguments <code class="literal">-pz /path/to/ubf-jsonrpc/ebin</code> to your Erlang
   shell’s <code class="literal">erl</code> command.
</li></ol></div></td></tr></table></div><p>The normal return value of the <code class="literal">ubf_jsonrpc_inets_httpc_simple:do()</code>
function is: <code class="literal">{ok,SuccessResult,ErrorResult,IdString}</code> where:</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">SuccessResult</code>
</span></dt><dd>
The JSON-RPC return response object’s <code class="literal">result</code> member.
If there was an error, <code class="literal">SuccessResult</code> will be the atom <code class="literal">undefined</code>.
</dd><dt><span class="term">
<code class="literal">ErrorResult</code>
</span></dt><dd>
The JSON-RPC return response object’s <code class="literal">error</code> member.
If there was no error, <code class="literal">ErrorResult</code> will be the atom <code class="literal">undefined</code>.
</dd><dt><span class="term">
<code class="literal">IdString</code>
</span></dt><dd>
The same binary used for the JSON-RPC call’s <code class="literal">id</code> member.
</dd></dl></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>See the EDoc documentation for the
<code class="literal">ubf_jsonrpc_inets_httpc_simple</code> module for full details.</p></td></tr></table></div><p title="Erlang client JSON-RPC requests for the UBF contract&#x2019;s get_req() and set_req() commands"><b>Erlang client JSON-RPC requests for the UBF contract’s <code class="literal">get_req()</code> and <code class="literal">set_req()</code> commands. </b>
</p><pre class="screen">&gt; ubf_jsonrpc_inets_httpc_simple:do("http://localhost:7583/gdss", ubf_gdss_plugin,
      {get, tab1, &lt;&lt;"foo"&gt;&gt;, [], 4000}, &lt;&lt;"my id #"&gt;&gt;, [], [], false).
{ok,{ok,1273090192965707,&lt;&lt;"foo val"&gt;&gt;}, undefined,&lt;&lt;"my id #"&gt;&gt;}

&gt; ubf_jsonrpc_inets_httpc_simple:do("http://localhost:7583/gdss", ubf_gdss_plugin,
      {set, tab1, &lt;&lt;"fookey"&gt;&gt;, &lt;&lt;"Hello, world!"&gt;&gt;, 0, [{testset,42}], 4000},
      &lt;&lt;"my id #"&gt;&gt;, [], [], false).
{ok,{ts_error,1273195802235704},undefined,&lt;&lt;"my id #"&gt;&gt;}</pre><p title="Erlang client JSON-RPC requests for the UBF contract&#x2019;s get_req() and set_req() commands">
</p><p title="Erlang client JSON-RPC query that violates the contract"><b>Erlang client JSON-RPC query that violates the contract. </b>
</p><pre class="screen">&gt; ubf_jsonrpc_inets_httpc_simple:do("http://localhost:7583/gdss", ubf_gdss_plugin,
    {get, tab1, "will fail"}, &lt;&lt;"my id #"&gt;&gt;, [], [], false).
{ok,undefined,
    [{name,&lt;&lt;"JSONRPCError"&gt;&gt;},
     {code,102},
     {message,&lt;&lt;"Bad call (clientBrokeContract)"&gt;&gt;},
     {error,undefined}],
    &lt;&lt;"my id #"&gt;&gt;}</pre><p title="Erlang client JSON-RPC query that violates the contract">
</p></div><div class="section" title="7.6.&#xA0;Pointer to the Hibari UBF contract"><div class="titlepage"><div><div><h3 class="title"><a id="_pointer_to_the_hibari_ubf_contract"></a>7.6. Pointer to the Hibari UBF contract</h3></div></div></div><p>See <a class="xref" href="#the-hibari-ubf-protocol-contract" title="5.4.&#xA0;The Hibari UBF Protocol Contract">Section 5.4, “The Hibari UBF Protocol Contract”</a>.</p></div></div><div class="section" title="8.&#xA0;Client API: JSON over TCP"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="client-api-json-over-tcp"></a>8. Client API: JSON over TCP</h2></div></div></div><p>Conceptually, the Hibari server’s JSON over TCP protocol is the same
as the Hibari JSON-RPC service (see <a class="xref" href="#client-api-json-rpc" title="7.&#xA0;Client API: JSON-RPC">Section 7, “Client API: JSON-RPC”</a>) except
without the use of HTTP as an intermediate protocol.  Instead, a JSON
over TCP protocol client sends UBF contract requests, encoded using
JSON, directly over a TCP connection to the server.  The server sends
its reply, also encoded using JSON.</p><p>The JSON over TCP protocol is very similar to the UBF and EBF
protocols (see <a class="xref" href="#client-api-ubf" title="5.&#xA0;Client API: UBF">Section 5, “Client API: UBF”</a>).  See
<a class="xref" href="#using-ubf-in-any-language" title="5.3.&#xA0;Steps for Using a UBF-based Protocol in Any Language">Section 5.3, “Steps for Using a UBF-based Protocol in Any Language”</a> for an overview of the lifecycle of a
JSON over TCP client lifecycle.</p><p>See <a class="xref" href="#the-hibari-ubf-protocol-contract" title="5.4.&#xA0;The Hibari UBF Protocol Contract">Section 5.4, “The Hibari UBF Protocol Contract”</a> for details on the Hibari
UBF protocol contract.</p><div class="section" title="8.1.&#xA0;Client Language Support for JSON over TCP"><div class="titlepage"><div><div><h3 class="title"><a id="client-language-support-for-json-over-tcp"></a>8.1. Client Language Support for JSON over TCP</h3></div></div></div><p>Hibari includes a client language support library in Erlang for
the JSON over TCP protocol.  In addition, the application developer is
free to use any programming language and library that supports TCP
sockets and encoding/decoding JSON-encoded data.</p></div><div class="section" title="8.2.&#xA0;Mapping UBF Contract Types to JSON Types"><div class="titlepage"><div><div><h3 class="title"><a id="mapping-ubf-contract-types-to-json-2"></a>8.2. Mapping UBF Contract Types to JSON Types</h3></div></div></div><p>The JSON over TCP protocol uses the same UBF &lt;→ JSON type mapping
scheme that the JSON-RPC protocol uses.  See
<a class="xref" href="#mapping-ubf-contract-types-to-json" title="7.2.&#xA0;Mapping UBF Contract Types to JSON Types">Section 7.2, “Mapping UBF Contract Types to JSON Types”</a> for details.</p></div><div class="section" title="8.3.&#xA0;Mapping UBF Contract Requests to JSON and Server Responses to JSON"><div class="titlepage"><div><div><h3 class="title"><a id="mapping-ubf-contract-requests-to-json-rpc-2"></a>8.3. Mapping UBF Contract Requests to JSON and Server Responses to JSON</h3></div></div></div><p>The JSON over TCP protocol uses the same client request type and
server response type mapping scheme that the JSON-RPC protocol uses.
See <a class="xref" href="#mapping-ubf-contract-requests-to-json-rpc" title="7.3.&#xA0;Mapping UBF Contract Requests to JSON-RPC">Section 7.3, “Mapping UBF Contract Requests to JSON-RPC”</a> and
<a class="xref" href="#mapping-ubf-contract-responses-from-json-rpc" title="7.4.&#xA0;Mapping UBF Contract Responses From JSON-RPC">Section 7.4, “Mapping UBF Contract Responses From JSON-RPC”</a> for details.</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The JSON-RPC protocol describes how the server should
respond when various types of errors are encountered.  The JSON over
TCP protocol does not have a similar mechanism to inform the client of
all possible errors.  Instead, when some types of errors are
encountered, the server will simple close the TCP connection.</p></td></tr></table></div></div><div class="section" title="8.4.&#xA0;Examples of using the JSON over TCP protocol"><div class="titlepage"><div><div><h3 class="title"><a id="_examples_of_using_the_json_over_tcp_protocol"></a>8.4. Examples of using the JSON over TCP protocol</h3></div></div></div><p>Like protocols such as SMTP, the JSON over TCP server sends a banner
greeting.  The banner returns a 3-tuple:</p><div class="variablelist"><dl><dt><span class="term">
UBF type <code class="literal">atom()</code>
</span></dt><dd>
Notice to the client that the server supports version <span class="emphasis"><em>jsf1.0</em></span> of
the protocol.
</dd><dt><span class="term">
UBF type <code class="literal">string()</code>
</span></dt><dd>
The name of the UBF protocol contract that is currently in use:
<code class="literal">gdss_meta_server</code>, the Hibari UBF metaprotocol.
</dd><dt><span class="term">
UBF type <code class="literal">string()</code>
</span></dt><dd>
A greeting in English giving some URLs for where to find more
information about UBF.
</dd></dl></div><p title="Connecting to the server (using &quot;telnet&quot; command)"><b>Connecting to the server (using "telnet" command). </b>
</p><pre class="screen">% telnet localhost 7582
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
{"$T":[{"$A":"jsf1.0"},{"$S":"gdss_meta_server"},{"$S":"\n\n See http://www.sics.se/~joe/ubf/ for ..."}]}</pre><p title="Connecting to the server (using &quot;telnet&quot; command)">
</p><div class="tip" title="Tip" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/icons/tip.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The JSON over TCP server does not make any effort to
"pretty-print" its JSON output.  A JSON parser doesn’t know if a JSON
string’s formatting is pretty or ugly, but a human does know.  For the
remaining examples below, the server’s responses will be
pretty-printed for easier reading.</p></td></tr></table></div><p title="Using the metaprotocol to request the &quot;gdss&quot; contract"><b>Using the metaprotocol to request the "gdss" contract. </b>
</p><pre class="screen">%% Client sends:
{"$T": [{"$A":"startSession"}, {"$S":"gdss"}, []] }

%% Server replies:
{"$T": [
    {"$T": [{"$A": "ok"},
            {"$A": "ok"}]
    },
    {"$A": "none"}
  ]}

%% UBF equivalent: {{ok, ok}, none}</pre><p title="Using the metaprotocol to request the &quot;gdss&quot; contract">
</p><div class="tip" title="Tip" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/icons/tip.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The Hibari server contract is "stateless".  All replies terms from the
<code class="literal">ubf_client:rpc/2</code> function use the form
<code class="literal">{reply,ServerReply,UBF_StateName}</code>.  Because the Hibari server
contract is stateless, the <code class="literal">UBF_StateName</code> will always be the atom
<code class="literal">none</code>.</p></td></tr></table></div><p title="JSON over TCP requests for the UBF contract&#x2019;s get_req() and set_req() commands"><b>JSON over TCP requests for the UBF contract’s <code class="literal">get_req()</code> and <code class="literal">set_req()</code> commands. </b>
</p><pre class="screen">%% Client sends:
{"$T": [{"$A":"get"}, {"$A":"tab1"},"fookey",[],4000]}

%% Server responds:
{"$T": [
    {"$T": [{"$A": "ok"}, 1273195802235704, "Hello, world!"]},
    {"$A": "none"}
  ]}

%% UBF equivalent: {{ok, 1273195802235704, &lt;&lt;"Hello, world!"&gt;&gt;}, none}

%% Client sends:
{"$T": [{"$A":"set"}, {"$A":"tab1"},"fookey","Hello, world!",0,[{"$T":[{"$A":"testset"},42]}],4000]}

%% Server responds:
{"$T": [
    {"$T": [{"$A": "ts_error"}, 1273195802235704]},
    {"$A": "none"}
  ]}

%% UBF equivalent: {{ts_error, 1273195802235704}, none}</pre><p title="JSON over TCP requests for the UBF contract&#x2019;s get_req() and set_req() commands">
</p><div class="tip" title="Tip" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Tip"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Tip]" src="images/icons/tip.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>There is no protocol operation to end the session.  The client
can simple close the TCP connection when the connection is no longer
needed.</p></td></tr></table></div></div><div class="section" title="8.5.&#xA0;Using the JSON over TCP Client library for Erlang"><div class="titlepage"><div><div><h3 class="title"><a id="_using_the_json_over_tcp_client_library_for_erlang"></a>8.5. Using the JSON over TCP Client library for Erlang</h3></div></div></div><p>JSON over TCP support is included in the UBF Erlang client library.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The only difference between using the UBF protocol and the JSON
over TCP is the <code class="literal">ubf_client:connect()</code> call: instead of using the
property <code class="literal">{proto,ubf}</code>, use the property <code class="literal">{proto,jsf}</code> instead.</p></td></tr></table></div><p>See <a class="xref" href="#using-ubf-erlang-client" title="5.5.&#xA0;Using the UBF Client Library for Erlang">Section 5.5, “Using the UBF Client Library for Erlang”</a> for usage examples.</p></div><div class="section" title="8.6.&#xA0;Pointer to the Hibari UBF contract"><div class="titlepage"><div><div><h3 class="title"><a id="_pointer_to_the_hibari_ubf_contract_2"></a>8.6. Pointer to the Hibari UBF contract</h3></div></div></div><p>See <a class="xref" href="#the-hibari-ubf-protocol-contract" title="5.4.&#xA0;The Hibari UBF Protocol Contract">Section 5.4, “The Hibari UBF Protocol Contract”</a>.</p></div></div><div class="section" title="9.&#xA0;Managing Hibari: API overview"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_managing_hibari_api_overview"></a>9. Managing Hibari: API overview</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Add a new table
</li><li class="listitem">
Delete a table
</li><li class="listitem"><p class="simpara">
Change to a single chain:
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Add one or more bricks (increase replication factor)
</li><li class="listitem">
Remove one or more bricks (decrease replication factor)
</li></ul></div></li><li class="listitem"><p class="simpara">
Change to a single table.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Add a new chain
</li><li class="listitem">
Remove a chain
</li><li class="listitem">
Change the chain weighting factor
</li><li class="listitem">
Change consistent hashing parameters
</li></ul></div></li></ul></div><div class="section" title="9.1.&#xA0;Add a New Table: brick_admin:add_table()"><div class="titlepage"><div><div><h3 class="title"><a id="add-a-new-table"></a>9.1. Add a New Table: brick_admin:add_table()</h3></div></div></div><div class="section" title="Why use hash prefixes?"><div class="titlepage"><div><div><h4 class="title"><a id="why-use-hash-prefixes"></a>Why use hash prefixes?</h4></div></div></div><p>Hash prefixes allow Hibari servers to guarantee the application
developer that certain keys will always be stored on the same chain
and therefore always on the same set of bricks.  With this guarantee,
an application aware of hash prefixes can use micro-transactions
successfully.</p><p>For example, assume the application requires a collection of
persistent stacks that are stored in Hibari.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Each stack is identified by a string/binary.  (The two types are
  identical for the sake of discussion.)
</li><li class="listitem">
Each item stored on the stack is a string.
</li><li class="listitem">
Support stack options push &amp; pop.
</li><li class="listitem">
Support quick stack stats, e.g. # of elements on the stack and # of
  bytes stored on the stack.
</li><li class="listitem">
Stacks may contain hundreds of thousands of items.
</li><li class="listitem">
The total size of a stack will not exceed the total storage capacity
  of any single brick in the cluster.
</li></ul></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Understanding the last assumption is vital.  Because all
keys with the same hash prefix <code class="literal">H</code> will be managed by the same chain
<code class="literal">C</code>, then all bricks in <code class="literal">C</code> must have enough capacity to store all <code class="literal">H</code>
prefix keys.</p></td></tr></table></div><p>The application developer then makes the following decisions:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
The application will use a table devoted to storing stacks, called
   <code class="literal">'stack'</code>.
</li><li class="listitem">
We know that the application requires strong durability (which is
   the Hibari default) and that the sum total of all stack <span class="strong"><strong>items</strong></span> will
   exceed a single brick’s RAM capacity.  Therefore, the <code class="literal">'stack'</code>
   table must store its value blobs on disk.  Read access to the table
   will be slower than if value blobs were stored in RAM, but the
   limited RAM capacity of bricks does not give us a choice.
</li><li class="listitem"><p class="simpara">
We have two machines, <code class="literal">boxA</code> and <code class="literal">boxB</code>, available for hosting the
   table’s logical bricks.
   We want to be able to survive at least one physical brick failure,
   therefore all chains have a minimum length of 2.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
We will use two chains, so that each physical machine (when up and
   running smoothly) will have 2 logical bricks for the table, one in
   the chain head role and one in the chain tail role.
</li><li class="listitem">
The naming scheme used for each chain name and brick name can be
   arbitrary, as long as all names are unique.  However, for
   ease-of-management purposes, the use of a systematic naming scheme
   is strongly encouraged.  The scheme used here numbers each chain
   (starting at 1) and numbers each brick (also starting at 1) with
   both the chain and brick number.
</li></ul></div></li><li class="listitem"><p class="simpara">
We use the following key naming convention:
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A stack’s metadata (item count, byte count) uses <code class="literal">&lt;&lt;"/StackName/md"&gt;&gt;</code>.
</li><li class="listitem">
A item uses <code class="literal">&lt;&lt;"/StackName/N"&gt;&gt;</code> where N is the item number.
</li></ul></div></li><li class="listitem"><p class="simpara">
We create the table using the following:
</p><pre class="screen">Opts = [{hash_init, fun brick_admin:chash_init/3}, {prefix_method, var_prefix},
        {num_separators, 2}, {prefix_separator, $/},
        {new_chainweights, [{stack_ch1, 100}, {stack_ch2, 100}]},
        {bigdata_dir, "."}, {do_logging, true}, {do_sync, true}].

ChainList = [{stack_ch1, [{stack_ch1_b1, hibari1@boxA},
                          {stack_ch1_b2, hibari1@boxB}]},
             {stack_ch1, [{stack_ch2_b1, hibari1@boxB},
                          {stack_ch2_b2, hibari1@boxA}]}].

brick_admin:add_table(stack, ChainList, Opts).</pre></li></ol></div><p>See <a class="xref" href="#examples-using-the-stack" title="Examples code for using the stack">the section called “Examples code for using the stack”</a> for sample usage code.</p></div><div class="section" title="Types for brick_admin:add_table()"><div class="titlepage"><div><div><h4 class="title"><a id="types-of-brick-admin-add-table"></a>Types for brick_admin:add_table()</h4></div></div></div><pre class="screen">add_table(Name, ChainList)
  equivalent to add_table(brick_admin, Name, ChainList)

add_table(Name, ChainList, BrickOptions)
  when is_atom(Name), is_list(ChainList)
  equivalent to add_table(brick_admin, Name, ChainList, BrickOptions)

add_table(ServerRef, Name, BrickOptions)
  when is_atom(Name), is_list(BrickOptions)
  equivalent to add_table(ServerRef, Name, ChainList, [])

add_table(ServerRef::gen_server_serverref(), Name::table(),
          ChainList::chain_list(), BrickOptions::brick_options())
-&gt; ok |
   {error, term()} |
   {error, term(), term()}

gen_server_serverref() = "ServerRef" type from STDLIB gen_server, gen_fsm, etc.
proplists_property()   = "Property" type from STDLIB proplists

bigdata_option()    = {'bigdata_dir', string()}
brick()             = {logical_brick(), node()}
brick_option()      = chash_prop() |
                      custom_prop() |
                      fixed_prefix_prop() |
                      {'hash_init', fun/3} |
                      var_prefix_prop()
brick_options()     = [brick_option]
chain_list()        = {chain_name(), [brick()]}
chain_name()        = atom()
chash_prop()        = {'new_chainweights', chain_weights()} |
                      {'num_separators', integer()} |
                      {'old_float_map', float_map()} |
                      {'prefix_is_integer_hack', boolean()} |
                      {'prefix_length', integer()} |
                      {'prefix_method', 'all' | 'var_prefix' | 'fixed_prefix'} |
                      {'prefix_separator', integer()}
chain_weights()     = [{chain_name, integer()}]
custom_prop()       = proplists_property()
fixed_prefix_prop() = {'prefix_is_integer_hack', boolean()} |
                      {'prefix_length', integer()}
logging_option()    = {'do_logging', boolean()}
logical_brick()     = atom()
node()              = atom()
sync_option()       = {'do_sync', boolean()}
table()             = atom()
var_prefix_prop()   = {'num_separators', integer()} |
                      {'prefix_separator', integer()}</pre><div class="variablelist"><dl><dt><span class="term">
<code class="literal">{'bigdata_dir', string()}</code>
</span></dt><dd><p class="simpara">
To store value blobs on disk (i.e. "big data" is true), specify this
value with any string (the string’s actual value is not used).
</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>To store value blobs in RAM, this option must be omitted.</p></td></tr></table></div></dd><dt><span class="term">
<code class="literal">{'do_logging', boolean()}</code>
</span></dt><dd>
Specify whether all bricks in the table will log updates to disk.
If not specified, the default is true.
</dd><dt><span class="term">
<code class="literal">{'do_sync', boolean()}</code>
</span></dt><dd>
Specify whether all bricks in the table will synchronously flush all
updates to disk before responding to the client.
If not specified, the default is true.
</dd><dt><span class="term">
<code class="literal">{'hash_init', fun/3}</code>
</span></dt><dd>
Specify the hash initialization function.  Of the four hash methods
bundled with Hibari, we recommend using <code class="literal">brick_hash:chash_init/3</code>
only.
</dd><dt><span class="term">
<code class="literal">{'new_chainweights, chain_weights()}</code>
</span></dt><dd>
(For <code class="literal">brick_admin:chash_init/3</code>)
Specify the chainweights for this new
table.  For creating a new table, this option is not used.
However, this option is used when changing a table to
add/remove chains or to change other table-related parameters.
</dd><dt><span class="term">
<code class="literal">{'num_separators', integer()}</code>
</span></dt><dd><p class="simpara">
(For <code class="literal">brick_admin:chash_init/3</code> and <code class="literal">brick_admin:var_prefix_init/3</code>)
For variable prefix hashes, this option specifies how many instances
of the variable prefix separator character (see <code class="literal">'prefix_separator'</code>
below) are included in the hashing prefix.
The default is 2.
</p><p class="simpara">For example, if <code class="literal">{'prefix_separator', $/}</code>, then</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
With <code class="literal">{'num_separators', 2}</code> and key <code class="literal">&lt;&lt;"/foo/bar/baz/hello"&gt;&gt;</code>,
   the hashing prefix is <code class="literal">&lt;&lt;"/foo/"&gt;&gt;</code>.
</li><li class="listitem">
With <code class="literal">{'num_separators', 3}</code> and key <code class="literal">&lt;&lt;"/foo/bar/baz/hello"&gt;&gt;</code>,
   the hashing prefix is <code class="literal">&lt;&lt;"/foo/bar/"&gt;&gt;</code>.
</li></ul></div></dd><dt><span class="term">
<code class="literal">{'old_float_map', float_map()}</code>
</span></dt><dd>
Specify the old version of the "float map".
For creating a new table, this option is not used.
However, this option is used when changing a table to
add/remove chains or to change other table-related parameters: it
is used to create a new mapping of {table, key} → chain that
relocates only a minimum number of keys a new chain.
</dd><dt><span class="term">
<code class="literal">{'prefix_method', 'all' | 'var_prefix' | 'fixed_prefix'}</code>
</span></dt><dd><p class="simpara">
(For <code class="literal">brick_admin:chash_init/3</code>) Specify which prefix method will be
used for consistent hashing:
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">'all'</code>: Use the entire key
</li><li class="listitem">
<code class="literal">'var_prefix'</code>: Use a variable-length prefix of the key
</li><li class="listitem">
<code class="literal">fixed_prefix'</code>: Use a fixed-length prefix of the key
</li></ul></div></dd><dt><span class="term">
<code class="literal">{'prefix_is_integer_hack', boolean()}</code>
</span></dt><dd>
(For <code class="literal">brick_admin:fixed_prefix_init/3</code>)
If true, the prefix should be interpreted
as an ASCII representation of a base 10 integer for use as the
hash calculation.
</dd><dt><span class="term">
<code class="literal">{'prefix_length', integer()}</code>
</span></dt><dd>
(For <code class="literal">brick_admin:fixed_prefix_init/3</code>)
For a fixed-prefix hashes, this option specifies the prefix length.
</dd><dt><span class="term">
<code class="literal">{'prefix_separator', integer()}</code>
</span></dt><dd>
(For <code class="literal">brick_admin:chash_init/3</code> and <code class="literal">brick_admin:var_prefix_init/3</code>)
For variable prefix hashes, this option specifies the
single byte ASCII value of the byte
that separates the key’s prefix from the rest of the key.
The default is $/, ASCII 47.
</dd></dl></div></div><div class="section" title="Examples code for using the stack"><div class="titlepage"><div><div><h4 class="title"><a id="examples-using-the-stack"></a>Examples code for using the stack</h4></div></div></div><p title="Create a new stack"><b>Create a new stack. </b>
</p><pre class="screen">Val = #stack_md{count = 0, bytes = 0}.
brick_simple:add(stack, "/new-stack/md", term_to_binary(Val)).</pre><p title="Create a new stack">
</p><p title="Push an item onto a stack"><b>Push an item onto a stack. </b>
</p><pre class="screen">{ok, OldTS, OldVal} = brick_simple:get(stack, "/new-stack/md").
#stack_md{count = Count, bytes = Bytes} = binary_to_term(OldVal).
NewMD = #stack_md{count = Count + 1, bytes = Bytes + size(NewItem)}.
ItemKey = "/new-stack/" ++ integer_to_list(Count).
[ok, ok] = brick_simple:do(stack,
                           [brick_server:make_txn(),
                            brick_server:make_replace("/new-stack/md",
                                                      term_to_binary(NewMD),
                                                      0, [{testset, OldTS}]),
                            brick_server:make_add(ItemKey, NewItem)]).</pre><p title="Push an item onto a stack">
</p><p title="Pop an item off a stack"><b>Pop an item off a stack. </b>
</p><pre class="screen">{ok, OldTS, OldVal} = brick_simple:get(stack, "/new-stack/md").
#stack_md{count = Count, bytes = Bytes} = binary_to_term(OldVal).
ItemKey = "/new-stack/" ++ integer_to_list(Count - 1).
{ok, _, Item} = brick_simple:get(stack, ItemKey).
NumBytes = proplists:get_value(val_len, Ps).
NewMD = #stack_md{count = Count - 1, bytes = Bytes - size(Item)}.
[ok, ok] = brick_simple:do(stack,
                           [brick_server:make_txn(),
                            brick_server:make_replace("/new-stack/md",
                                                      term_to_binary(NewMD),
                                                      0, [{testset, OldTS}]),
                            brick_server:make_delete(ItemKey)]).
Item.</pre><p title="Pop an item off a stack">
</p></div></div><div class="section" title="9.2.&#xA0;Delete a Table"><div class="titlepage"><div><div><h3 class="title"><a id="delete-a-table"></a>9.2. Delete a Table</h3></div></div></div><p>As yet, Hibari does not have a method to delete a table.  The only
methods available now are:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Delete all files and subdirectories from the <code class="literal">bootstrap_*</code> brick
  data directories, restart the Admin Server, and recreate all tables.
  (Also known as, "Start over".)
</li><li class="listitem">
Make a backup copy of all <code class="literal">bootstrap_*</code> brick data directories
  before creating a new table.  If you wish to undo, then stop Hibari
  on all Admin Server-eligible nodes, remove the <code class="literal">bootstrap_*</code> brick
  data directories, restore the <code class="literal">bootstrap_*</code> brick data directories
  from the previous backup, then start all of the Admin
  Server-eligible nodes.
</li></ul></div></div><div class="section" title="9.3.&#xA0;Change a Chain: Add or Remove Bricks"><div class="titlepage"><div><div><h3 class="title"><a id="change-a-chain-add-remove-bricks"></a>9.3. Change a Chain: Add or Remove Bricks</h3></div></div></div><p>Adding or removing bricks from a single chain changes the replication
factor for the keys stored in that chain: more bricks increases the
replication factor, and fewer bricks decreases it.</p><p title="Data types for brick_admin:change_chain_length()"><b>Data types for brick_admin:change_chain_length(). </b>
</p><pre class="screen">brick_admin:change_chain_length(ChainName, BrickList)

ChainName       = atom()
BrickList       = [brick()]

brick()         = {logical_brick(), node()}
logical_brick() = atom()
node()          = atom()</pre><p title="Data types for brick_admin:change_chain_length()">
</p><p>See also,
<a class="link" href="#example-change-chain-length"><code class="literal">brick_admin:change_chain_length()</code> usage examples</a>
<a class="xref" href="#example-change-chain-length">Section 3.9, “Changing Chain Length”</a>.</p></div><div class="section" title="9.4.&#xA0;Change a Table: Add/Remove Chains"><div class="titlepage"><div><div><h3 class="title"><a id="change-a-table-add-remove-chains"></a>9.4. Change a Table: Add/Remove Chains</h3></div></div></div><p title="Data types for brick_admin:start_migration()"><b>Data types for brick_admin:start_migration(). </b>
</p><pre class="screen">brick_admin:start_migration(TableName, LH)
  equivalent to brick_admin:start_migration(TableName, LH, [])

brick_admin:start_migration(TableName, LH, Options)
-&gt; {ok, cookie()} |
   {'EXIT', term()}

TableName           = atom()
LH                  = hash_r()
Options             = migration_options()

cookie()            = term()
migration_option()  = {'do_not_initiate_serial_ack', boolean()} |
                      {'interval', integer()} |
                      {'max_keys_per_chain', integer()} |
                      {'max_keys_per_iter', integer()} |
                      {'propagation_delay', integer()}
migration_options() = [migration_option()]

brick_admin:chash_init('via_proplist', ChainList, Options)
-&gt; hash_r()

ChainList = chain_list()
Options   = brick_options()</pre><p title="Data types for brick_admin:start_migration()">
</p><p>See <a class="xref" href="#types-of-brick-admin-add-table" title="Types for brick_admin:add_table()">the section called “Types for brick_admin:add_table()”</a> for definitions of
<code class="literal">chain_list()</code> and <code class="literal">brick_options()</code> types.</p><p>The <code class="literal">hash_r()</code> type is an Erlang record, <code class="literal">#hash_r</code> as defined in the
<code class="literal">brick_hash.hrl</code> header file.  It is normally considered an opaque
type that is created by a function such as <code class="literal">brick_hash:chash_init/3</code>.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The options list passed in argument #3 to
<code class="literal">brick_admin:chash_init/3</code> is the same properties list that is used
for <code class="literal">brick_admin:add_table/3</code>.  The difference is that the options
that are related strictly to brick behavior, such as the <code class="literal">do_logging</code>
and <code class="literal">do_sync</code> properties, are ignored by <code class="literal">chash_init/3</code>.</p></td></tr></table></div><p>Once a <code class="literal">hash_r()</code> term is created and <code class="literal">brick_admin:start_migration/2</code>
is called successfully, the data migration will start immediately.</p><p>The <code class="literal">cookie()</code> type is an opaque term that uniquely identifies the
data migration that was triggered for the <code class="literal">TableName</code> table.  Another
data migration may not be triggered until the current migration has
finished successfully.</p><p>The <code class="literal">migration_option()</code> properties are described below:</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">{'do_not_initiate_serial_ack', boolean()}</code>
</span></dt><dd>
For internal use only, do not use.
</dd><dt><span class="term">
<code class="literal">{'interval', integer()}</code>
</span></dt><dd>
Interval (in milliseconds) to send kick_next_sweep messages.
Default = 50.
</dd><dt><span class="term">
<code class="literal">{'max_keys_per_chain', integer()}</code>
</span></dt><dd>
Maximum number of keys
to send to any particular chain.  Not yet implemented.
</dd><dt><span class="term">
<code class="literal">{'max_keys_per_iter', integer()}</code>
</span></dt><dd>
Maximum number of keys to examine per sweep iteration.
Default = 500 for bricks with value blobs in RAM, 25 for bricks with
value blobs on disk.
</dd><dt><span class="term">
<code class="literal">{'propagation_delay', integer()}</code>
</span></dt><dd>
Number of milliseconds to delay for each brick’s logging operation.
Default = 0.
</dd></dl></div><p>See also <a class="xref" href="#changing-chains-example" title="3.10.&#xA0;Creating New/Deleting Current/Reweighting/Rehashing Chains">Section 3.10, “Creating New/Deleting Current/Reweighting/Rehashing Chains”</a>.</p></div><div class="section" title="9.5.&#xA0;Change a Table: Change Chain Weighting"><div class="titlepage"><div><div><h3 class="title"><a id="change-a-table-chain-chain-weighting"></a>9.5. Change a Table: Change Chain Weighting</h3></div></div></div><p>The functions to change chain weighting are the same for
adding/removing chains, see <a class="xref" href="#change-a-table-add-remove-chains" title="9.4.&#xA0;Change a Table: Add/Remove Chains">Section 9.4, “Change a Table: Add/Remove Chains”</a>
for additional details.</p><p>When creating a <code class="literal">hash_r()</code> type record, follow these two bits of
advice:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The <code class="literal">chain_list()</code> term remains exactly the same as the chain list
  currently used by the table.  See
  <code class="literal">brick_admin:get_table_chain_list/1</code> for how to retrieve this list.
</li><li class="listitem">
The <code class="literal">new_chainweights</code> property in the <code class="literal">brick_options()</code> list
  specifies a different set of chain weighting factors than is
  currently used by the table.  The current chain weighting list is in
  the <code class="literal">brick_options</code> property returned by the
  <code class="literal">brick_admin:get_table_info/1</code> function.
</li></ul></div><p>See also <a class="xref" href="#changing-chains-example" title="3.10.&#xA0;Creating New/Deleting Current/Reweighting/Rehashing Chains">Section 3.10, “Creating New/Deleting Current/Reweighting/Rehashing Chains”</a>.</p></div><div class="section" title="9.6.&#xA0;Admin Server API"><div class="titlepage"><div><div><h3 class="title"><a id="admin-server-api"></a>9.6. Admin Server API</h3></div></div></div><p>See EDoc documentation for <code class="literal">brick_admin.erl</code> API.</p></div><div class="section" title="9.7.&#xA0;Scoreboard API"><div class="titlepage"><div><div><h3 class="title"><a id="scoreboard-api"></a>9.7. Scoreboard API</h3></div></div></div><p>See EDoc documentation for <code class="literal">brick_sb.erl</code> API.</p></div><div class="section" title="9.8.&#xA0;Chain Monitor API"><div class="titlepage"><div><div><h3 class="title"><a id="chain-monitor-api"></a>9.8. Chain Monitor API</h3></div></div></div><p>See EDoc documentation for <code class="literal">brick_chainmon.erl</code> API.</p></div></div><div class="section" title="10.&#xA0;Hibari Internals: The Source, Module by Module"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_hibari_internals_the_source_module_by_module"></a>10. Hibari Internals: The Source, Module by Module</h2></div></div></div><p>It would be wonderful to say that Hibari sprang from someone’s
forehead, fully formed and adult, like the goddess Athena’s birth from
the forehead of Zeus.  Software development is usually a bit more
organic and unplanned than that.  Hibari is no exception.</p><p>Once upon a time, in a galaxy far, far away … Hibari started as a
small, focused replacement for Mnesia, the database bundled with
Erlang/OTP.  Gemini Mobile was bidding on a project that required an
extremely high throughput database, with high availability and data
durability guarantees for a workload with a very low read/write ratio
(i.e. very write-intensive).  The amount of money dedicated to
hardware was fixed.  Mnesia could do the job very well, except for the
throughput.  Gemini needed something both faster and simpler.  The
skeleton of Hibari was written in haste, in case Gemini got the
contract.</p><p>Fortunately, Gemini lost the bid for the contract.  Hibari sat on the
shelf for a while, then picked up and developed as a main memory
database, like Mnesia.  Then requirements changed.  Then a project was
canceled, and Hibari set aside.  Then picked up and set aside again.
Each time, requirements changed.</p><p>Hindsight is perfect.  This section will attempt to give the reader,
developers who are maintaining Hibari or adding new features, some
background for why the code is structured the way it is.  The APIs for
some modules are straightforward to use, and others are not so clear.
Some modules were written together in a brief period of time, and
other evolved slowly over several years.</p><div class="section" title="10.1.&#xA0;Major subsystems"><div class="titlepage"><div><div><h3 class="title"><a id="major-subsystems"></a>10.1. Major subsystems</h3></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Server (aka the brick)
</li><li class="listitem">
Chain replication
</li><li class="listitem">
Consistent hashing
</li><li class="listitem">
Client
</li><li class="listitem">
Admin Server
</li><li class="listitem">
Miscellaneous
</li></ul></div><div class="section" title="Server (aka the &quot;logical brick&quot;) modules"><div class="titlepage"><div><div><h4 class="title"><a id="server-modules"></a>Server (aka the "logical brick") modules</h4></div></div></div><p>As described in the
<a class="ulink" href="hibari-sysadmin-guide.en.html#bricks-outside-chain-replication" target="_top">Hibari
Sysadmin Guide, "Bricks outside of chain replication" section</a>, a
Hibari logical brick can be used with or without chain replication.
When used without chain replication, each brick is a standalone data
storage entity.  Any replication of data across logical bricks must be
done by the client, typically by a “quorum replication” technique.</p><p>The source modules that implement the logical brick are divided into
two groups:</p><div class="variablelist"><dl><dt><span class="term">
Write-ahead logging, aka disk persistence
</span></dt><dd><p class="simpara">
The following modules
maintain the write-ahead logs on disk.  See the
<a class="ulink" href="hibari-sysadmin-guide.en.html#write-ahead-logs" target="_top">Hibari
Sysadmin Guide, "Write-Ahead Logs" section</a> for a description of the
two types of write-ahead log and how they interact with each other.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">gmt_hlog.erl</code>
</li><li class="listitem">
<code class="literal">gmt_hlog_common.erl</code>
</li><li class="listitem">
<code class="literal">gmt_hlog_local.erl</code>
</li></ul></div></dd><dt><span class="term">
Protocol service and in-memory data management
</span></dt><dd><p class="simpara">
The following modules
handle Hibari client requests and manage the in-core binary trees used
for key management:
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_ets.erl</code>
</li><li class="listitem">
<code class="literal">brick_server.erl</code>
</li></ul></div></dd></dl></div></div><div class="section" title="Chain replication modules"><div class="titlepage"><div><div><h4 class="title"><a id="chain-replication-modules"></a>Chain replication modules</h4></div></div></div><p>The chain replication algorithm is implemented in <code class="literal">brick_server.erl</code>.
That module also contains server and client code, which helps explain
why it’s the largest source module in the Hibari application.</p></div><div class="section" title="Consistent hashing modules"><div class="titlepage"><div><div><h4 class="title"><a id="consistent-hashing-modules"></a>Consistent hashing modules</h4></div></div></div><p>The consistent hashing algorithm is implemented in the
<code class="literal">brick_simple.erl</code> module.  The code in this module has two roles:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The "gen_server" callbacks for the <code class="literal">brick_simple</code> registered process
  that runs on each brick node.  This server receives updates from the
  Admin Server when there are changes to chain membership.
</li><li class="listitem">
Client-side stub functions, executed by a Hibari client application,
  to implement the client API that uses consistent hashing.
</li></ul></div></div><div class="section" title="Client modules"><div class="titlepage"><div><div><h4 class="title"><a id="client-modules"></a>Client modules</h4></div></div></div><p>Hibari clients fall into two categories: those that use consistent
hashing and those that do not.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
As described in <a class="xref" href="#consistent-hashing-modules" title="Consistent hashing modules">the section called “Consistent hashing modules”</a>, the
  <code class="literal">brick_simple.erl</code> module implements the client API that uses
  consistent hashing.
</li><li class="listitem">
The <code class="literal">brick_server.erl</code> module implements the low-level client API
  that is not aware of consistent hashing.
</li><li class="listitem">
The <code class="literal">brick_squorum.erl</code> module is a partial implementation of a
  “quorum replication” method for managing data consistency across
  multiple logical bricks.  This module is used only by the Admin
  Server and is tailored to the Admin Server’s use.  It should not be
  used by other quorum replication-based applications.
</li></ul></div></div><div class="section" title="Admin Server modules"><div class="titlepage"><div><div><h4 class="title"><a id="admin-server-modules"></a>Admin Server modules</h4></div></div></div><p>See <a class="ulink" href="hibari-sysadmin-guide.en.html#admin-server-app" target="_top">Hibari
Sysadmin Guide, "The Admin Server Application" section</a> for a
description of the various services provided by the Admin Server
application.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_admin.erl</code> provides the major external API to most of the
  Admin Server’s function as well as basic table management
  functions.
</li><li class="listitem">
<code class="literal">brick_bp.erl</code> implements the “brick pinger” processes.  Each
  pinger process is responsible for monitoring the health of a single
  Hibari logical brick.
</li><li class="listitem">
<code class="literal">brick_chainmon.erl</code> implements the “chain monitor” processes.
  Each chain monitor is responsible for monitoring the status of a
  single Hibari chain and to reconfigure the chain safely as its member
  bricks crash and restart.
</li><li class="listitem">
<code class="literal">brick_migmon.erl</code> implements the server process that is responsible
  for monitoring data migrations that take place whenever chains are
  added, deleted, or reweighted.
</li><li class="listitem">
<code class="literal">brick_sb.erl</code> implements the “scoreboard” process, which provides
  historical data about each brick and chain state transition.
</li></ul></div></div><div class="section" title="Miscellaneous modules"><div class="titlepage"><div><div><h4 class="title"><a id="misc-modules"></a>Miscellaneous modules</h4></div></div></div><p>These modules do a variety of things, including the Erlang/OTP
application and supervisor behaviors that create a single, cohesive
application.  They will be described in more detail below.</p></div></div><div class="section" title="10.2.&#xA0;Admin Server notes: crash-recovery design"><div class="titlepage"><div><div><h3 class="title"><a id="admin-server-crash-recovery"></a>10.2. Admin Server notes: crash-recovery design</h3></div></div></div><p>The <a class="xref" href="#admin-server-modules" title="Admin Server modules">the section called “Admin Server modules”</a> indirectly outlines many of the
processes that, when grouped together, form the Hibari Admin Server
application:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The main Admin Server process.
</li><li class="listitem">
Many “brick pinger” processes
</li><li class="listitem">
Many “chain monitor” processes
</li><li class="listitem">
The “migration monitor” process
</li><li class="listitem">
The “scoreboard” process
</li><li class="listitem">
… and several other long- and short-lived processes,
  discussed in xref:module-by-module-commentary.
</li></ul></div><p>Acting together, these processes maintain data consistency for all
bricks in a Hibari cluster.  However, individual processes can crash
and restart at unpredictable times.  The Admin Server must be able to
recover correctly from a failure of any number of its helper
processes, regardless of timing.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The Admin Server implementation was written for correctness
first and for speed/efficiency only when necessary.  It has been used
in production environments with rough total of 2,000 logical brick
pinger and chain monitor processes.  At this scale, the implementation
shows signs of stress under the worst-case scenario of "Restart the
Admin Server <span class="strong"><strong>and</strong></span> all logical bricks on <span class="strong"><strong>all</strong></span> physical bricks
simultaneously", but it works none-the-less.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-admin-monitor"></a></th></tr><tr><td align="left" valign="top"><p>An increase in size by a factor of 4 or 5 will probably hit the limits
of the current implementation.  It’s likely that splitting the Admin
Server monolith into separate sub-servers, perhaps each servicing a
single table, would be a good refactoring task?</p></td></tr></table></div></td></tr></table></div><p>The architecture decision to have one Admin Server process, one
scoreboard process, one pinger process per brick and one health
monitor per chain is quite intentional.  If there is only one at a
given time performing a given task, then there cannot be race
conditions.</p></div><div class="section" title="10.3.&#xA0;Module-By-Module Commentary"><div class="titlepage"><div><div><h3 class="title"><a id="module-by-module-commentary"></a>10.3. Module-By-Module Commentary</h3></div></div></div><p>The modules in this section appear in alphabetical order.  For an
overview of their use by functional category, see
<a class="xref" href="#major-subsystems" title="10.1.&#xA0;Major subsystems">Section 10.1, “Major subsystems”</a>.</p><div class="section" title="brick.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-erl"></a>brick.erl</h4></div></div></div><p>This module provides the Erlang/OTP "application" behavior for the
Hibari application.  Such modules are usually quite small.  The reason
why <code class="literal">brick.erl</code> doesn’t fit the small pattern is that it has some
extra logic to shutdown logical bricks in a particular order when
application shutdown has been requested.</p></div><div class="section" title="brick_admin.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-admin-erl"></a>brick_admin.erl</h4></div></div></div><p>Please see <a class="ulink" href="hibari-sysadmin-guide.en.html#admin-server-app" target="_top">Hibari
Sysadmin Guide, "The Admin Server Application" section</a> for a
description of the Admin Server’s various functions.</p><p>The Admin Server has a "schema", though perhaps that’s a poor choice
of name.  The schema defines:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Each Hibari table
</li><li class="listitem">
The consistent hashing <code class="literal">{TableName, Key}</code> → chain mapping
</li><li class="listitem">
Status of any data migrations
</li></ul></div><p>The schema, together with the “scoreboard” operational history, is
stored in the “bootstrap bricks”.
See <a class="ulink" href="hibari-sysadmin-guide.en.html#bootstrap-bricks" target="_top">Hibari
Sysadmin Guide, "Admin Server’s Private State: the Bootstrap Bricks" section</a>
and <a class="ulink" href="hibari-sysadmin-guide.en.html#bricks-outside-chain-replication" target="_top">Hibari
Sysadmin Guide, "Bricks outside of chain replication" section</a> for
more details.</p><p>Functions for creating a new schema and defining the names of the
bootstrap bricks that will store the schema are in this module.  So
are assorted functions for querying the schema, such as
<code class="literal">brick_admin:get_tables/0</code> and <code class="literal">brick_admin:get_table_chain_list/2</code>.
Changes to chain length and chain addition/deletion/reweighting are
also available here.</p><div class="section" title="Global Hash spamming"><div class="titlepage"><div><div><h5 class="title"><a id="_global_hash_spamming"></a>Global Hash spamming</h5></div></div></div><p><a id="spamming-the-global-hash"></a>When a chain health monitor process makes a major state transition, it
will notify the Admin Server of the change.  The Admin Server will
then broadcast, or "spam" status notifications to all server and
client nodes.  The data structure spammed is a <code class="literal">#g_hash_r</code> record, or
simply a "global hash record". This record is maintained by the admin
server per table. Each table has its own unique global hash record.</p><div class="sidebar"><p class="title"><b></b></p><p>For Erlang nodes running the full Hibari application, these global
hash pushes are automatic and require no extra configuration.</p><p>For Erlang nodes that run only the Hibari client application
(called <code class="literal">gdss_client</code>), <span class="strong"><strong>additional configuration is required</strong></span> to add that
node’s name to the client spam list. This is because the admin server
uses the output of the nodes() function to know what clients it needs to
spam the global hash to. Client monitoring causes nodes which are alive to
be connected to the admin server automatically. See:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The "Client monitoring API" comment in the exports section at the
top of brick_admin.erl
</li><li class="listitem">
and/or the "Add/Delete a client node monitor" link at the bottom of
the Admin Server HTTP top-level status page at port 23080.
</li></ul></div></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Among other things, the global hash contains the bricks
and their roles in each chain. In this manner, a gdss client can
know which chain a key belongs to and what brick in that chain
is acting as head or tail. In this manner they can talk directly
to the correct brick for a given operation.</p></td></tr></table></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The admin server increments a minor revision number in the global hash
for each update. Bricks and clients can then compare this revision number
to what they already have to ensure that they don’t revert to using
an older global hash.</p></td></tr></table></div></div><div class="section" title="&quot;Fast Sync&quot; utility"><div class="titlepage"><div><div><h5 class="title"><a id="_fast_sync_utility"></a>"Fast Sync" utility</h5></div></div></div><p>The <code class="literal">brick_admin:fast_sync()</code> family of functions are an attempt to
help Hibari cluster administrators to perform bulk-copies of data from
in-service bricks to bricks that have zero data.  For example,
consider a physical brick has crashed due to data loss caused by a
hard disk failure.  The crashed brick can be put back into service
after fixing the disk problem, but the brick’s data has been lost.
Chain replication can create new replicas of the lost data, but the
chain replication implementation can create a lot of disk I/O on the
upstream brick for long periods of time, e.g. several days for
terabytes of data.  The <code class="literal">fast_sync()</code> function attempts to minimize
the amount of random disk I/O by copying keys &amp; values in file+offset
sorted order.</p><p>See <a class="xref" href="#scavenger-and-code-reuse" title="Scavenger and code reuse">the section called “Scavenger and code reuse”</a>.</p></div><div class="section" title="Processes created by brick_admin.erl"><div class="titlepage"><div><div><h5 class="title"><a id="brick-admin-erl-processes"></a>Processes created by brick_admin.erl</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A "gen_server" for the Admin Server main process.
</li><li class="listitem">
The “bootstrap scan” process, which scans all keys in the
  bootstrap bricks every 5 seconds and repairs any inconsistencies
  created by crashing &amp; restarting bootstrap bricks and/or a crash of
  the Admin Server itself.
</li><li class="listitem">
Each request to "spam" a new global hash record to all servers and
  clients will spawn a process to send the new global hash to all
  server nodes and then all <code class="literal">brick_simple</code> servers on all nodes.
</li><li class="listitem">
The "fast sync" bulk data copy API will spawn a process to
  coordinate the bulk data copy activities.
</li></ul></div></div></div><div class="section" title="brick_admin_event_h.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-admin-event-h-erl"></a>brick_admin_event_h.erl</h4></div></div></div><p>The Admin Server registers the brick_admin_event_h.erl as an event
handler with the partition detector application.  It’s
<code class="literal">handle_event()</code> function takes action for two kinds of events:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
If a network heartbeat alarm is set, an app log message is
  generated.  If the alarm is on the <span class="emphasis"><em>A</em></span> network, that node is
  forcibly disconnected from the VM’s <code class="literal">net_kernel</code> services.
</li><li class="listitem">
If another Admin Server instance is detected, the Hibari application
  will be stopped and the VM halted.
</li></ul></div></div><div class="section" title="brick_admin_sup.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-admin-sup-erl"></a>brick_admin_sup.erl</h4></div></div></div><p>This is the supervisor for Admin Server-related processes.  If the
Admin Server application is not running, this supervisor will have no
children to monitor.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>A careful reader will notice that the preceding paragraph
contains a contradiction.  The Hibari <code class="literal">gdss</code> application is an OTP
application.  This document speaks of the Admin Server as being a
separate OTP application, because the Admin Server is managed by the
OTP kernel’s application controller.</p><p>The contradiction is: the Admin Server’s processes are supervised by
another application’s supervisor.</p></td></tr></table></div><p>The simple answer is: the Admin Server is not a 100% OTP-compliant
application.</p><p>The complicated answer is: it is complicated.  There’s so much
day-to-day developer activity that relies on the Admin Server that
it’s really inconvenient to package the Admin Server as a 100%
OTP-compliant application.  It’s much, much more convenient to have
its source code and its processes mixed in with the rest of the Hibari
server code and processes.</p><p>So, the Admin Server application is OTP-compliant enough to be managed
by the OTP application controller.  But it is conveniently managed,
source-wise and process-wise, within the Hibari/<code class="literal">gdss</code> application as
a whole.</p></div><div class="section" title="brick_bp.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-bp-erl"></a>brick_bp.erl</h4></div></div></div><p>This module implements the “brick pinger” server: a "gen_fsm"
process that is responsible for polling the health of a single logical
brick.  The Admin Server starts a "brick pinger" process for each
logical brick in each chain in every table.
See the
<a class="ulink" href="hibari-sysadmin-guide.en.html#brick-lifecycle-fsm" target="_top">Hibari
Sysadmin Guide, "Brick Lifecycle Finite State Machine" section</a> for a
description of the state machine implemented by this module.</p><p>A 1-second periodic timer is used to check the status of the brick
that this FSM monitors.  Any major changes in status will be sent as a
proplist to the "scoreboard" proc (see <a class="xref" href="#brick-chainmon-erl" title="brick_chainmon.erl">the section called “brick_chainmon.erl”</a>) .</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-brick-bp"></a></th></tr><tr><td align="left" valign="top"><p>There are two areas where this module could use some refactoring:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
This "gen_fsm" module isn’t very FSM-ish in style; it more resembles
"gen_server" style programming instead of "gen_fsm".
</li><li class="listitem"><p class="simpara">
The current communication pattern for health monitoring is too
brittle.  When a "pinger" detects a change of state, it informs the
"scoreboard" process.  But the "scoreboard" server does not actively
notify the chain monitor process; instead, the "chain monitor" process
polls the scoreboard and then calculates changes in brick state based
on the results of the previous polling.  This can cause information
about state changes to get lost.
</p><p class="simpara">The "pinger" and "chain monitor" processes are now quite robust in
dealing with corner cases where state changes happen really rapidly,
but the result is code that’s more complex and difficult to maintain
than it should be.</p></li></ul></div></td></tr></table></div><p>Health polling is based on two attributes: brick repair state and
brick repair time.  Due to the polling nature of this interface (a
weakness, see the "NOTE" section above), it’s possible that a logical
brick in certain repair states X could crash, restart, and reenter the
state X before the "pinger" polled again.  The logical brick’s start
time is checked to make certain that the "pinger" is talking to the
same PID over time.</p><div class="section" title="Processes created by brick_bp.erl"><div class="titlepage"><div><div><h5 class="title"><a id="_processes_created_by_brick_bp_erl"></a>Processes created by brick_bp.erl</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A long-lived process starts running the <code class="literal">brick_monitor_simple()</code>
  function, which creates a monitor to the remote logical brick and
  then waits for a <code class="literal">{'DOWN', ...}</code> message from that monitor.
</li><li class="listitem">
When an illegal state transition has been detected, a short-lived
  function is spawned to kill the remote node before it does something
  even more illegal than it already has.
</li></ul></div></div></div><div class="section" title="brick_brick_sup.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-brick-sup-erl"></a>brick_brick_sup.erl</h4></div></div></div><p>This is the direct supervisor for all logical bricks that run on this
node.  The <code class="literal">brick_shepherd.erl</code> module provides the interface used to
request that this supervisor start &amp; stop a logical brick.</p></div><div class="section" title="brick_chainmon.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-chainmon-erl"></a>brick_chainmon.erl</h4></div></div></div><p>This module implements the “chain monitor” server: a "gen_fsm"
process that is responsible for monitoring the health of all logical
bricks within a single chain.  The Admin Server starts a "chain
monitor" for each chain in every table.
See the
<a class="ulink" href="hibari-sysadmin-guide.en.html#chain-lifecycle-fsm" target="_top">Hibari
Sysadmin Guide, "Chain Lifecycle Finite State Machine" section</a> for a
description of the state machine implemented by this module.</p><p>See the <a class="xref" href="#brick-bp-erl" title="brick_bp.erl">the section called “brick_bp.erl”</a> for an overview of the polling method used
by both the brick health "pinger" processes, the "chain monitor"
processes, and the "scoreboard" and that method’s known limitations.</p><p>In addition to monitoring health, the chain monitor proc is
responsible for taking actions required to repair the chain.</p><p>Chain member status is tricky to calculate correctly.  Any chain
monitor process may crash at any time (e.g. due to bugs), or the
entire machine hosting the monitor may crash.  When the monitor has
restarted, it doesn’t know how many times chain members may have
changed state.</p><p>Each monitor queries the "scoreboard" to get the current status of
each chain member.  (Remember: The scoreboard’s info may be slightly
out-of-date!)  Each current status is compared with the monitor’s
in-memory history of the status during the last check.  (All bricks
start in the <code class="literal">unknown</code> state.)  If there’s a difference, then suitable
action is taken.</p><p>Also, any change in brick or chain status is also reported to the
scoreboard.</p><p>Each brick’s scoreboard status is converted to an internal status:</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">unknown</code>
</span></dt><dd>
The brick’s status is not known.
</dd><dt><span class="term">
<code class="literal">disk_error</code>
</span></dt><dd>
The brick has hit a disk checksum error and has
  not been able to initialize itself 100%.
</dd><dt><span class="term">
<code class="literal">pre_init</code>
</span></dt><dd>
The brick is running and ping’able, but the
  brick is not in service, and the state of the brick’s local
  storage is unknown.
</dd><dt><span class="term">
<code class="literal">repairing</code>
</span></dt><dd>
The monitor has chosen this brick to be the next
  brick to resume service in the chain.  Its local storage is actively
  being repaired by chain’s current tail.
</dd><dt><span class="term">
<code class="literal">repair_overload</code>
</span></dt><dd>
If a brick was in ‘repairing’ state and was
  determined to be overloaded (usually by too much disk I/O),
  the node can be switched to this state to halt repair.
</dd><dt><span class="term">
<code class="literal">ok</code>
</span></dt><dd>
The brick is fully in-sync with the rest of the chain
  and is in service in its correct chain role.
</dd></dl></div><p>There are times when the chain monitor detects a chain that has zero
running bricks.  It must then examine the operational history of all
bricks in the chain and determine which is the best brick to start
first.  This must be the last brick to crash.  The chain monitor will
wait forever for that "best brick" to start.  If it is impossible to
start (for example, the machine was destroyed by fire, or data was
lost due to a disk failure), then a human may use the
<code class="literal">force_best_first_brick()</code> function to give permission to the chain
monitor to start another brick as the chain’s first brick.</p><p>There are times when a chain monitor restarts and discovers that some
or all bricks in the chain are running.  However, the new chain
monitor cannot know exactly what roles each brick was in without
polling each one … and because a chain transition may have been
interrupted by a chain monitor crash, it is quite tricky to make
correct decisions about what running bricks are OK and which ones are
not.</p><p>The uncertainty of each brick’s exact status could be addressed by
more logging of intermediate states to the Admin Server’s private
state (i.e. stored in the <code class="literal">bootstrap_copy</code>* bricks).  But each write
to that private state has an overhead that, when multiplied by
thousands of bricks and hundreds of chains, is quite significant.</p><p>When a chain monitor starts, it attempts to calculate the chain’s
status.  If the chain was <code class="literal">healthy</code> before the monitor crash, the chain
will be deemed <code class="literal">healthy</code>.  If the chain was <code class="literal">degraded</code>, then it’s
likely that the chain will be "whittled down" to a single brick and
then reconstructed using the chain repair protocol.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-brick-chainmon"></a></th></tr><tr><td align="left" valign="top"><p>The reconstruction of the exact repair state &amp; role of each brick in a
chain should be refactored to be smarter and therefore reduce the
total time required to return a chain to <code class="literal">healthy</code> state in more/all
failure scenarios.  The current implementation is pretty conservative
and has room for improvement.</p></td></tr></table></div><p>The <code class="literal">process_brickstatus_diffs()</code> function is a long, long bear of a
function.  Refactoring it would be useful, even necessary if the
polling-based mechanism were changed (as suggested elsewhere).  But it
encodes a lot of hard-won knowledge of how to maintain data
consistency under really weird, hard-to-find and hard-to-fix bugs over
more than two years of testing and production use.</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Read the code and the comments before embarking on any
refactoring journey.</p></td></tr></table></div><div class="section" title="Processes created by brick_chainmon.erl"><div class="titlepage"><div><div><h5 class="title"><a id="_processes_created_by_brick_chainmon_erl"></a>Processes created by brick_chainmon.erl</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The <code class="literal">digraph</code> stdlib module is used for chain status reconstruction.
  A separate process is used to idiot-proof and exception-proof the
  cleanup of ETS tables and other resources used by that library
  code.
</li></ul></div></div></div><div class="section" title="brick_cinfo.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-cinfo-erl"></a>brick_cinfo.erl</h4></div></div></div><p>This module implements the callbacks for the OTP application
<code class="literal">cluster_info</code>, bundled with Hibari.  Functions such as
<code class="literal">cluster_info:dump_all_connected/1</code> can be used to write a huge amount
of diagnostic information about the cluster.</p><p>At startup time, both the <code class="literal">gdss</code> and <code class="literal">gdss_client</code> applications
register a callback with the <code class="literal">cluster_info</code> application.</p></div><div class="section" title="brick_client_data_sup.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-client-data-sup-erl"></a>brick_client_data_sup.erl</h4></div></div></div><p>This is a supervisor used by the <code class="literal">gdss_client</code> application.</p></div><div class="section" title="brick_client.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-client-erl"></a>brick_client.erl</h4></div></div></div><p>This is the start/stop module for the <code class="literal">gdss_client</code> application.  If
the <code class="literal">gdss</code> application is not running on each node that a Hibari
client application runs, then the lighter-weight <code class="literal">gdss_client</code>
application must be running.</p></div><div class="section" title="brick_clientmon.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-clientmon-erl"></a>brick_clientmon.erl</h4></div></div></div><p>This process implements a "gen_server" that monitor the condition of
each client node that is monitored by the Admin Server.  See the
<code class="literal">brick_admin:run_client_monitor_procs()</code> function for the definition
of the funs used when the client monitor sense that a client node has
stopped or started.</p></div><div class="section" title="brick_client_sup.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-client-sup-erl"></a>brick_client_sup.erl</h4></div></div></div><p>This is a supervisor used by the <code class="literal">gdss_client</code> application.</p></div><div class="section" title="brick_data_sup.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-data-sup-erl"></a>brick_data_sup.erl</h4></div></div></div><p>This is the <code class="literal">gdss</code> application supervisor that is responsible for
supervising all processes related to logical bricks:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The "common log" write-ahead log
</li><li class="listitem">
The actual logical brick supervisor
</li><li class="listitem">
The brick "shepherd" to start &amp; stop logical bricks
</li><li class="listitem">
The "simple" table state server (to support for the Hibari client
  <code class="literal">brick_simple.erl</code> API.
</li><li class="listitem">
The brick mailbox monitor
</li><li class="listitem">
The checkpoint I/O throttle server
</li><li class="listitem">
The brick "primer" throttle server
</li></ul></div></div><div class="section" title="brick_ets.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-ets-erl"></a>brick_ets.erl</h4></div></div></div><p>In an ideal world, <code class="literal">brick_ets.erl</code> would be a flexible plug-in module
to implement the data store for a Hibari logical brick.  With regard
to management of in-memory data structures (i.e. ETS <code class="literal">ordered_set</code>
tables, which are implemented as balanced binary trees), this module
is mostly self-contained.  For disk-based persistence, it uses the
write-ahead log modules <code class="literal">gmt_hlog.erl</code>, <code class="literal">gmt_hlog_common.erl</code>, and
<code class="literal">gmt_hlog_local.erl</code>) to handle disk I/O-related activity.</p><p>In the real world, <code class="literal">brick_ets.erl</code> is a mongrel, a mix of various
tasks: some memory related, some disk related, and some other stuff.
A "pluggable storage system" was not part of Hibari’s original design.
The original design called for two kinds of bricks, with two separate
implementations: one RAM-based and one disk-based.  The RAM-based one
was written first: it was the original <code class="literal">brick_ets.erl</code> module, to be
used as part of a quorum-style replication system.  The disk-based
module was delayed.</p><p>Then Hibari development stopped.  Then it restarted, but this time
needing to meet larger-than-RAM storage requirements and to use chain
replication (instead of quorum replication).  The decision was made to
split the <code class="literal">brick_ets.erl</code> module was several pieces:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">brick_ets.erl</code> would maintain the RAM-based data structures
</li><li class="listitem">
<code class="literal">gmt_hlog.erl</code> would maintain the disk-based write-ahead log
</li><li class="listitem">
<code class="literal">brick_server.erl</code> would maintain chain replication &amp; repair logic
</li></ul></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-brick-ets"></a></th></tr><tr><td align="left" valign="top"><p>Ideally, each of those three modules would have a strict
separation of concerns.  In reality, the split isn’t very clean.
There are some remnants of chain replication code and write-ahead log
code in <code class="literal">brick_ets.erl</code>.  There are small bits of ETS table management
code in <code class="literal">brick_server.erl</code>.  There are refactoring opportunities there
to finish the module-splitting work that was never fully finished.</p></td></tr></table></div><p>A big legacy of the original, everything-in-<code class="literal">brick_ets.erl</code>
implementation are the functions with names prefixed by "bcb_".  "BCB"
= "Brick CallBack".  These functions are required by
<code class="literal">brick_server.erl</code> for various purposes that also need access to the
ETS tables managed by <code class="literal">brick_ets.erl</code>.</p><div class="section" title="&quot;gen_server&quot; nested inside a &quot;gen_server&quot;, Matroshka-style"><div class="titlepage"><div><div><h5 class="title"><a id="brick-ets-matroshka"></a>"gen_server" nested inside a "gen_server", Matroshka-style</h5></div></div></div><p>Originally, the principal process for a logical brick was a
"gen_server" behavior process that was implemented by
<code class="literal">brick_ets.erl</code>.  When the <code class="literal">brick_ets.erl</code> module was split apart, the
choice was made to do the following:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The "gen_server" process would use <code class="literal">brick_server.erl</code> as its
  implementation module and use its own <code class="literal">#state</code> record which is
  _completely independent of the <code class="literal">brick_ets.erl</code> <code class="literal">#state</code> record.
</li><li class="listitem">
Keep the "gen_server" behavior callbacks in <code class="literal">brick_ets.erl</code>
</li><li class="listitem">
Use a layer of indirection to allow <code class="literal">brick_server.erl</code> code manage
  the behavior callbacks and <code class="literal">#state</code> of <code class="literal">brick_ets.erl</code>
</li></ul></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>This choice complicates <code class="literal">brick_server.erl</code> a little bit but
avoided a lot of refactoring work in <code class="literal">brick_ets.erl</code>.  It isn’t clear
if now is a good time to review that decision.</p></td></tr></table></div></div><div class="section" title="State record"><div class="titlepage"><div><div><h5 class="title"><a id="_state_record"></a>State record</h5></div></div></div><p>The <code class="literal">#state</code> record used by <code class="literal">brick_ets.erl</code> has members in several
major categories:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Major configuration items, e.g. <code class="literal">do_logging</code> and <code class="literal">bigdata_dir</code>
</li><li class="listitem">
Operation counts, e.g. <code class="literal">n_add</code> and <code class="literal">syncsum_count</code>
</li><li class="listitem">
Log management, e.g. <code class="literal">logging_op_serial</code> and <code class="literal">log</code>
</li><li class="listitem">
Checkpoint management, e.g. <code class="literal">check_pid</code>
</li><li class="listitem">
ETS tables, e.g. <code class="literal">ctab</code> and <code class="literal">shadowtab</code>
</li><li class="listitem">
Dirty key management, e.g. <code class="literal">dirty_tab</code> and <code class="literal">wait_on_dirty_q</code>
</li></ul></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-brick-ets-state"></a></th></tr><tr><td align="left" valign="top"><p>The <code class="literal">#state</code> record is probably too big.  Profiling suggests
that a substantial amount of CPU time is being spent in
<code class="literal">erlang:setelement()</code>; I’m guessing that’s related to <code class="literal">#state</code> record
updates, but I’m not 100% certain.  There are about 43 members in that
record, so refactoring by moving some items (e.g. operation counts
like <code class="literal">n_add</code>) to the process dictionary or ETS is likely a good idea.</p></td></tr></table></div></div><div class="section" title="ETS tables"><div class="titlepage"><div><div><h5 class="title"><a id="brick-ets-erl-ets-tables"></a>ETS tables</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">#state.ctab</code>, the contents table.  Except for changes made during a
  checkpoint, all data about a key lives in this table as a "store
  tuple" (see below).
</li><li class="listitem">
<code class="literal">#state.dirty_tab</code>, the dirty table.  If a key has been updated but
  not yet flushed to disk, the key appears here.  Necessary for any
  update, inside or outside of a micro-transaction, where race
  conditions are possible.  See <a class="xref" href="#dirty-keys-table" title="The dirty keys table">the section called “The dirty keys table”</a>.
</li><li class="listitem">
<code class="literal">#state.etab</code>, the expiry table.  If a key has a non-zero expiry time
  associated with it (an integer in UNIX <code class="literal">time_t</code> form), then the
  expiry time appears in this table.
</li><li class="listitem">
<code class="literal">#state.mdtab</code>, the brick private metadata table.  Used for private
  state management during data migration and other tasks.
</li><li class="listitem">
<code class="literal">#state.shadowtab</code>, the shadow table.  During checkpoints, the
  <code class="literal">#state.ctab</code> table is frozen while the checkpoint process dumps its
  contents.  All updates made while the checkpoint is running (insert
  or delete) are stored in this table.  When the checkpoint is
  finished, the contents of this table are applied to the contents
  table, and then the shadow table is deleted.
</li></ul></div></div><div class="section" title="The &quot;store tuple&quot;"><div class="titlepage"><div><div><h5 class="title"><a id="store-tuple"></a>The "store tuple"</h5></div></div></div><p>A "store tuple" is the internal representation of a key’s metadata.
It uses a variable-sized tuple to try to save some memory, avoiding
storing common values.  This is the tuple that is stored in the
<code class="literal">#state.ctab</code> table.</p><div class="informaltable"><table cellpadding="4px" style="border-collapse: collapse;border-top: 3px solid #527bbd; border-bottom: 3px solid #527bbd; border-left: 3px solid #527bbd; border-right: 3px solid #527bbd; "><colgroup><col /><col /><col /><col /><col /><col /></colgroup><thead><tr><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Element 1 </th><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Element 2 </th><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Element 3 </th><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Element 4 </th><th style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"> Element 5 </th><th style="border-bottom: 1px solid #527bbd; " align="center" valign="top"> Element 6</th></tr></thead><tbody><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">{Key,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">TStamp,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">Value,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">ValueLen}</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal"></code></p></td><td style="border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal"></code></p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">{Key,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">TStamp,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">Value,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">ValueLen,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">ExpTime}</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal"></code></p></td></tr><tr><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">{Key,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">TStamp,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">Value,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">ValueLen,</code></p></td><td style="border-right: 1px solid #527bbd; border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">Flags}</code></p></td><td style="border-bottom: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal"></code></p></td></tr><tr><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">{Key,</code></p></td><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">TStamp,</code></p></td><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">Value,</code></p></td><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">ValueLen,</code></p></td><td style="border-right: 1px solid #527bbd; " align="center" valign="top"><p><code class="literal">ExpTime,</code></p></td><td style="" align="center" valign="top"><p><code class="literal">Flags}</code></p></td></tr></tbody></table></div><p>Types used:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">Key = binary()</code>
</li><li class="listitem">
<code class="literal">TStamp = integer()</code>
</li><li class="listitem"><p class="simpara">
<code class="literal">Value = binary() | {integer(), integer()}</code>
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
For value blob storage in RAM, <code class="literal">Value = binary()</code>
</li><li class="listitem">
For value blob storage on disk, <code class="literal">Value = {FileNumber::integer(),
   Offset::integer()}</code> where <code class="literal">FileNumber</code> and <code class="literal">Offset</code> give the
   starting location for the write-ahead log "hunk" that stores the
   actual value blob.
</li></ul></div></li><li class="listitem">
<code class="literal">ValueLen = integer()</code>
</li><li class="listitem">
<code class="literal">ExpTime = integer()</code>
</li><li class="listitem">
<code class="literal">Flags = list()</code>
</li></ul></div></div><div class="section" title="Logical brick initialization and WAL scan"><div class="titlepage"><div><div><h5 class="title"><a id="_logical_brick_initialization_and_wal_scan"></a>Logical brick initialization and WAL scan</h5></div></div></div><p>The time required for full initialization of a logical brick is not
predictable.  We cannot know in advance how much metadata must be read
from the brick’s private write-ahead log, nor do we know how much time
it will take to read that data.</p><p>The OTP "supervisor" behavior places a limit on how long a worker
process’s init() function can take, and while a supervisor is starting
a worker process, it is blocked from starting/restarting/stopping
other workers.  Therefore, it’s very important that the logical brick
initialization function execute in a short amount of time.</p><p>The second-to-last statement in <code class="literal">brick_ets:init/1</code> is this:</p><pre class="literallayout">self() ! do_init_second_half,</pre><p>Then the <code class="literal">handle_info/3</code> callback can take as much time as is
necessary to read &amp; process the updates in the private write-ahead
log.</p></div><div class="section" title="The dirty keys table"><div class="titlepage"><div><div><h5 class="title"><a id="dirty-keys-table"></a>The dirty keys table</h5></div></div></div><p>Here are some examples of why the dirty keys table,
<code class="literal">#state.dirty_tab</code>, is used (not an exhaustive list):</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
To prevent more than one <code class="literal">add</code> operations succeeding.  If key <code class="literal">K</code>
  does not exist, and if multiple clients race to <code class="literal">add(Table, K, Value)</code>,
  then only one client should succeed.
</li><li class="listitem">
To prevent more than one update operation from succeeding with the same
  <code class="literal">{testset,CurrentTimeStamp}</code> flag.
</li><li class="listitem">
To prevent more than one micro-transaction from committing when
  using exclusive operations (e.g. <code class="literal">replace</code>) and/or exclusive flags
  (e.g. <code class="literal">{testset,CurrentTimeStamp}</code> and <code class="literal">key_must_exist</code>).
</li></ul></div><p>A Hibari micro-transaction is designed to avoid holding locks by
forcing the client to send the entire micro-transaction in a single
message.  The server brick’s gen_server should immediately be able to
enforce the above properties, correct?  Yes and no, unfortunately.</p><p>Because each logical brick is implemented as a single "gen_server"
process (we ignore the helper processes enumerated in
<a class="xref" href="#brick-ets-erl-processes" title="Processes created by brick_ets.erl">the section called “Processes created by brick_ets.erl”</a>), all messages processed by the brick
are automatically serialized.  That serialization property makes it
much easier to implement immediate commit/abort decisions.  However,
there’s a small problem: <span class="emphasis"><em>disk I/O is slow</em></span>.  Here is one example of a
race condition that is caused by slow disk I/O:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Assume key <code class="literal">K</code> does not exist.
</li><li class="listitem">
Client X sends <code class="literal">add(Table, K, Value1)</code> to brick B.
</li><li class="listitem">
Brick B receives the <code class="literal">add</code> op.  The key <code class="literal">K</code> does not exist, so the
operation is permitted.
</li><li class="listitem">
Brick B writes an insert record into its
private write-ahead log and requests a file sync.
</li><li class="listitem">
Brick B is told that the file sync has not yet finished and
therefore cannot send a reply to Client X yet.
</li><li class="listitem">
Client Y sends <code class="literal">add(Table, K, Value2)</code> to brick B.
</li><li class="listitem">
Brick B receives the <code class="literal">add</code> op.  The key <code class="literal">K</code> does not exist, so the
operation is permitted.  <span class="emphasis"><em>Although key <code class="literal">K</code> was added in step #4, that
operation’s write-ahead log has not yet been flushed safely to disk, so
therefore Brick B cannot yet guarantee that the key does exist.</em></span>
</li><li class="listitem">
Brick B writes an insert record into its
private write-ahead log and requests a file sync.
</li><li class="listitem">
Brick B is told that the file sync has not yet finished and
therefore cannot send a reply to Client Y yet.
</li><li class="listitem">
Brick B is informed asynchronously that the flush of step #3’s
operation is finished.  B sends a reply to Client X of <code class="literal">ok</code>.
</li><li class="listitem">
Brick B is informed asynchronously that the flush of step #7’s
operation is finished.  B sends a reply to Client Y of <code class="literal">ok</code>.  <span class="emphasis"><em>This
reply violates the principle of strong consistency and is therefore
incorrect.</em></span>
</li></ol></div><p>Any key that is updated by an operation that is waiting for its
write-ahead log entry to be flushed to disk will have an entry in the
<code class="literal">#state.dirty_tab</code> ETS table.  When the <code class="literal">fsync(2)</code> system call is
finished, the key will be removed from <code class="literal">#state.dirty_tab</code> and the
<code class="literal">#state.ctab</code> (or the "shadow table", if a checkpoint is in progress)
will be updated to make the key’s update visible.</p></div><div class="section" title="Micro-transaction implementation"><div class="titlepage"><div><div><h5 class="title"><a id="micro-transaction-implementation"></a>Micro-transaction implementation</h5></div></div></div><p>If a Hibari client calls <code class="literal">do</code> when the first op in the <code class="literal">DoList</code> is the
atom <code class="literal">txn</code>, then the <code class="literal">DoList</code> will be evaluated as a micro-transaction.
The check is done by <code class="literal">do_do2/3</code>, with micro-transaction preconditions
checked by <code class="literal">do_txnlist/3</code>.</p><p>If <code class="literal">do_txnlist/3</code> detects that a micro-transaction precondition has
been violated, e.g. <code class="literal">add</code> a key that already exists, then an error
accumulator is built to inform the client of which items in <code class="literal">DoList</code>
failed.  Note that the <code class="literal">txn</code> op is removed from the <code class="literal">DoList</code> before
<code class="literal">do_txnlist/3</code> starts.</p><p>If <code class="literal">do_txnlist/3</code> finds no errors in the micro-transaction, then the
<code class="literal">DoList</code> is then executed by the same function that processes
non-micro-transaction lists, <code class="literal">do_dolist/4</code>.</p></div><div class="section" title="Log flushing and the sync pid and the logging_op_q"><div class="titlepage"><div><div><h5 class="title"><a id="log-flushing-and-sync-pid"></a>Log flushing and the sync pid and the logging_op_q</h5></div></div></div><p>The management of the write-ahead log and maintaining strong
consistency was a more difficult problem than I had first realized.
To preserve strong consistency, the order of all updates must be
preserved when writing log entries to the write-ahead log.  Updates
come from two sources:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Client requests
</li><li class="listitem">
Chain replication messages, e.g. a log replay message from a brick’s
  immediate upstream neighbor.  (NOTE: These messages are handled by
  the <code class="literal">brick_server.erl</code> module, see <a class="xref" href="#brick-server-erl" title="brick_server.erl">the section called “brick_server.erl”</a>.)
</li></ul></div><p>The brick maintains a monotonically-increasing counter,
<code class="literal">#state.logging_op_serial</code>, to assign a serial number to each update.
Each update is written in increasing serial number order.  After an
update is written, the brick will request an <code class="literal">fsync(2)</code> system call on
the log.  The write-ahead log manager will initiate the call (if no
<code class="literal">fsync(2)</code> call is currently in progress) or queue the request for a
later time (because an <code class="literal">fsync(2)</code> system call is in progress already).</p><p>Because the brick does not know when the <code class="literal">fsync(2)</code> system call will
finish, the brick stores the operation and its serial number in a
queue called <code class="literal">#state.logging_op_q</code>.</p><p>The write-ahead log manager will notify the brick when an <code class="literal">fsync(2)</code>
system call is finished, telling the brick the largest serial number
<code class="literal">N</code>.  The brick will remove all pending requests from the
<code class="literal">#state.logging_op_q</code> that have serial numbers less than or equal to
serial <code class="literal">N</code>.  Processing of those pending requests is then resumed.</p></div><div class="section" title="The syncpid: How it works, room for improvement"><div class="titlepage"><div><div><h5 class="title"><a id="the-syncpid"></a>The syncpid: How it works, room for improvement</h5></div></div></div><p>As described above, the "syncpid"'s job is pretty simple:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Collect requests for an <code class="literal">fsync(2)</code> call.  (Each request is tagged
   with a log sequence number.)
</li><li class="listitem">
Now and then, start a <code class="literal">fsync(2)</code> call via the <code class="literal">gmt_hlog_local.erl</code>
   API.
</li><li class="listitem">
When the call is finished, notify the brick of the largest log
   sequence number serviced by the completed <code class="literal">fsync(2)</code> call.
</li></ol></div><p>The tricky part is step #2, specifically, when should "now and then"
be?  There are a couple of easy answers to the question:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
Initiate an <code class="literal">fsync(2)</code> call whenever a single request in step #1
  arrives.  Block all other <code class="literal">fsync(2)</code> requests until this one
  finishes.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Both throughput and latency under high load are quite poor.
</li></ul></div></li><li class="listitem"><p class="simpara">
Collect requests in step #1 for a fixed amount of time, e.g. 100
  milliseconds, then start <code class="literal">fsync(2)</code>.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Throughput under high load is very good, but latency under light
   loads is very high.
</li></ul></div></li></ul></div><p>The current implementation, in <code class="literal">collect_sync_requests/3</code>, uses a
variable amount of time in step #1 by waiting a maximum of 5
milliseconds since the last fsync request before going to step #2.
The method is virtuous by being simple and for being "good enough" for
both very low and very high load conditions.</p></div><div class="section" title="Value blob storage on disk: bigdata_dir"><div class="titlepage"><div><div><h5 class="title"><a id="value-blobs-on-disk"></a>Value blob storage on disk: bigdata_dir</h5></div></div></div><p>As explained in <a class="xref" href="#store-tuple" title="The &quot;store tuple&quot;">the section called “The "store tuple"”</a>, when a value blob is stored on
disk, its store tuple representation is <code class="literal">{FileNumber::integer(),
Offset::integer()}</code>.  These two integers are used to find the value
blob’s storage location on disk.  See <a class="xref" href="#gmt-hlog-erl" title="gmt_hlog.erl">the section called “gmt_hlog.erl”</a> for API
details.</p><p>A brick’s behavior for value storage is defined by the value of
<code class="literal">#state.bigdata_dir</code>:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
If <code class="literal">undefined</code>, then values are stored in RAM, i.e. as an Erlang
  binary within the store tuple.
</li><li class="listitem">
If not <code class="literal">undefined</code>, then values are stored on disk.
</li></ul></div><p>When a key is set by a <code class="literal">set</code>/<code class="literal">add</code>/<code class="literal">replace</code> operation in a table that
stores value blobs on disk, there are actually two hunks written to
the brick’s write-ahead log:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
The value blob itself is written in a hunk first.
</li><li class="listitem">
Then the brick’s metadata hunk is written second.  This hunk
   contains the store tuple for this key and therefore contains the
   <code class="literal">{FileNumber,Offset}</code> tuple for the location of the value blob hunk
   stored in step #1.
</li></ol></div><p>To retrieve a hunk, the <code class="literal">gmt_hlog</code> API is used, passing the
<code class="literal">FileNumber</code> and <code class="literal">Offset</code> as arguments.  The library function then:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Converts <code class="literal">FileNumber</code> to a full file path for the log sequence file.
</li><li class="listitem">
Opens the file and seeks to offset <code class="literal">Offset</code>
</li><li class="listitem">
Reads the write-ahead log hunk header, which contains hunk metadata
  such as blob size and MD5 checksum.
</li><li class="listitem"><p class="simpara">
Reads the hunk blob, which immediately follows the hunk header.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
If the client passes the blob size as an extra argument, the two
   reads are combined into a single read request.
</li></ul></div></li></ul></div></div><div class="section" title="Squid/flash and priming"><div class="titlepage"><div><div><h5 class="title"><a id="squid-flash-priming"></a>Squid/flash and priming</h5></div></div></div><p>The serial nature of message handling by the "gen_server" behavior is
almost always a good thing.  However, dealing with disk I/O is one of
the few times when it would be really nice to have "gen_server" handle
multiple messages in parallel.</p><p>It’s certainly possible to have "gen_server" handle multiple messages
in parallel, but it’s the developer’s responsibility to juggle the
asynchronous replies to clients.  This can get very tricky very
quickly.  However, a logical brick must do this kind of juggling to
minimize latency across all Hibari client requests.</p><p>The Erlang virtual machine does not expose an API to the OS’s
<code class="literal">mmap(2)</code> and <code class="literal">mincore(2)</code> system calls, so it is impossible for a
logical brick to know which parts of a file are in the page cache and
which are not.  Without that knowledge, the brick cannot predict how
long it will take to open or read a log sequence file to retrieve a
value blob.</p><p>To make the unpredictable disk I/O pattern into something almost 100%
predictable, Hibari bricks borrow a trick from the
<a class="ulink" href="http://www.squid-cache.org" target="_top">Squid HTTP Caching Proxy server</a> and
the <a class="ulink" href="http://www.cs.princeton.edu/~vivek/flash/" target="_top">Flash HTTP
server</a>.  To avoid having computation threads blocked by disk I/O,
both servers use a pool of OS processes or Pthreads whose sole job is
to perform disk I/O.  The model goes something like this:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
The main server process/thread wishes to read file X.
</li><li class="listitem">
The main server process/thread sends a request to the I/O worker
pool to read X.
</li><li class="listitem">
A process (or thread) in the worker pool opens X, reads X’s data,
and closes X.
</li><li class="listitem">
The worker process/thread notifies the main server thread that the
read of X has finished, via a pipe file descriptor.
</li><li class="listitem">
The main server process/thread receives the completion message from
step #4 via the other end of the pipe.
</li><li class="listitem">
Now the main server process/thread can open and read file X with
almost 0% probability that it will be blocked by the OS: it’s almost
100% certain that all file system metadata and file data are now in
the OS page cache and therefore the probability of blocking due to
disk I/O is nearly zero.
</li></ol></div><p>The logical brick uses the same basic strategy, which I’ve called
"squid/flash priming" or simply "priming", as in "priming a pump".  A
brick will spawn a short-lived Erlang process to read the log hunk,
notify the main gen_server that the I/O is finished, and then the main
gen_server process can open &amp; read the file with virtual certainty
that it will not be blocked by disk I/O.</p><p>Primer processes are used when reading data from a Hibari client <code class="literal">get</code>
or <code class="literal">get_many</code> request as well as when reading value blobs during brick
repair operations.  Each has a separate throttle configuration
attribute.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>There is a throttle mechanism to keep too many squid/flash
primer processes from executing simultaneously: the
<code class="literal">brick_primer_limit</code> attribute in <code class="literal">central.conf</code>.  Too many primer
processes can cause several problems, separately or in combination
or together:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Consume too many Erlang processes
</li><li class="listitem">
Consume too many OS file descriptors
</li><li class="listitem">
Consume too much virtual machine memory
</li></ul></div></td></tr></table></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-blob-reading"></a></th></tr><tr><td align="left" valign="top"><p>There is plenty of opportunity for refactoring here.  The
current implementation has been "good and fast enough", but there’s
almost certainly room for optimization, especially if very large blobs
(greater than 4MB, approximately) are routinely used.  Some possible
optimizations would included:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Use Erlang NIF functions to use <code class="literal">mmap(2)</code> and <code class="literal">mincore(2)</code> system calls.
</li><li class="listitem">
Use the <code class="literal">readahead(2)</code> system call on Linux platforms.  Try to find
  substitutes on other platforms aren’t <code class="literal">mmap(2)</code> and <code class="literal">mincore(2)</code>.
</li><li class="listitem">
Experiment with <a class="ulink" href="http://libprefetch.cs.ucla.edu/" target="_top">libprefetch</a>.
</li><li class="listitem">
Adding a bytes-per-second throttle for priming operations.
</li><li class="listitem">
Perhaps using <code class="literal">mmap(2)</code> instead of <code class="literal">file:read()</code> for the final blob
  reading step?
</li></ul></div></td></tr></table></div></div><div class="section" title="Magic values: ?VALUE_REMAINS_CONSTANT, ?VALUE_SWITCHAROO"><div class="titlepage"><div><div><h5 class="title"><a id="_magic_values_value_remains_constant_value_switcharoo"></a>Magic values: ?VALUE_REMAINS_CONSTANT, ?VALUE_SWITCHAROO</h5></div></div></div><p>There are two magic values that an Erlang client can use in a
<code class="literal">set</code>/<code class="literal">add</code>/<code class="literal">replace</code> operation in place of the usual binary or iolist
value blob.</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">?VALUE_REMAINS_CONSTANT</code>
</span></dt><dd>
The client can use this magic constant in an <code class="literal">set</code>/<code class="literal">add</code>/<code class="literal">replace</code>
operation to keep the value blob the same while changing other
attributes of the key, such as expiration time or flags.
</dd><dt><span class="term">
<code class="literal">?VALUE_SWITCHAROO</code>
</span></dt><dd>
Use of this flag is limited to the scavenger only and should not be
used by any other client.  See <a class="xref" href="#the-scavenger" title="The scavenger">the section called “The scavenger”</a> for more.
</dd></dl></div></div><div class="section" title="Areas where brick_server.erl stuff bleeds over into brick_ets.erl"><div class="titlepage"><div><div><h5 class="title"><a id="_areas_where_literal_brick_server_erl_literal_stuff_bleeds_over_into_literal_brick_ets_erl_literal"></a>Areas where <code class="literal">brick_server.erl</code> stuff bleeds over into <code class="literal">brick_ets.erl</code></h5></div></div></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>These are some areas where logic that most likely should be
moved to <code class="literal">brick_server.erl</code>.</p></td></tr></table></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Migration sweep logic bleeding into get_many1()
</li><li class="listitem">
Chain replication into filter_mods_from_upstream()
</li><li class="listitem">
Repair-related stuff in repair_diff_round1()
</li></ul></div></div><div class="section" title="get_many and the shadow table"><div class="titlepage"><div><div><h5 class="title"><a id="_literal_get_many_literal_and_the_shadow_table"></a><code class="literal">get_many</code> and the shadow table</h5></div></div></div><p>The implementation of the contents table and the shadow table,
<code class="literal">#state.ctab</code> and <code class="literal">#state.shadowtab</code> respectively, causes some
problems.  The biggest problem is that when a checkpoint is in
progress and the <code class="literal">#state.shadowtab</code> exists, then the "does the key
exist?" decision must consult both tables in a sane manner.</p><p>The <code class="literal">get_many</code> operation is most affected by the necessity to look in
both tables.  The <code class="literal">get_many_shadow()</code> function implements the tricky
logic that’s required to combine the contents of both contents and
shadow tables into a consistent set of results.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Because <code class="literal">get_many</code> is really complicated by the shadow table,
and because there has been no hard requirement for a client <code class="literal">get_many</code>
op that returns keys in reverse order (i.e. search backwards), a
reverse- ordered <code class="literal">get_many</code> operation does not exist.  There is no
foreseeable technical reason why one couldn’t be added.</p></td></tr></table></div></div><div class="section" title="Controlling MD5 checksums"><div class="titlepage"><div><div><h5 class="title"><a id="controlling-md5-checksums"></a>Controlling MD5 checksums</h5></div></div></div><p>By default, MD5 checksums are generated for all data written to all
write-ahead logs, and those MD5 checksums are checked for all data
read from write-ahead logs.</p><p>If the file "disable-md5" exists in the Hibari server data directory,
then data will be written to write-ahead logs without MD5 checksums,
and data read from write-ahead logs will not have MD5 checksums
verified.</p><p>If the file "use-md5-bif" exists in the Hibari server data directory,
then the <code class="literal">erlang:md5/1</code> function will be used to create MD5
checksums.  By default, the <code class="literal">crypto:md5/1</code> is used to create MD5
checksums.</p></div><div class="section" title="MD5 checksum errors"><div class="titlepage"><div><div><h5 class="title"><a id="_md5_checksum_errors"></a>MD5 checksum errors</h5></div></div></div><p>If an MD5 checksum error is detected, the easy thing to do is crash
the brick.  In practice, this approach causes some additional problems
that we would rather avoid.  The logic is in <code class="literal">bigdata_dir_get_val()</code>:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
Mark the sequence file as bad.  The assumption is that the entire
  log sequence file is bad.  This assumption may or may not be true,
  but the default is to be conservative.  We don’t know if there are
  other checksum errors within the file, so we will:
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Rename the log sequence file to that it cannot be accessed again.
</li><li class="listitem">
By not deleting the file, the bad data block(s) in it cannot be
   recycled and therefore contaminate data sometime in the future.
</li><li class="listitem">
We can examine the bad file at leisure to confirm that it is bad
   and find any other places where checksums have been corrupted.
</li><li class="listitem">
We delete all references to keys that depend on the corrupted log
   sequence file.  Then we crash.  Chain repair will repopulate the
  missing keys.
</li></ul></div></li><li class="listitem">
Silently drop the entire query.  The client will see a timeout
  eventually and have to retry (if it wishes).
</li></ul></div></div><div class="section" title="The scavenger"><div class="titlepage"><div><div><h5 class="title"><a id="the-scavenger"></a>The scavenger</h5></div></div></div><p>The "scavenger" procedure is used to reclaim disk space in the "common
log" that is no longer used by a local logical brick.  It is
essentially a copying garbage collector:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
It determines which hunks in all common log files are currently in
   use or not in use.
</li><li class="listitem">
It perhaps copies some hunks to new log sequence files.
</li><li class="listitem">
It perhaps deletes some log sequence files to reclaim disk space.
</li></ol></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>By default, the scavenger is run once every 24 hours at
03:00.</p></td></tr></table></div><p>Each write-ahead log is divided into log sequence files.  Each log
sequence files contains a sequence of "hunks".  The hunks are put into
one of two categories:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A "live" hunk is still in use, i.e. there is a key which has a value
  blob pointer that points to this hunk.
</li><li class="listitem">
A "dead" hunk is not "alive": i.e. the key that originally had a
  value blob pointer to this hunk has since been changed or deleted.
</li></ul></div><p>The goal of the scavenger is to reclaim disk space.  The only way to
reclaim disk space is to delete files.  If the scavenger finds a log
sequence file with 0% live hunks, that file can be deleted
immediately.  However, it is quite rare to find a log sequence file
that has 0% live hunks.  For all other log sequence files, a different
strategy is used:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Fetch the <code class="literal">brick_skip_live_percentage_greater_than</code> attribute from
<code class="literal">central.conf</code>.  Call it <code class="literal">SkipPercent</code>.
</li><li class="listitem">
For each log sequence file, calculate the ratio of disk space used
by live hunks; call it <code class="literal">LivePercent</code>.
</li><li class="listitem"><p class="simpara">
For each log sequence file where <code class="literal">LivePercent</code> is less than
<code class="literal">SkipPercent</code>:
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Copy all live hunks to a new log sequence file(s).
</li><li class="listitem">
Update the location pointers of those keys to point to the new
   storage locations.
</li><li class="listitem">
Delete the old log sequence file.
</li></ul></div></li></ol></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-scavenger"></a></th></tr><tr><td align="left" valign="top"><p>The current scavenger implementation trades (relatively) low
memory usage for increased execution time and increased disk I/O.
There are probably opportunities to refactor the scavenger to operate
faster or to generate less disk I/O to its temp files.</p></td></tr></table></div></div><div class="section" title="Processes created by brick_ets.erl"><div class="titlepage"><div><div><h5 class="title"><a id="brick-ets-erl-processes"></a>Processes created by brick_ets.erl</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The long-lived "sync pid" process.  This process is responsible for
  combining, or "batching", multiple brick write operations into a
  single <code class="literal">fsync(2)</code> OS system call.  Once an <code class="literal">fsync(2)</code> call has
  finished, the "sync pid" will send a message to the logical brick’s
  "gen_server" process to tell it what log items (identified by log
  serial number) have been flushed to disk and can be sent downstream
  and/or to the client.
</li><li class="listitem">
The long-lived "local" write-ahead log process.  Each logical brick
  has its own local write-ahead log, managed by its own local log
  process.  This process works together with the "common log"
  write-ahead log and the "sync pid" to store brick updates safely to
  disk.
</li><li class="listitem">
Short-lived "checkpoint" processes.  When a brick’s local log has
  grown larger than the <code class="literal">brick_check_checkpoint_max_mb</code> configuration
  variable, a checkpoint process is spawned to perform the checkpoint
  task.  See <a class="ulink" href="hibari-sysadmin-guide.en.html#checkpoints" target="_top">Hibari
  Sysadmin Guide, "Checkpoints" section</a> for an overview of the
  checkpoint procedure.
</li><li class="listitem">
Very short-lived processes to implement the data "priming" process,
  see above for description.
</li><li class="listitem">
A short-lived process to delete keys that have expired.
</li><li class="listitem">
Short-lived "scavenger processes, see <a class="xref" href="#the-scavenger" title="The scavenger">the section called “The scavenger”</a>.
</li></ul></div></div></div><div class="section" title="brick_hash.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-hash-erl"></a>brick_hash.erl</h4></div></div></div><p>The consistent hashing layer is the top-level of the layered
abstraction of a Hibari storage cluster, as discussed in
<a class="ulink" href="hibari-sysadmin-guide.en.html#hibari-architecture" target="_top">Hibari Sysadmin
Guide, "Hibari Architecture" section</a>.</p><p>The <code class="literal">#hash_r</code> record encapsulates two things:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The algorithm used to choose what part of the key will be used for
  hashing: the entire key, fixed length prefix, variable length
  prefix, etc.
</li><li class="listitem">
The consistent hashing algorithm itself.
</li></ul></div><p>The <code class="literal">#g_hash_r</code> record is the "global hash record" for a table.  It is
the record that is "spammed" to all brick servers and clients (see the
<a class="link" href="#spamming-the-global-hash">description of global hash spamming</a>
<a class="xref" href="#spamming-the-global-hash">the section called “Global Hash spamming”</a>).
The <code class="literal">#g_hash_r</code> record contains the <code class="literal">#hash_r</code> records for:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The current hash configuration
</li><li class="listitem">
The new hash configuration.
</li></ul></div><p>Usually, the current hash config is the same as the new hash config.
However, when chains are added/removed/reweighted and a data migration
takes place, the new hash configuration is used to determine which
keys stay in their current chain and which need to be moved to a new
chain.</p><p>In theory, all Hibari clients have access to an up-to-date copy of
each tables' <code class="literal">#g_hash_r</code> record, via their node-local <code class="literal">brick_simple</code>
server.  In practice, due to message passing latencies, all clients do
not have correct global hashes 100% of the time.  The Admin Server
also sends <code class="literal">#g_hash_r</code> updates to all server bricks also.  If a client
is using an old global hash, the servers (using the same consistent
hash calculations) can forward the request to the correct brick.</p><div class="section" title="Key hashing methods"><div class="titlepage"><div><div><h5 class="title"><a id="_key_hashing_methods"></a>Key hashing methods</h5></div></div></div><p>The only method that should be used for new Hibari tables is the
<code class="literal">chash</code> method.  The other three, <code class="literal">naive</code>, ``var_prefix`, and
<code class="literal">fixed_prefix</code>, are deprecated and will be removed at some point.  The
<code class="literal">chash</code> method supports all three schemes and also provides
migration-related features that the three deprecated schemes alone
cannot.</p></div><div class="section" title="Initializing a chash"><div class="titlepage"><div><div><h5 class="title"><a id="_initializing_a_literal_chash_literal"></a>Initializing a <code class="literal">chash</code></h5></div></div></div><p>See the EDoc entry for <code class="literal">chash_init/3</code> for full details on all the
valid properties that can be passed in the 3rd argument proplist.</p><p>The two properties that are mandatory are <code class="literal">prefix_method</code> and
<code class="literal">new_chainweights</code>.  We strongly advise that you also include the
<code class="literal">old_float_map</code> property; the float map can be extracted from a
<code class="literal">#g_hash_r</code> or a <code class="literal">#hash_r</code> record using the
<code class="literal">chash_extract_new_float_map/1</code> function.</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Do not use the <code class="literal">chash_extract_old_float_map/1</code> function to
extract the consistent hash "float map" from the current global hash
record.  In the context of the current global hash, the "old float
map" is the float map used from the global hash <span class="emphasis"><em>prior to the current
one</em></span>, which is almost certainly not the float map you want when making
a new global hash record.</p></td></tr></table></div></div><div class="section" title="Checking data migration pattern before initiating migration"><div class="titlepage"><div><div><h5 class="title"><a id="_checking_data_migration_pattern_before_initiating_migration"></a>Checking data migration pattern before initiating migration</h5></div></div></div><p>The chain changing example in <a class="xref" href="#changing-chains-example" title="3.10.&#xA0;Creating New/Deleting Current/Reweighting/Rehashing Chains">Section 3.10, “Creating New/Deleting Current/Reweighting/Rehashing Chains”</a> shows how
to verify that the <code class="literal">#hash_r</code> that you’ve created will result in the
key distribution across chains that you desire.  See the
<a class="link" href="#chash-migration-pre-check">example of using ``brick_simple:chash_migration_pre_check/2`</a>
<a class="xref" href="#chash-migration-pre-check">Section 3.10, “Creating New/Deleting Current/Reweighting/Rehashing Chains”</a>.</p></div><div class="section" title="brick_itimer.erl"><div class="titlepage"><div><div><h5 class="title"><a id="brick-itimer-erl"></a>brick_itimer.erl</h5></div></div></div><p>Older versions of Hibari made substantial use of
<code class="literal">timer:send_interval/2</code> for sending periodic timer messages.  The
<code class="literal">timer</code> module’s implementation can be too inefficient when over 1,000
separate timer interval requests are made.  The <code class="literal">brick_itimer</code> module
creates a more CPU-efficient implementation for heavily used timer
intervals, for example 1 second.</p><p>The latency jitter in delivering these shared timer messages is
intentional.  Strict real-time accuracy for sending these periodic
messages is not required.  If stricter delivery timings are required,
do not use this module.</p></div></div><div class="section" title="brick_mboxmon.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-mboxmon-erl"></a>brick_mboxmon.erl</h4></div></div></div><p>Hibari servers use asynchronous message passing in two major areas:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Chain replication: sending events "downstream" to the next brick in
  a chain.
</li><li class="listitem">
Chain repair: sending key updates to bricks that have crashed and
  later restarted.
</li></ul></div><p>The number of these asynchronous messages can arrive more quickly than
a brick can handle.  Perhaps its CPU is overloaded, or perhaps disk
I/O rates are so high that the hardware cannot provide adequate
service times.  In either case, the number of messages in a logical
brick "gen_server" process mailbox can grow too large.</p><p>It is vital for good performance that a brick’s mailbox.  Large
mailboxes can interfere with other messaging, for example, synchronous
calls to the brick’s write-ahead log process.  If the mailbox grows
too large, the VM will spend 100% of a CPU core performing selective
<code class="literal">receive</code> operations on the mailbox.  If the mailbox continues to grow
without limit, the entire VM can crash by consuming all virtual memory
available to the OS.</p><p>If a brick’s mailbox gets too big, then some kind of "pressure"
mechanism is required to slow down message producers.  In cases of
mailbox overload during brick repair, repair operations by the
upstream brick (with the "official tail" role) must slow down.  In
normal chain operations, the head brick must slow down its rate of
updates.</p><p>The throttling mechanism implemented by <code class="literal">brick_mboxmon.erl</code> is
straightforward.  Every 500 milliseconds, the mailbox size of each
brick on the local node is polled via <code class="literal">erlang:process_info/2</code>.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
If the mailbox size exceeds the <code class="literal">brick_mbox_repair_high_water</code>
  attribute in <code class="literal">central.conf</code>, and if the brick is under repair, then
  the throttle mechanism is activated.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
The repair process is stopped and will be restarted in
  <code class="literal">brick_mbox_repair_overload_resume_interval</code> seconds.
</li></ul></div></li><li class="listitem"><p class="simpara">
If the mailbox size exceeds the <code class="literal">brick_mbox_high_water</code> attribute in
  <code class="literal">central.conf</code>, then the throttle mechanism is activated.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
The head brick in the chain is flipped to "read-only mode".  When
   in read-only mode, the head brick cannot process any updates, so
   the head brick cannot create new key updates that will eventually
   be sent to the overloaded brick.
</li></ul></div></li><li class="listitem"><p class="simpara">
When the overloaded brick’s mailbox size falls under
  <code class="literal">brick_mbox_low_water</code>, then the brick is no longer considered
  overloaded.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
In cases of repair overload, repair is restarted.
</li><li class="listitem">
In cases of normal chain replication overload, the head brick’s
   "read-only status" is turned off (i.e. updates are permitted
   again).  For transient overload conditions lasting 0-3 seconds,
   client request buffering by the head brick is usually sufficient to
   avoid timeouts visible by Hibari clients.  However, if the chain is
   so overloaded that client timeouts occur, then the client timeout
   mechanism itself will reduce the chain’s total workload.
</li></ul></div></li></ul></div><p>The application log files on the overloaded brick, the head brick, and
(in repair cases) the Admin Server will contain messages stating when
and why the brick was considered overloaded and when the overload
condition ended.</p></div><div class="section" title="brick_migmon.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-migmon-erl"></a>brick_migmon.erl</h4></div></div></div><p>During times when a table’s chain configuration is changed
(e.g. chains added, removed, or reweighted), a "data migration" takes
place.  Some keys are copied, or "migrated", from one chain to
another.  The <code class="literal">brick_migmon.erl</code> module is responsible for monitoring
the overall status of this data migration period.</p><p>Data migrations are tied closely to a table’s global hash record.
Each Hibari table has its own global hash record (<code class="literal">#g_hash_r</code>
record).  It is therefore possible to have multiple migrations running
simultaneously for multiple tables.</p><p>However, each data migration for a global hash is assigned a "cookie",
which is an opaque Erlang term.  In the event that some or all
processes in the Admin Server crash, this cookie is used to
distinguish between resuming an in-progress migration and starting a
new migration.  If migrations are numbered <span class="emphasis"><em>X</em></span>, <span class="emphasis"><em>X+1+</em></span>, <span class="emphasis"><em>X+2</em></span>, etc.,
then a migration <span class="emphasis"><em>X+1</em></span> for table <span class="emphasis"><em>Y</em></span> will not be permitted to start
until migration <span class="emphasis"><em>X</em></span> for table <span class="emphasis"><em>Y</em></span> has finished.</p></div><div class="section" title="brick_migmon_sup.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-migmon-sup-erl"></a>brick_migmon_sup.erl</h4></div></div></div><p>This is a supervisor dedicated to <code class="literal">brick_migmon</code> processes.</p></div><div class="section" title="brick_pingee.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-pingee-erl"></a>brick_pingee.erl</h4></div></div></div><p>Earlier versions of Hibari had difficulty with brick "pinger"
processes getting timeouts when trying to check a logical brick’s
health.  Under extremely high workloads, the first-come, first-served
nature of a "gen_server"'s message handling was not sufficient.</p><p>The solution is to create a separate "pingee" process for each logical
brick.  As the main brick "gen_server" process makes major state
transitions, those transitions are transmitted to the "pingee"
process.  The "pinger" processes actually communicate with the
"pingee" process for health inquiries and not with the main brick
process.  Because the "pingee" is only used for state transition and
health check messages, its mailbox is almost always empty, and its
process almost always idle.  This combination helps make responses to
health checks much quicker.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-pingee"></a></th></tr><tr><td align="left" valign="top"><p>The split between the main brick process and the "pingee"
process does not eliminate timeouts under extremely heavy workloads.
There may be useful refactoring work possible here.  The main source
of latency appears to be during inter-node messaging congestion,
e.g. when <span class="emphasis"><em>dist_port_busy</em></span> system events are generated.</p></td></tr></table></div></div><div class="section" title="brick_sb.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-sb-erl"></a>brick_sb.erl</h4></div></div></div><p>This module implements the Admin Server’s "scoreboard" process.  The
scoreboard reflects the health status of each logical brick and chain.</p><p>Accelerate read-only query performance, all scoreboard status is
maintained in RAM.  To make the scoreboard resilient in case of
crashing, each status change is synchronously written to the Admin
Server’s private <code class="literal">bootstrap_copy</code>* bricks.  See
<a class="xref" href="#admin-server-crash-recovery" title="10.2.&#xA0;Admin Server notes: crash-recovery design">Section 10.2, “Admin Server notes: crash-recovery design”</a> for more info on crash-recovery
design.  For more information about the Admin Server’s bootstrap
bricks, see <a class="ulink" href="hibari-sysadmin-guide.en.html#bootstrap-bricks" target="_top">Hibari
Sysadmin Guide, "Admin Server’s Private State: the Bootstrap Bricks"
section</a> and
<a class="ulink" href="hibari-sysadmin-guide.en.html#bricks-outside-chain-replication" target="_top">Hibari
Sysadmin Guide, "Bricks outside of chain replication" section</a>.</p><p>Each status change event that is sent to the scoreboard includes a
proplist that can contain additional information about the event.  At
this time, there is no requirement of mandatory properties in that
proplist.  Though mandatory properties may be introduced later, the
main purpose is merely to provide a human developer/systems
administrator with some extra information about the event.</p><div class="figure"><a id="id36119160"></a><p class="title"><b>Figure 1. Scoreboard and it’s surrounding (partial) supervision tree</b></p><div class="figure-contents"><a class="ulink" href="images/brick-sb-stree.svg" target="_top">
  <div class="mediaobject" align="center"><img src="images/brick-sb-stree.png" align="middle" alt="images/brick-sb-stree.svg" /></div>
</a></div></div><br class="figure-break" /><p>The scoreboard and it’s surrounding (partial) supervision tree is
depicted above by "dotted" lines.  The chainmon_XXX and pinger_YYY
processes manually establish a link with the brick_sb process.  If a
"down event" for the brick_sb processed is received, the chainmon_XXX
and pinger_YYY processes sleep for 1 second before exiting abnormally.
The brick_mon_sup supervisor will then automatically restart the
chainmon_XXX and pinger_YYY processes.</p><div class="figure"><a id="id36119205"></a><p class="title"><b>Figure 2. Scoreboard and it’s surrounding (partial) call tree</b></p><div class="figure-contents"><a class="ulink" href="images/brick-sb-ctree.svg" target="_top">
  <div class="mediaobject" align="center"><img src="images/brick-sb-ctree.png" align="middle" alt="images/brick-sb-ctree.svg" /></div>
</a></div></div><br class="figure-break" /><p>During initialization of the scoreboard, the brick_sb loads the
“scoreboard” operational history into RAM from the bootstrap bricks
via the brick_admin server.  After initialization, the brick_sb
manages the state in RAM and synchronously writes the full state
directly to the bootstrap bricks after receiving new chain and/or
brick status reports.  To help improve performance, the implementation
of the brick_sb is optimized to process all pending status reports as
a batch and to then save the full state to the bootstrap bricks as a
single write operation.</p><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The scoreboard’s maximum length of the list of historical
events is hard-coded at 100.  This should be changed to use a
<code class="literal">central.conf</code> configuration attribute instead.</p></td></tr></table></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-scoreboard"></a></th></tr><tr><td align="left" valign="top"><p>If the Admin Server is refactored to enhance performance, then
the scoreboard will likely be one of the first items fixed.  Because
all state changes must be reported to the scoreboard, and the
scoreboard synchronous writes each change to the bootstrap bricks, the
scoreboard is can be a substantial performance bottleneck in a cluster
that contains thousands of logical bricks.</p></td></tr></table></div></div><div class="section" title="brick_server.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-server-erl"></a>brick_server.erl</h4></div></div></div><p>The <code class="literal">brick_server.erl</code> module implements the storage-agnostic aspects
of a logical brick.  It isn’t fully insulated from matters related to
ETS and disk write-ahead log, but it’s close.  See the beginning of
<a class="xref" href="#brick-ets-erl" title="brick_ets.erl">the section called “brick_ets.erl”</a> for more details of how <code class="literal">brick_ets.erl</code> started
and how <code class="literal">brick_server.erl</code> came along later.</p><div class="section" title="&quot;gen_server&quot; nested inside a &quot;gen_server&quot;, Matroshka-style"><div class="titlepage"><div><div><h5 class="title"><a id="brick-server-matroshka"></a>"gen_server" nested inside a "gen_server", Matroshka-style</h5></div></div></div><p>See also <a class="xref" href="#brick-ets-matroshka" title="&quot;gen_server&quot; nested inside a &quot;gen_server&quot;, Matroshka-style">the section called “"gen_server" nested inside a "gen_server", Matroshka-style”</a>.</p><p>After the split of <code class="literal">brick_ets.erl</code> and <code class="literal">brick_server.erl</code>, the
"gen_server" callback functions of both were preserved, even though
both are used by a single process.  As far as OTP is concerned,
<code class="literal">brick_server.erl</code> is the callback module used for the main logical
brick gen_server process.  If a call, cast, or message isn’t handled
by <code class="literal">brick_server</code>'s callback function, then the message is handled by
<code class="literal">brick_ets</code>'s callback function.</p><p>The wrinkle in this otherwise flawless scheme is that
<code class="literal">brick_server.erl</code> has to maintain the <code class="literal">#state</code> record that
<code class="literal">brick_ets.erl</code> uses, keeping it completely separate from
<code class="literal">brick_server.erl</code>'s record of the same name.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-logging-op-q"></a></th></tr><tr><td align="left" valign="top"><p>The <code class="literal">brick_server</code> <code class="literal">#state</code> record is pretty simple, compared to
<code class="literal">brick_ets</code>'s, and much smaller.  Note that <code class="literal">brick_server</code>'s <code class="literal">#state</code>
record also contains a <code class="literal">logging_op_q</code> member, which is used for a
similar purpose as <code class="literal">brick_ets</code>'s.  Maintaining two separate queues of
log entries is quite messy.  It would be really tricky to refactor
without breaking anything, but the effort would be worthwhile.</p></td></tr></table></div></div><div class="section" title="Making do operations, operation flags, and do flags"><div class="titlepage"><div><div><h5 class="title"><a id="do-ops-op-flags-do-flags"></a>Making <code class="literal">do</code> operations, operation flags, and <code class="literal">do</code> flags</h5></div></div></div><p>See <a class="xref" href="#do-api-via-brick-simple" title="The do API via brick_simple">the section called “The <code class="literal">do</code> API via <code class="literal">brick_simple</code>”</a> for examples that use the <code class="literal">do()</code>
client interface.</p><p>All of the basic <code class="literal">do</code> operations are encoded into a small number of
tuples.  See <code class="literal">make_op2()</code>, <code class="literal">make_op5()</code>, and <code class="literal">make_op6()</code>.  Note that
if you want to manage your own timestamps, rather than use ones based
on the OS system clock, you must use the <code class="literal">make_op6()</code> function
yourself.  A more convenient API doesn’t yet exist because there’s
been no need for it … but it would be easy &amp; quick to write.</p><p>By default, the various operations within a <code class="literal">do</code> call’s <code class="literal">DoList</code> do
not have any transaction semantics.  If a <code class="literal">DoList</code> contains 5
operations, then there is almost no difference between sending that
<code class="literal">DoList</code> to a server than there is sending 5 different <code class="literal">do</code>
operations, each containing a single op.  However…</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
there are two good reasons why an application developer might want
to combine those 5 ops into a single <code class="literal">do</code> call:
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
To reduce the total amount of time required to process the 5 ops.
</li><li class="listitem"><p class="simpara">
To take advantage of the brick’s guarantee that no other ops (sent
  by another client) can be interleaved with the execution of those 5 ops.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Note that this guarantee is not the same as the guarantees provided
   by micro-transactions.
</li></ul></div></li></ul></div></li></ol></div><p>There are two types of flags that can be sent with a <code class="literal">do</code> op:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
Flags bundled in the <code class="literal">make_op</code>* function, which affect only that
  particular operation.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
See the EDoc description of <code class="literal">encode_op_flags/1</code> for valid op flag
   names.
</li></ul></div></li><li class="listitem"><p class="simpara">
Flags that affect all ops in the <code class="literal">do</code> list.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
See the EDoc description of <code class="literal">do/5</code> for valid <code class="literal">DoFlags</code> names.
</li></ul></div></li></ul></div></div><div class="section" title="Disk logging and log flush options"><div class="titlepage"><div><div><h5 class="title"><a id="_disk_logging_and_log_flush_options"></a>Disk logging and log flush options</h5></div></div></div><p>The Admin Server maintains the table-specific settings for disk
logging and log flush parameters for all bricks in the table.  By
default, both disk logging and log flushing are enabled.  Both
features are actually implemented by <code class="literal">brick_ets.erl</code>, but the API to
change those parameters at runtime are handled through
<code class="literal">brick_server.erl</code>.</p><p>See <code class="literal">set_do_logging/2</code> and <code class="literal">set_do_sync</code>.</p></div><div class="section" title="Brick role management"><div class="titlepage"><div><div><h5 class="title"><a id="_brick_role_management"></a>Brick role management</h5></div></div></div><p>The role management functions were designed for use by the Admin
Server to manage the brick lifecycle state machine.  See comment
"Chain admin &amp; related API" in <code class="literal">-export</code> statements at top of the
file.</p><p>See <a class="ulink" href="hibari-sysadmin-guide.en.html#brick-lifecycle-fsm" target="_top">Hibari
Sysadmin Guide, "Brick Lifecycle Finite State Machine" section</a> for
a description of a brick’s lifecycle within chain replication.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-role-management"></a></th></tr><tr><td align="left" valign="top"><p>When a brick’s role is set, the brick knows at most its
immediate upstream brick and its immediate downstream brick.  Most of
the time, this decision works well.  However, occasionally it’s useful
for a brick to know all members of its chain, e.g. when the
<code class="literal">brick_mboxmon</code> needs to signal the head brick to slow down.  These
cases haven’t happened often enough to trigger a refactoring, but it
might be useful later.</p></td></tr></table></div><p>Management of the <code class="literal">#chain_r</code> record is tricky whenever a role is
changed.  There are some attributes of the record that should be reset
to a default value and other attributes that must be preserved.
Examples of the latter are log serial numbers used by the brick as
well as serial numbers ack’ed downstream &amp; upstream.  Some role
transitions must also be reflected in the <code class="literal">brick_pingee</code> helper
process (see <a class="xref" href="#brick-pingee-erl" title="brick_pingee.erl">the section called “brick_pingee.erl”</a>).  The result looks more complex
than you’d first believe is necessary, but there isn’t much excess
code to remove: much of that complexity is necessary.</p></div><div class="section" title="Consistent hashing is enforced by brick servers, do forwarding"><div class="titlepage"><div><div><h5 class="title"><a id="_consistent_hashing_is_enforced_by_brick_servers_literal_do_literal_forwarding"></a>Consistent hashing is enforced by brick servers, <code class="literal">do</code> forwarding</h5></div></div></div><p>As described in <a class="xref" href="#brick-hash-erl" title="brick_hash.erl">the section called “brick_hash.erl”</a>, the <code class="literal">brick_hash.erl</code> module is
used for consistent hashing calculations by Hibari clients.  However,
because a client may be acting on old/stale data, each Hibari brick
also uses <code class="literal">brick_hash</code> to verify that each operation it receives
should be executed locally.</p><p>If a client sends a <code class="literal">do</code> call to the wrong brick, as calculated by the
brick’s global hash, then that brick will forward the <code class="literal">do</code> call to
what it believes is the correct brick.  However, due to asynchronous
message passing, scheduling latencies, network latencies, etc., the
<span class="emphasis"><em>brick itself</em></span> may have an old/stale version of the global hash.  In
such a case, the <code class="literal">do</code> will be forwarded to the wrong brick.  However,
because each brick will forward the <code class="literal">do</code> to where it believes the <code class="literal">do</code>
should go, eventually the <code class="literal">do</code> call will arrive at its proper
location.  In the event that the forwarding takes too long, the client
will see a timeout.</p><p>The forwarding mechanism is limited by a couple of factors:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Each forwarding increments a forwarding hop counter.
</li><li class="listitem">
After the first few forwarding hops, a geometrically-increasing
  sleep period is used before actual forwarding.
</li><li class="listitem">
After a limit of 18 forwarding hops, the query is dropped.
</li></ul></div><p>Each time the <code class="literal">do</code> call is forwarded, the <code class="literal">SentAt</code> time (which is
originally set by the client node) is reset to the current wall-clock
time.  This reset is done to prevent <code class="literal">brick_do_op_too_old_timeout</code>
configuration attribute enforcement; see
<a class="ulink" href="hibari-sysadmin-guide.en.html#ntp-config-strongly-recommended" target="_top">Hibari
Sysadmin Guide, "NTP configuration of all Hibari server and client
nodes" section</a>.</p></div><div class="section" title="Chain replication protocol messages and sending client replies"><div class="titlepage"><div><div><h5 class="title"><a id="_chain_replication_protocol_messages_and_sending_client_replies"></a>Chain replication protocol messages and sending client replies</h5></div></div></div><p>See <a class="ulink" href="hibari-sysadmin-guide.en.html#chain-lifecycle-fsm" target="_top">Hibari
Sysadmin Guide, "Chain Lifecycle Finite State Machine" section</a> for
background information.</p><p>Both chain replication protocol messages and client replies are sent
"downstream", i.e. they are sent to the next brick in the chain.</p><p>The reply term for a <code class="literal">do</code> call is piggy-backed onto the chain
replication message that is sent down the chain.  When a chain
replication protocol message reaches a brick has the "official tail"
role, then:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The reply is sent to the client.
</li><li class="listitem">
If the brick has a downstream brick (i.e. there is a brick currently
  under repair that is downstream of the "official tail" brick), then
  the chain replication protocol message is sent downstream.
</li></ul></div><p>If the <code class="literal">do</code> operation has the <code class="literal">ignore_role</code> property in its <code class="literal">DoFlags</code>
property list, then the reply is sent directly to the client (instead
of the default behavior of being sent downstream with the chain
replication message).</p><p>The chain replication protocol messages are:</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">{ch_log_replay, UpstreamBrick, Serial, Thisdo_Mods, From, Reply}</code>
</span></dt><dd>
The <code class="literal">UpstreamBrick</code> and <code class="literal">Serial</code> terms are used to verify that the
message comes from the correct brick and that messages have not been
sent out-of-order.  The <code class="literal">Thisdo_Mods</code> term contains the write-ahead
log terms associated with this update (i.e. insert and delete
commands), and <code class="literal">From</code> and <code class="literal">Reply</code> are used to send the <code class="literal">Reply</code> term to
the client.
</dd><dt><span class="term">
<code class="literal">{ch_serial_ack, Serial, BrickName, Node, Props}</code>
</span></dt><dd>
Once per second, the tail brick sends this message upstream.  All
other bricks in the chain forward it upstream until it reaches the
head brick.  All bricks in the chain keep track of the <code class="literal">Serial</code> number
in these messages and purge from their in-memory buffers all log
replay requests with serial numbers less than or equal to <code class="literal">Serial</code>:
these replay requests are no longer required to recover from failure
of a middle brick.
</dd></dl></div></div><div class="section" title="Write-ahead log sequence number complications"><div class="titlepage"><div><div><h5 class="title"><a id="_write_ahead_log_sequence_number_complications"></a>Write-ahead log sequence number complications</h5></div></div></div><p>See <a class="xref" href="#log-flushing-and-sync-pid" title="Log flushing and the sync pid and the logging_op_q">the section called “Log flushing and the sync pid and the logging_op_q”</a> for background on the write-ahead
log serial number’s use and management.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-wal"></a></th></tr><tr><td align="left" valign="top"><p>Of all the complications that were introduced by the separation
of the ‘brick_ets.erl` and <code class="literal">brick_server.erl</code> modules, the largest
source of nasty, hard-to-find bugs has been management of the
write-ahead log queues, the <code class="literal">#state.logging_op_q</code> term in both
modules’ state record.  Refactoring this log management would probably
help performance by reducing CPU consumption as well as making the
core server code less fragile.</p><p>One area that might be easier to refactor is the management of the
serial number associated with each queue.  Incrementing the serial
number is done by the caller after writing something to the queue.  It
would likely be much less error-prone if the writing and the
incrementing were done by the same call.</p></td></tr></table></div><p>There is a lot of code in <code class="literal">chain_send_downstream_iff_empty_log_q/6</code>
and elsewhere to make certain that log events are sent downstream
without violating ordering constraints.  I confess it isn’t pretty,
but all of the bugs that I know of have been wrung out.  If there are
still bugs (and I suspect but cannot prove that there is one more),
the paranoid sanity checking done by the downstream/receiving brick
will crash if <code class="literal">Serial</code> numbers are received out-of-order.  It isn’t a
pretty way to recover from such an error, but it’s the safest reaction
that I know of.</p></div><div class="section" title="Chain repair protocol messages"><div class="titlepage"><div><div><h5 class="title"><a id="_chain_repair_protocol_messages"></a>Chain repair protocol messages</h5></div></div></div><p>The chain repair protocol has been implemented twice.  The first
protocol was a brute-force, "as simple as possible" affair.  The
upstream brick would send a series of <code class="literal">{ch_repair, Serial,
RepairList}</code> messages to the repairing brick.  <code class="literal">RepairList</code> contained
a list of store tuples (see <a class="xref" href="#store-tuple" title="The &quot;store tuple&quot;">the section called “The "store tuple"”</a>) for all keys in the
table.  Note that these store tuples will always contain the full
value blob.</p><p>The first protocol was deprecated after it became clear that "as
simple as possible" had too much overhead.  When in-RAM storage of
value blobs was the only option, then it was cheap to fetch the value
blobs and send them across the network to the repairing brick.  But
when "bigdata" storage was introduced (see
<a class="xref" href="#value-blobs-on-disk" title="Value blob storage on disk: bigdata_dir">the section called “Value blob storage on disk: bigdata_dir”</a>), then the disk I/O, network bandwidth, and
total latency became far too high to be practical.</p><p>The second chain repair protocol uses two rounds of messages to avoid
the I/O problems caused by the first protocol:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
First round: The upstream sends a list of keys, a
subset of all keys stored by the brick.  The downstream replies with
the list of keys that it does not have copies of.
</li><li class="listitem">
Second round: If the downstream does not need any keys, this round
is skipped.  Otherwise, the upstream sends the downstream the store
tuples (including value blob) for only the keys that the client
requested in round 1.
</li></ol></div><p>The following messages are exchanged:</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">{ch_repair_diff_round1, Serial, RepairList}</code>
</span></dt><dd>
The 1st round message sent by the upstream brick.  Only key and
timestamps are included in <code class="literal">RepairList</code>.
</dd><dt><span class="term">
<code class="literal">{ch_repair_diff_round1_ack, Serial, BrickName, Node, Unknown, Ds}</code>
</span></dt><dd><p class="simpara">
This is the downstream brick’s response to the
<code class="literal">{ch_repair_diff_round1, ...}</code> message.  The <code class="literal">Unknown</code> term is a list
of keys that are missing from the downstream brick (completely missing
or timestamp mismatch).  The <code class="literal">Ds</code> informs the upstream brick of how
many keys were deleted by the downstream brick.
</p><p class="simpara">If the brick’s value blobs are stored on disk, then an asynchronous
"priming" mechanism is used by the upstream brick to force those blobs
into RAM before processing sending the 2nd round.</p></dd><dt><span class="term">
<code class="literal">{ch_repair_diff_round2, Serial, RepairList, Ds}</code>
</span></dt><dd>
The upstream brick sends this message with <code class="literal">RepairList</code> containing all
store tuples (with value blobs) for all keys requested in round 1.
The <code class="literal">Ds</code> term is not used.
</dd><dt><span class="term">
<code class="literal">{ch_repair_ack, Serial, BrickName, Node, Inserted, Deleted}</code>
</span></dt><dd>
The downstream brick sends this message in both the old and new repair
protocol versions.  <code class="literal">Inserted</code> and <code class="literal">Deleted</code> count the number of keys
that were inserted and deleted into the repairing brick, respectively.
</dd><dt><span class="term">
<code class="literal">{ch_repair_finished, Brick, Node, Checkpoint_p, NumKeys}</code>
</span></dt><dd>
The upstream brick sends this message when the round 1 messages have
iterated over all keys.  When received, the downstream brick will move
itself from the <code class="literal">repairing</code> state to the <code class="literal">ok</code> state.  The brick
"pinger" process will notice this state transition and trigger further
chain role changes.
</dd></dl></div><p>While these repair protocol messages are exchanged, the upstream brick
will send all <code class="literal">{ch_log_replay,...}</code> chain replication messages as
updates occur.  On the upstream brick, the <code class="literal">{ch_repair_diff_round1,
Serial, RepairList}</code> is created without interference from client
updates; any keys not in <code class="literal">RepairList</code> are immediately deleted by the
downstream brick before replying with the
<code class="literal">{ch_repair_diff_round1_ack,...}</code> message.  Therefore, any possible
race conditions involving client updates of keys within the
<code class="literal">RepairList</code> range of keys are resolved correctly by the log serial
mechanism, because only one of two races can happen inside the
upstream brick:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The client update <code class="literal">{ch_log_replay,...}</code> message is sent before the
  upstream creates and sends the round 1 repair message.  Any keys
  updated in the log replay message are guaranteed to be included in
  the round 1 repair message.
</li><li class="listitem">
The client update <code class="literal">{ch_log_replay,...}</code> message is sent after the
  upstream creates and sends the round 1 repair message.  Any keys
  updated in the log replay message are guaranteed to not be included
  in the round 1 repair message.  Replay of the replay message can
  happen safely at any time (as long as serial number ordering is
  preserved).
</li></ul></div></div><div class="section" title="Data migration protocol messages"><div class="titlepage"><div><div><h5 class="title"><a id="_data_migration_protocol_messages"></a>Data migration protocol messages</h5></div></div></div><p>The data migration mechanism is used to move keys from one chain to
another when chains are added, removed, or reweighted.  The task of
moving keys while maintaining strong consistency is a delicate
business.  The protocol, which uses two rounds (or phases), described
below is used to move keys safely between chains.</p><p>During migration, the head of each chain maintains a "sweep key
pointer".  This pointer moves through the keys, first to last (in
lexicographic sorting order).</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Keys that are "in front" of the sweep
key, i.e. keys that are larger than the sweep key, have not yet been
scanned by the migration algorithm.
</li><li class="listitem">
Keys that are "behind" the sweep key, i.e. keys that are smaller
than the sweep key, have been scanned by the migration algorithm.
</li></ul></div><p>The sweep key advances through the head brick’s keys, advancing by a
maximum of <code class="literal">max_keys_per_iter</code> configuration attributed in
<code class="literal">central.conf</code> or a maximum of 64MB of blob values (hardcoded for now
in <code class="literal">get_sweep_tuples/4</code>.  These keys are what the code calls the
"sweep zone": those keys between the sweep key’s current value and the
sweep key’s value from the last successful iteration of the migration
protocol.</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">{ch_log_replay,...}</code> message with <code class="literal">{plog_sweep,phase1_sweep_info,#sweepcheckp_r}</code> modification inside
</span></dt><dd>
If the chain length is &gt; 1, the head brick must inform all bricks in
the chain where the new sweep key is located.  For chains of length 1,
this first phase is not required.  All bricks record the sweep info in the
<code class="literal">sweepcheckp_r</code> record into its private brick metadata: the head brick
before sending the message, all other bricks when receiving the
message.  The private metadata is used to recover vital state in case
the head brick crashes.  NOTE: This migration sweep metadata is called
a sweep checkpoint and is not related to a brick key checkpoint.
</dd><dt><span class="term">
<code class="literal">{sweep_phase1_done,LastKey}</code>
</span></dt><dd>
Sent by the tail of the chain back to the head, acknowledging that all
bricks in the chain have seen the <code class="literal">{plog_sweep,phase1_sweep_info,...}</code>
message.
</dd><dt><span class="term">
<code class="literal">{ch_sweep_from_other, ChainHeadPid, ChainName, Thisdo_Mods, LastKey}</code>
</span></dt><dd>
This message starts the second phase of migration.  The head brick has
calculated which keys must be moved to a new chain.  This message is
sent to the head of the new chain.  The <code class="literal">Thisdo_Mods</code>
contains the list of store tuples that are moving to the receiving
brick; this list is sent down the chain using the usual chain
replication protocol.  <code class="literal">LastKey</code> specifies where the sweep key
location for the <code class="literal">ChainName</code> chain.  One of these messages will be
sent to each chain that stores keys within the sweep zone; call the
number of chains <span class="emphasis"><em>X</em></span>.
</dd><dt><span class="term">
<code class="literal">{sweep_phase2_done, Key, PropList}</code>
</span></dt><dd>
When the modifications from the second phase’s
<code class="literal">{ch_sweep_from_other,...}</code> message have reached the tail of the new
chain, this message is sent to the head of the old chain to
acknowledge that the migrated keys are now fully replicated on the new
chain.  When the head brick receives <code class="literal">{ch_sweep_from_other,...}</code>
messages from all <span class="emphasis"><em>X</em></span> chains, then the second phase of migration is
finished.
</dd></dl></div></div><div class="section" title="Data migration mechanism and value blob &quot;priming&quot;"><div class="titlepage"><div><div><h5 class="title"><a id="_data_migration_mechanism_and_value_blob_priming"></a>Data migration mechanism and value blob "priming"</h5></div></div></div><p>In between round 1 and round 2 of a migration sweep iteration, the
same value blob "priming" technique is used to prevent disk I/O from
blocking the brick’s gen_server process.  See <code class="literal">sweep_move_or_keep/3</code>
and <code class="literal">spawn_val_prime_worker_for_sweep/3</code>.</p></div><div class="section" title="SSF: The server-side fun, client side"><div class="titlepage"><div><div><h5 class="title"><a id="_ssf_the_server_side_fun_client_side"></a>SSF: The server-side fun, client side</h5></div></div></div><p>"SSF" stands for "Server-Side Fun".  An SSF is an Erlang fun that is
created by a Hibari client and executed on a Hibari server brick.  The
SSF has the ability to rewrite the <code class="literal">DoList</code> of operations in the <code class="literal">do</code>
call based on the ability to examine the brick’s internal state.</p><p>In the end, the SSF cannot do anything that cannot be done with
multiple queries to a brick.  For example, here is a simple two-query
scheme to update simple counter value in a race-safe manner:</p><p title="Incrementing a counter"><b>Incrementing a counter. </b>
</p><pre class="screen">{ok, TS, OldValBin} = brick_simple:get(TableName, Key),
OldVal = binary_to_term(OldValBin),
ok = brick_simple:replace(TableName, Key, term_to_binary(OldVal + 1),
                          [{testset, TS}]),
%% Use OldVal in code below this point.</pre><p title="Incrementing a counter">
</p><p>An SSF would use a very similar bit of logic and would create the same
<code class="literal">replace</code> operation.</p><p title="Incrementing a counter with an SSF"><b>Incrementing a counter with an SSF. </b>
</p><pre class="screen">F = fun(Key, _DoOp, _DoFlags, S) -&gt;
      [{_Key, TS, Val, _Exp, _KeyFlags}] = brick_server:ssf_peek(Key, true, S),
      OldVal = binary_to_term(Val),
      {ok, [brick_server:make_replace(Key, term_to_binary(OldVal + 1), 0,
                                      [{testset, TS}]),
            {current_val, OldVal}]}
    end,
Op = brick_server:make_ssf(Key, F),
[ok, {current_val, OldVal}] = brick_server:do(TableName, [op]),
%% Use OldVal in code below this point.</pre><p title="Incrementing a counter with an SSF">
</p><p>The SSF fun creates a list of <code class="literal">do</code> primitive operations, in this case
two operations:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A <code class="literal">replace</code> operation to update the key
</li><li class="listitem">
A "pass-through" 2-tuple to tell the client the current value of the
  counter.  Because this 2-tuple isn’t a valid brick operation, the
  term is returned to the client as-is.
</li></ul></div><p>Here is an example that uses the SSF above.  It assumes that the shell
variable <code class="literal">F</code> has been bound to the fun above.  A cut-and-paste of the
code above will work well, assuming that <code class="literal">F</code> is not already bound to a
shell variable and that the final "end," is replaced with "end.".</p><pre class="literallayout">(hibari_dev@bb3)13&gt; brick_simple:set(tab1, "c1", term_to_binary(0)).
ok</pre><pre class="literallayout">(hibari_dev@bb3)14&gt; Op = brick_server:make_ssf("c1", F).
{ssf,&lt;&lt;"c1"&gt;&gt;,[#Fun&lt;erl_eval.4.105156089&gt;]}</pre><pre class="literallayout">(hibari_dev@bb3)15&gt; brick_simple:do(tab1, [Op]).
[ok,{current_val,0}]</pre><pre class="literallayout">(hibari_dev@bb3)16&gt; brick_simple:do(tab1, [Op]).
[ok,{current_val,1}]</pre><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The SSF is executed to create a list of <code class="literal">do</code> primitive
operations.  All attempts to examine brick keys must be done using the
<code class="literal">brick_server:ssf_peek/3</code> function.  The <code class="literal">brick_server:ssf_peek/3</code>
cannot guarantee that the key will not be modified immediately after
the <code class="literal">ssf_peek/3</code> call and the actual execution of the <code class="literal">DoList</code> created
by the SSF.</p><p>For example, here is a case where the timestamp of the key has been
modified in a race with another client.  Note that the 2nd element in
the return term, <code class="literal">{current_val, N}</code>, is included in the results
despite the error.  The client must perform sufficient pattern
matching and/or other sanity checks to verify that the SSF and its
<code class="literal">DoList</code> output were successful.</p><pre class="literallayout">(hibari_dev@bb3)21&gt; brick_simple:do(tab1, [Op2]).
[{ts_error,1272654442441669},{current_val,2}]</pre></td></tr></table></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The API of the SSF is a work-in-progress.  It is used by one
internal Gemini project but otherwise does not have strong
backward-compatibility requirements.</p></td></tr></table></div></div><div class="section" title="SSF: The server-side fun, server side"><div class="titlepage"><div><div><h5 class="title"><a id="_ssf_the_server_side_fun_server_side"></a>SSF: The server-side fun, server side</h5></div></div></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The API of the SSF is a work-in-progress.  It is used by one
internal Gemini project but otherwise does not have strong
backward-compatibility requirements.</p></td></tr></table></div><p>The implementation of SSFs (server-side funs) on the server side of
the world is an experiment using a general framework for modifying
<code class="literal">do</code> operations on the client side before they are executed.  This
experiment is implemented by the combination of:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The <code class="literal">brick_preprocess_method</code> configuration attributed in
  <code class="literal">central.conf</code>.
</li><li class="listitem">
The <code class="literal">handle_call_do/3</code> and <code class="literal">preprocess_fold/4</code> functions.
</li><li class="listitem">
Individual functions in the <code class="literal">#state.do_list_preprocess</code> list.
</li></ul></div><p>The current implementation allows the output of the SSF to replace the
{ssf, Key, Fun} tuple inside the <code class="literal">do</code> call’s <code class="literal">DoList</code> list of
operations.  It does not permit the arbitrary modification of the
entire <code class="literal">DoList</code> list, nor does it permit examination of other
operations in the <code class="literal">DoList</code>.  The reasoning for the limitation is that
all <code class="literal">DoList</code> items ultimately come from a single client in a single
<code class="literal">do</code> operation; if the client wanted to reorder things arbitrarily,
the client has the power to do that before sending the <code class="literal">do</code> call.</p></div><div class="section" title="MD5 checksum errors in the write-ahead log"><div class="titlepage"><div><div><h5 class="title"><a id="_md5_checksum_errors_in_the_write_ahead_log"></a>MD5 checksum errors in the write-ahead log</h5></div></div></div><p>When an MD5 checksum error is detected by <code class="literal">brick_ets.erl</code> or one of
the write-ahead log modules, dealing with the error is a bit complex:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Data structures maintained by <code class="literal">brick_ets.erl</code> require changes.
</li><li class="listitem">
The error may be inside a file in the "common log", the part
  of the write-ahead log shared by all bricks on the node.  In this
  case, all bricks must be notified that a file in the common log is
  bad.
</li></ul></div><p>The <code class="literal">common_log_sequence_file_is_bad/3</code> function is used by
<code class="literal">gmt_hlog_common.erl</code> to notify each brick when an MD5 checksum error
is found.</p></div><div class="section" title="Checkpoint options"><div class="titlepage"><div><div><h5 class="title"><a id="_checkpoint_options"></a>Checkpoint options</h5></div></div></div><p>The checkpoint operation is implemented by <code class="literal">brick_ets.erl</code>, but the
API options are documented in the EDoc for
<code class="literal">brick_server:checkpoint/3</code>.</p><p>See <a class="xref" href="#brick-ets-erl-ets-tables" title="ETS tables">the section called “ETS tables”</a> and <a class="xref" href="#brick-ets-erl-processes" title="Processes created by brick_ets.erl">the section called “Processes created by brick_ets.erl”</a>
for more information information about checkpointing.</p></div><div class="section" title="Scavenger options"><div class="titlepage"><div><div><h5 class="title"><a id="_scavenger_options"></a>Scavenger options</h5></div></div></div><p>The implementation of the scavenger is spread across both
two modules.  As a general rule, the low-level key scanning and hunk
copying is done by functions in <code class="literal">brick_ets.erl</code>, while the
higher-level coordination is implemented in <code class="literal">gmt_hlog_common.erl</code>.</p><p>One property worth noting here is the <code class="literal">destructive</code> option.  If this
property is false, then the scavenger will read keys but not do
anything to relocate the keys.  When used in combination with
<code class="literal">{skip_live_percentage_greater_than,100}</code>, the scavenger can verify
the MD5 checksums of all value blobs by reading all value blob hunks
in sorted, log file sequence order.</p><p>The scavenger can be halted manually using
<code class="literal">gmt_hlog_common:stop_scavenger_commonlog/0</code> and resumed using
<code class="literal">gmt_hlog_common:resume_scavenger_commonlog/2</code>.</p></div><div class="section" title="Scavenger and code reuse"><div class="titlepage"><div><div><h5 class="title"><a id="scavenger-and-code-reuse"></a>Scavenger and code reuse</h5></div></div></div><p>One of the design ideas behind the scavenger is that it should try to
avoid random I/O as much as possible.  The scavenger uses the same
write-ahead log as everyone else, and since the write-ahead log always
uses sequential file writes and does a decent job of batching multiple
writes with a fewer number of <code class="literal">fsync(2)</code> calls, write I/O is mostly
sequential.  However, the scavenger’s read I/O should also be as
sequential as possible … so the scavenger goes through a lot of
effort to read all hunks from a single log file at the same time and
in sequential offset order.</p></div><div class="section" title="Fast sync"><div class="titlepage"><div><div><h5 class="title"><a id="fast-sync"></a>Fast sync</h5></div></div></div><p>The sequential read property introduced at
<a class="xref" href="#scavenger-and-code-reuse" title="Scavenger and code reuse">the section called “Scavenger and code reuse”</a> can be useful in other areas also.
For example, the "fast sync" utility in <code class="literal">brick_admin.erl</code>.</p><p>The utility is intended for use in cases where a very large brick has
had a catastrophic failure, and all data on that brick is lost.  The
chain replication algorithm will perform repair based on key
lexicographic sort order.  The key sorting order is not correlated with
storage location within the common log.  The result is disk read I/O
patterns that are mostly random, meaning it could take days to fully
repair a brick that had lost many terabytes of data.</p><p>The "fast sync" utility uses the scavenger’s infrastructure to sort
live keys into log sequence and offset order (instead of lexicographic
order).  Ideally, this changes the read I/O pattern on the repairing
brick to be more sequential than random.  Once the "fast sync" utility
is finished, then usual chain replication is used to fix discrepancies
caused by updates made while the "fast sync" was running.</p></div></div><div class="section" title="brick_shepherd.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-shepherd-erl"></a>brick_shepherd.erl</h4></div></div></div><p>The brick shepherd "gen_server" is the public interface for
adding/removing logical bricks to/from the <code class="literal">brick_brick_sup</code>
supervisor.</p><p>For testing purposes, the functions <code class="literal">add_do_not_restart_brick/2</code> and
<code class="literal">delete_do_not_restart_brick/2</code> allow developers and test scripts to
crash a brick and prevent their prompt restart.</p></div><div class="section" title="brick_simple.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-simple-erl"></a>brick_simple.erl</h4></div></div></div><p>The <code class="literal">brick_simple.erl</code> module provides three sets of services for
Hibari clients and administrators.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
An easy-to-use client API to fetch and update key/value data in a
  Hibari cluster.
</li><li class="listitem">
A "gen_server" that runs on each Hibari client node that receives
  cluster status updates from the Hibari Admin Server.  This server,
  with the registered name <code class="literal">brick_simple</code>, runs as part of both the
  <code class="literal">gdss</code> and <code class="literal">gdss_client</code> OTP applications.
</li><li class="listitem">
A handful of hash-related utility functions useful for Hibari
  administrators.
</li></ul></div><p>Each client API call, e.g. <code class="literal">add()</code>, <code class="literal">get_many()</code>, needs to query the
<code class="literal">brick_simple</code> server as prerequisite of the consistent hashing
calculation and <code class="literal">{TableName, Key}</code> → chain mapping.  The Erlang
process dictionary is (ab)used to improve performance by reducing the
size of replies sent by <code class="literal">brick_simple</code>.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-brick-simple"></a></th></tr><tr><td align="left" valign="top"><p>Parts of the exported API for this module may seem cumbersome to
use.  Those parts are from a bottom-up code writing experiment that
created only exported APIs needed for very specific tasks, not to
create a more useful (generally-speaking) interface.  A refactoring
exercise could be useful here.</p></td></tr></table></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The <code class="literal">fold_table()</code> API functions are not fully robust in cases
where bricks fail or when a data migration is in progress.  If a
robust full-table fold is required, then another implementation is
required.</p></td></tr></table></div></div><div class="section" title="brick_squorum.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-squorum-erl"></a>brick_squorum.erl</h4></div></div></div><p>This is a simplified quorum-based replication client for Hibari server
bricks.  See <a class="xref" href="#brick-admin-erl" title="brick_admin.erl">the section called “brick_admin.erl”</a> for background and
<a class="ulink" href="hibari-sysadmin-guide.en.html#admin-server-app" target="_top">Hibari Sysadmin
Guide, "The Admin Server Application" section</a> for background info.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-brick-squorum"></a></th></tr><tr><td align="left" valign="top"><p>"Simplified" means that it’s meant for use only within the Admin
Server and should not be used (in its current form) by other
applications.  It should be straightforward enough to maintain
compatibility with the Admin Server while refactoring to add some
missing robustness features, e.g. client-side repair when
inconsistencies are detected in 100% of use cases.</p></td></tr></table></div><p>The intent of this module is provide naive and simple yet robust
storage for use by an cluster admin/manager server.  Such a server
has limited requirements for persistent data, but it doesn’t make
sense to store that data on a local disk.  For availability, that
data should be spread across multiple bricks.  However, there’s a
chicken-and-the-egg problem for a cluster manager: if the cluster
must be running in order to serve data, how do you start the
cluster?</p><p>The answer (for now) is to have any machine capable of running an
administrator to have a statically configured list of bricks that
store cluster manager data.  A very simple quorum technique is used
for robust storage.</p><p>No transaction support is provided, since we assume that the
manager will use some other mechanism for preventing multiple
managers from running simultaneously.</p><p>The Admin Server uses the <code class="literal">Schema.local</code> file as a hint for breaking
the chicken-and-egg problem of finding the bootstrap bricks.  The
bricks listed in <code class="literal">Schema.local</code> are consulted to try to find a valid
<code class="literal">#schema_r</code> record.  Once a copy of that record is found, then the
real list of bootstrap bricks in <code class="literal">#schema_r.schema_bricklist</code> is used
for all subsequent quorum calculations.</p></div><div class="section" title="brick_sup.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-sup-erl"></a>brick_sup.erl</h4></div></div></div><p>This is the top-level supervisor for the <code class="literal">gdss</code> Hibari application.</p></div><div class="section" title="brick_ticket.erl"><div class="titlepage"><div><div><h4 class="title"><a id="brick-ticket-erl"></a>brick_ticket.erl</h4></div></div></div><p>The <code class="literal">brick_ticket.erl</code> module implements a subset of functionality of
another Gemini application.  It provides ticket-based workload
limiting services, sometimes called "admission-based rate limiting".</p><p>The goal is to limit the amount of <span class="emphasis"><em>X</em></span> things that can happen per unit
of time, e.g. executing a function per minute or reading a maximum
number of bytes/second.</p><p>Hibari bricks use this ticket-based system to provide shared
throttling mechanisms for checkpoint and scavenger operations.  Via
<code class="literal">central.conf</code>, both activities are limited to a certain amount of
write bandwidth per second.</p></div><div class="section" title="gmt_hlog.erl"><div class="titlepage"><div><div><h4 class="title"><a id="gmt-hlog-erl"></a>gmt_hlog.erl</h4></div></div></div><p>See <a class="ulink" href="hibari-sysadmin-guide.en.html#write-ahead-logs" target="_top">Hibari Sysadmin
Guide, "Write-Ahead Logs" section</a> for background info.</p><p>The Erlang/OTP <code class="literal">disk_log</code> library does not support random access into
one of its log files.  Hibari’s on-disk value blob storage requires
very efficient random access to the write-ahead log.  Therefore,
<code class="literal">disk_log</code> wasn’t sufficient.</p><p>I came close to using a bridge to Berkeley DB to use only the Berkeley
DB logging subsystem.  But I discovered some tough problems around the
edges of the that subsystem, and I abandoned the idea.  I don’t
recall what issue(s) it was, but I recall it was related to a
not-so-clean separation between the logging subsystem and another DB
system when the log was opened?</p><p>The basic concept for this module is stolen from the Berkeley DB
logging subsystem.  DB’s logging subsystem allows you to append a hunk
to a log.  In return, you get an "LSN", which is a file number and
byte offset for where that hunk of data is stored.  Given the LSN,
it’s trivial matter (with very low overhead) to retrieve any hunk in
any desired access pattern.</p><p>I added a couple of features that Berkeley DB’s logging subsystem does
not have:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Each hunk written to the log can contain multiple blobs (or perhaps
sub-hunks?).  So instead of identifying a hunk by <code class="literal">{FileNum,Offset}</code>
it would be identified by <code class="literal">{FileNum,Offset,HunkNumber}</code>.  I don’t
believe this feature is actually used by Hibari, but the CPU and
storage overheads to support it are low enough to be ignored.
</li><li class="listitem">
For any given hunk, each blob can have an MD5 checksum to detect
corruption of the blob.
</li></ol></div><p>The <code class="literal">gmt_hlog.erl</code> module started as the sole implementation module of
a write-ahead log.  Later, it was split into three separate modules:</p><div class="variablelist"><dl><dt><span class="term">
<code class="literal">gmt_hlog.erl</code>
</span></dt><dd>
This module manages all of the directories and files used to store
write-ahead log data.  The separation of "common log" and "brick
private logs" is merely a matter of which directory each type of log
uses; both types of logs use exactly the same file data structures.
</dd><dt><span class="term">
<code class="literal">gmt_hlog_common.erl</code>
</span></dt><dd>
This module maintains the "common log" storage area.
</dd><dt><span class="term">
<code class="literal">gmt_hlog_local.erl</code>
</span></dt><dd>
This module is a code proxy/intermediate layer between a brick and the
actual write-ahead logs that it relies upon.  This module maintains
the barrier between the "common log" and the brick’s private metadata
write-ahead log.  Much of the <code class="literal">gmt_hlog_local</code> exported API are just
2-line wrappers around calls to <code class="literal">gmt_hlog</code> functions, because there is
nothing for the proxy to do in those cases.
</dd></dl></div><div class="section" title="Glossary for write-ahead log terms"><div class="titlepage"><div><div><h5 class="title"><a id="glossary-write-ahead-log-terms"></a>Glossary for write-ahead log terms</h5></div></div></div><div class="variablelist"><dl><dt><span class="term">
Log
</span></dt><dd>
A collection of log files.
</dd><dt><span class="term">
Log file
</span></dt><dd>
A single file that stores hunks as part of a larger
collection known as a "log".
</dd><dt><span class="term">
Log sequence number
</span></dt><dd>
The integer used to name a specific log file.
The sign of the log sequence number, i.e. positive or negative, may
change (see below) but the absolute value of the integer may not.
</dd><dt><span class="term">
Hunk
</span></dt><dd>
A collection of blobs that is appended as an atomic
unit to the end of the log’s latest log file.
</dd><dt><span class="term">
<code class="literal">{SeqNum, Offset}</code>
</span></dt><dd>
This tuple uniquely identifies a hunk.
It is directly analogous to the Berkeley DB "LSN" (Log Sequence
Number).  Together with the directory path for the log, any
part of the hunk can be retrieved via random access.
</dd><dt><span class="term">
Hunk type
</span></dt><dd>
A 32-bit integer that describes the type of hunk.
Mostly useful for application use.
</dd><dt><span class="term">
Blob
</span></dt><dd>
An Erlang binary term.
</dd><dt><span class="term">
CBlob/c_blob
</span></dt><dd>
A blob that also has an MD5 checksum stored inside
the hunk.
</dd><dt><span class="term">
UBlob/u_blob
</span></dt><dd>
A blob without an MD5 checksum.
</dd></dl></div></div><div class="section" title="Short term vs. long term log storage"><div class="titlepage"><div><div><h5 class="title"><a id="shortterm-and-longterm-storage"></a>Short term vs. long term log storage</h5></div></div></div><p>First, let’s have a short review of Hibari brick disk storage
properties and goals.  See the
<a class="ulink" href="hibari-sysadmin-guide.en.html#write-ahead-logs" target="_top">Hibari Sysadmin
Guide, "Write-Ahead Logs" section</a>
and also the
<a class="ulink" href="hibari-sysadmin-guide.en.html#brick-init" target="_top">"Brick Initialization" section</a>
for background info.</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
A logical brick stores all key metadata in RAM.
</li><li class="listitem"><p class="simpara">
All key updates (including ) are written to the write-ahead log.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
This metadata includes the <code class="literal">{FileNum,Offset}</code> storage location
   of disk-based value blob hunks, which are stored separately from
   key metadata hunks.
</li></ul></div></li><li class="listitem">
The write-ahead log is not, by itself, a random-access data
   structure in the way that a disk-based B-tree or hash table.
</li><li class="listitem">
It is desirable to eliminate as much random disk I/O as much as
   possible.
</li><li class="listitem">
After a crash, it is desirable to have the logical brick restart as
   quickly as possible.
</li></ol></div><p>As a consequence of these properties:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
After a crash, the only method to reconstruct the brick’s “key
  catalog” is a sequential scan of the write-ahead log (because
  random access is not fully supported).
</li><li class="listitem">
To meet the goal of restarting quickly, it would be helpful to
  reduce the the amount of data that must be scanned sequentially.
</li><li class="listitem"><p class="simpara">
It is quite difficult to fully support Items #4 and #5
  simultaneously.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
Item #4 suggests that both types of data hunks, key metadata and
   value blobs, be written into the same log to reduce disk I/O.
</li><li class="listitem">
Item #5 suggests that both types of data hunks be written in
   separate locations to make brick startup, specifically the scan &amp;
   reconstruction of the key catalog, as fast as possible.
</li></ul></div></li></ul></div><p>The implementation of <code class="literal">gmt_hlog.erl</code> tries to resolve the conflict
between I/O efficiency and short startup times by storing data in
files stored in two different areas:</p><div class="variablelist"><dl><dt><span class="term">
The short term area (<code class="literal">shortterm</code> in the code)
</span></dt><dd><p class="simpara">
All key metadata hunks are always stored in shortterm storage.  To
support item #4, value blob hunks are also be written in short term
storage in order to amortize the expense of <code class="literal">fsync(2)</code> system calls.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Log files in short term storage have positive log sequence numbers.
</li><li class="listitem">
Log files in short term storage can be found in the <code class="literal">"s"</code>
   subdirectory, where "s" is an abbreviation for "short".
</li></ul></div></dd><dt><span class="term">
The long term area (<code class="literal">longterm</code> in the code)
</span></dt><dd><p class="simpara">
All long-lived value blob hunks, i.e. those hunks which have existed
long enough to exist after a checkpoint operation, are stored in long
term storage.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Log files in long term storage have negative log sequence numbers.
</li><li class="listitem">
Log files in long term storage are hashed and stored in one of many
   subdirectories, to avoid having millions of files all inside a
   single directory.
</li></ul></div></dd></dl></div><p title="Top-level listing of the common log&#x2019;s gmt_hlog file store."><b>Top-level listing of the common log’s <code class="literal">gmt_hlog</code> file store. </b>
</p><pre class="screen">% ls -l hlog.commonLogServer
total 24
drwxrwxr-x 9 hibari root 4096 2010-06-09 13:56 1/
drwxrwxr-x 9 hibari root 4096 2010-06-09 13:56 2/
drwxrwxr-x 9 hibari root 4096 2010-06-09 13:56 3/
-rw-rw-r-- 1 hibari root   14 2010-06-09 13:59 flush
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:56 register/
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:59 s/

% ls -l hlog.commonLogServer/s
total 16760
-rw-rw-r-- 1 hibari root 2701321 2010-06-09 13:58 000000000014.HLOG
-rw-rw-r-- 1 hibari root 2719724 2010-06-09 13:58 000000000015.HLOG
-rw-rw-r-- 1 hibari root 2765506 2010-06-09 13:59 000000000016.HLOG
-rw-rw-r-- 1 hibari root 2679379 2010-06-09 13:59 000000000017.HLOG
-rw-rw-r-- 1 hibari root 3008375 2010-06-09 13:59 000000000018.HLOG
-rw-rw-r-- 1 hibari root 2785571 2010-06-09 13:59 000000000019.HLOG
-rw-rw-r-- 1 hibari root  451182 2010-06-09 13:59 000000000020.HLOG
-rw-rw-r-- 1 hibari root      45 2010-06-09 13:56 Config

% ls -l hlog.commonLogServer/1
total 28
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:56 1/
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:56 2/
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:59 3/
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:57 4/
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:56 5/
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:59 6/
drwxrwxr-x 2 hibari root 4096 2010-06-09 13:57 7/

% ls -l hlog.commonLogServer/1/7:
total 2688
-rw-rw-r-- 1 hibari root 2745369 2010-06-09 13:56 -000000000006.HLOG</pre><p title="Top-level listing of the common log&#x2019;s gmt_hlog file store.">
</p><p>The application can request that a hunk be written into either area by
the write-ahead log.  As examples:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
All key updates (key metadata hunks and value blob hunks) are always
  written to the short term area.
</li><li class="listitem">
Checkpoint data is always written to the short term area.
</li><li class="listitem">
The scavenger reads value blob hunks that are still “alive” from
  their current location and always writes them to the long term area.
</li></ul></div><p>An entire log file can moved from short term storage to long term
storage by renaming it to its long term name, i.e from a positive log
sequence number to a negative log sequence number.  This renaming
operation is done at the end of a checkpoint operation by bricks that
store value blobs on disk: see the "Brick checkpoint processing steps"
list in
<a class="ulink" href="hibari-sysadmin-guide.en.html#checkpoints" target="_top">Hibari Sysadmin
Guide, "Brick Checkpoint Operations" section</a>.</p><p>Log files cannot move from long term to short term storage.</p><p>Given the separation of various log hunk types into short term and
long term storage, we have a couple of new properties:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
The number of log sequence files in short term storage will be
   quite small, usually well under 1,000 files total and typically
   under 100 files.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
This gets us most of the way to our goal of, "brick
   startup must be fast."  All key metadata is stored in the short term
   area.  Therefore we only need to read sequentially a fairly small
   number of files to reconstruct the brick’s key catalog.
</li></ul></div></li><li class="listitem"><p class="simpara">
The number of log sequence files in long term storage can be huge,
   perhaps millions of files.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Millions of files in the long term area can create
   a storage problem.  Many OS file systems cannot efficiently handle too
   many files within a single directory.  The long term storage area uses
   two levels of intermediate directories to avoid directories that are
   "too big".
</li></ul></div></li></ol></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>In theory, the constants to define the number of subdirectories
at each level are completely flexible.  In reality, use of the
<code class="literal">?ARCH_H1_SIZE</code> and <code class="literal">?ARCH_H2_SIZE</code> macros is hard-coded in some
critical areas.</p></td></tr></table></div></div><div class="section" title="Writing hunks and flushing them to stable storage"><div class="titlepage"><div><div><h5 class="title"><a id="_writing_hunks_and_flushing_them_to_stable_storage"></a>Writing hunks and flushing them to stable storage</h5></div></div></div><p>There’s a fundamental tension between writing hunks to disk as
efficiently as possible and flushing them to stable storage via the
<code class="literal">fsync(2)</code> system call.  The latency overhead of <code class="literal">fsync(2)</code> on
Winchester disks is extremely high.  Also, Linux-based systems can
block writes to a file descriptor when an <code class="literal">fsync(2)</code> operation is in
progress.</p><p>To mitigate the effects of <code class="literal">fsync(2)</code> calls, a couple of strategies
are used.  First, <code class="literal">file:sync/1</code> calls are performed asynchronously
when feasible.  Second, writes are buffered by the log’s "gen_server"
process while an <code class="literal">file:sync/1</code> call is in progress.  The "gen_server"
will promise to write the hunk at a given <code class="literal">{FileNum,Offset}</code> location
but won’t actually write the data there until the <code class="literal">fsync(2)</code> is
finished.</p><p>The "gen_server"'s write buffering opens up a can of worms: nasty race
conditions.  Races with write requests, fsync requests, in-progress
fsync calls, and "advance sequence number" requests are possible.
This module has been extensively reviewed and tested with both unit
tests and QuickCheck to eliminate those race conditions.  We believe
that all bugs have been eliminated, but as with many things in the
software world, we don’t really know with 100% certainty.</p></div><div class="section" title="Application-level and OS-level readahead"><div class="titlepage"><div><div><h5 class="title"><a id="_application_level_and_os_level_readahead"></a>Application-level and OS-level readahead</h5></div></div></div><p>See <a class="ulink" href="hibari-sysadmin-guide.en.html#os-readahead-configuration" target="_top">Hibari
Sysadmin Guide, "OS Readahead Configuration" section</a> for background.</p><p>The key metadata for disk-based value blob storage contains both the
storage location of the value blob hunk <span class="strong"><strong>and</strong></span> the size of the blob.
The blob’s size is usually passed through the <code class="literal">gmt_hlog</code> API when
reading the blob.  First the hunk header must be read and then the
value blob can be read.  A function like <code class="literal">read_hunk_summary/5</code> uses
the blob size argument to help combine (further down in the call
chain) the two reads into a single <code class="literal">file:pread()</code> call via the
<code class="literal">my_pread/4</code> function.</p><p>The <code class="literal">my_pread/4</code> function is a simple application-level readahead
mechanism.  The two major types of read operations both have elements
of readahead to them:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
For reads during brick initialization, the write-ahead log scan is
   reading many small-sized hunks in sequential order.  The average
   size of a key metadata hunk is less than 200 bytes, so a read-ahead
   of 4KB or 8KB is very helpful (though a bigger size would reduce
   CPU consumption even more).
</li><li class="listitem">
For the random reads of value blobs hunks, adding the estimated
   size of the hunk header and the known size of the value blob makes
   it possible to read both with a single <code class="literal">file:pread()</code> call.
</li></ol></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-my-pread"></a></th></tr><tr><td align="left" valign="top"><p>The code path of hunk reads, by both sequential reads during brick
init and random reads of value blob hunks, is probably sub-optimal.
The addition of <code class="literal">?MY_PREAD_MODEST_READAHEAD_BYTES</code> to the readahead
size by <code class="literal">read_hunk_summ_ll_middle/3</code> is a good thing (and should
probably be even bigger) in the former case and a bad thing for the
latter case.  Refactoring might be a good idea here.</p><p>Function tracing verifies that <code class="literal">read_hunk_summ_ll_middle/3</code> is
definitely used by the latter case.  But for random read I/O, reading
the extra <code class="literal">?MY_PREAD_MODEST_READAHEAD_BYTES</code> bytes is very unlikely to
have any benefit and quite possibly has negative impact.</p></td></tr></table></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>See also, the discussion at xref:squid-flash-priming.</p></td></tr></table></div></div><div class="section" title="MD5 checksums"><div class="titlepage"><div><div><h5 class="title"><a id="_md5_checksums"></a>MD5 checksums</h5></div></div></div><p>See <a class="xref" href="#controlling-md5-checksums" title="Controlling MD5 checksums">the section called “Controlling MD5 checksums”</a>.</p></div><div class="section" title="API comments"><div class="titlepage"><div><div><h5 class="title"><a id="_api_comments"></a>API comments</h5></div></div></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-gmt-hlog"></a></th></tr><tr><td align="left" valign="top"><p>Parts of the exported API for this module may seem cumbersome to
use.  Those parts are from a bottom-up code writing experiment that
created only exported APIs needed for very specific tasks, not to
create a more useful (generally-speaking) interface.  A refactoring
exercise could be useful here.</p></td></tr></table></div></div><div class="section" title="Processes created by gmt_hlog.erl"><div class="titlepage"><div><div><h5 class="title"><a id="gmt-hlog-erl-processes"></a>Processes created by gmt_hlog.erl</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Very short-lived processes to finish <code class="literal">{read_hunk,...}</code>
  <code class="literal">{get_all_seqnums}</code>, and <code class="literal">{sync}</code>  calls.
</li></ul></div></div></div><div class="section" title="gmt_hlog_common.erl"><div class="titlepage"><div><div><h4 class="title"><a id="gmt-hlog-common-erl"></a>gmt_hlog_common.erl</h4></div></div></div><p>This module is responsible for combining write &amp; fsync requests from
multiple bricks, via their <code class="literal">gmt_hlog_common</code> private write-ahead log
servers, into a single write-ahead log.  The writes and fsyncs must
provide a durable storage service (to prevent data loss), and
performance must be good enough (despite the slow speed of <code class="literal">fsync(2)</code>
operations on Winchester disk drives).</p><p>The "short term/long term" storage areas are described in
<a class="xref" href="#gmt-hlog-erl" title="gmt_hlog.erl">the section called “gmt_hlog.erl”</a>.  Together with <code class="literal">gmt_hlog_local.erl</code>, this module
creates a different separation of hunk types:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
Key metadata hunks, type = <code class="literal">?LOGTYPE_METADATA</code>.
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
To maintain the illusion of each logical brick maintaining its own
   private write-ahead log, hunks of type <code class="literal">?LOGTYPE_METADATA</code> are copied
   asynchronously out of the common log and into their pre-chosen
   <code class="literal">{FileNum,Offset}</code> location in the brick’s private write-ahead log by
   the <code class="literal">do_sync_writeback/1</code> function.  When a logical brick restarts,
   all common → private log writebacks are performed synchronously
   via <code class="literal">full_writeback/1</code> before the brick is allowed to restart.
</li></ul></div></li><li class="listitem">
Value blob hunks, type = <code class="literal">?LOGTYPE_BLOB</code>
</li><li class="listitem">
Bad sequence hunks, type = <code class="literal">?LOGTYPE_BAD_SEQUENCE</code>
</li></ul></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"><a id="refactor-os-sync"></a></th></tr><tr><td align="left" valign="top"><p>The common → private log writebacks are performed
lazily/asynchronously and do not use <code class="literal">fsync(2)</code> to flush to disk.
Instead, a
time-based mechanism is used, assuming that the OS has flushed all
writeback data to stable storage within a generous time limit
(configured by the <code class="literal">brick_dirty_buffer_wait</code> configuration attribute
in <code class="literal">central.conf</code>).  The advantage is to allow the OS to combine
various dirty page writes into as few disk I/O operations as possible
without interference from <code class="literal">fsync(2)</code> calls.</p><p>This assumption works for Linux platforms but probably isn’t valid for
FreeBSD and Mac OS.  It would be straightforward to use <code class="literal">file:sync(2)</code>
in a background task to flush these writebacks very infrequently (to
allow write coalescing), but that refactoring has not been performed
yet.</p></td></tr></table></div><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-hunk-writeback"></a></th></tr><tr><td align="left" valign="top"><p>The <code class="literal">write_back_to_local_log/8</code> function’s goal is to perform
individual hunk writebacks as efficiently as possible, i.e. with as
few file open/write/close operations as possible.  The logic is
tortuous and difficult to debug.  It’s probably correct now, but a
refactoring might be a good idea.</p></td></tr></table></div><div class="section" title="Separate file systems for common log short term and long term"><div class="titlepage"><div><div><h5 class="title"><a id="_separate_file_systems_for_common_log_short_term_and_long_term"></a>Separate file systems for common log short term and long term</h5></div></div></div><p>Another part of the lazy writeback process is to manage the transition
of files from the common log’s “short term” storage area to “long
term” storage.  See <a class="xref" href="#shortterm-and-longterm-storage" title="Short term vs. long term log storage">the section called “Short term vs. long term log storage”</a> for
background; see
<a class="ulink" href="hibari-sysadmin-guide.en.html#high-io-rate-devices" target="_top">Hibari Sysadmin
Guide, "High I/O rate devices (e.g. SSD) may be used" section</a> for a
discussion of using high-speed non-volatile storage such as
solid-state memory disks.</p><p>If SSD or similar disk is used, then a file system for that disk
should be mounted under the common log’s short term directory:
<code class="literal">.../var/data/hlog.commonLogServer/s</code>.  The
<code class="literal">do_bigblob_hunk_writeback/3</code> function, together with
<code class="literal">clean_old_seqnums/2</code>, will take care of copying the <code class="literal">?LOGTYPE_BLOB</code>
hunks from the short term file system to the long term file system,
which (we assume) will use traditional, cheap Winchester-type disk drives.</p></div><div class="section" title="Scavenger"><div class="titlepage"><div><div><h5 class="title"><a id="_scavenger"></a>Scavenger</h5></div></div></div><p>See also: <a class="xref" href="#scavenger-and-code-reuse" title="Scavenger and code reuse">the section called “Scavenger and code reuse”</a>.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-scav-mapreduce"></a></th></tr><tr><td align="left" valign="top"><p>The scavenger presents another refactoring opportunity.  An earlier
version was much simpler, but it relied too heavily on in-memory
sorting and consumed too much memory when scavenging systems
containing tens of millions of keys.</p><p>The current implementation is quite brute-force now.  Perhaps a more
explicitly map-reduce style, while still preserving disk-based
sorting, would be useful?</p></td></tr></table></div></div><div class="section" title="Brick registration"><div class="titlepage"><div><div><h5 class="title"><a id="_brick_registration"></a>Brick registration</h5></div></div></div><p>When the scavenger copies a <code class="literal">?LOGTYPE_BLOB</code> hunk to its new storage
location, the brick that owns that value blob must be notified of its
new location.  A brick that isn’t running &amp; in <code class="literal">ok</code> state cannot (by
definition) handle such notifications.  If all logical bricks are not
running, the scavenger should be aborted.</p><p>The <code class="literal">register_local_brick/2</code> function is used by a brick’s startup to
assist the common log keep track of all logical bricks that may have
records stored in the common log.  If a registered brick is not
running when the scavenger starts, the scavenger will be aborted.
Brick failures during the scavenger’s run are handled separately.</p></div><div class="section" title="Processes created by gmt_hlog_common.erl"><div class="titlepage"><div><div><h5 class="title"><a id="gmt-hlog-common-erl-processes"></a>Processes created by gmt_hlog_common.erl</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A <code class="literal">gmt_hlog</code> "gen-server" process to handle I/O to and from the
  "common log".
</li><li class="listitem">
The scavenger is run in a separate process that may run for 0
  seconds to a few hours.
</li><li class="listitem">
Short-lived processes to handle fsync requests.
</li><li class="listitem">
Short-lived processes to perform tasks that were deferred until
  after the <code class="literal">brick_dirty_buffer_wait</code> time interval has passed.
</li><li class="listitem">
A short-lived process to avoid blocking the OTP supervisor framework
  when shutting down the <code class="literal">gdss</code> application in certain MD5 checksum
  failure scenarios.
</li></ul></div></div></div><div class="section" title="gmt_hlog_local.erl"><div class="titlepage"><div><div><h4 class="title"><a id="gmt-hlog-local-erl"></a>gmt_hlog_local.erl</h4></div></div></div><p>The <code class="literal">gmt_hlog_local.erl</code> module’s purpose is to present the same
client API as <code class="literal">gmt_hlog.erl</code> while providing the "common log"/"private
log" split that is described in the
<a class="ulink" href="hibari-sysadmin-guide.en.html#write-ahead-logs-in-hibari" target="_top">Hibari Sysadmin
Guide, "Write-ahead logs in the Hibari application" section</a>.</p><p>This module uses atoms for mapping to hunk metadata types:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">metadata</code> → <code class="literal">?LOGTYPE_METADATA</code>
</li><li class="listitem">
<code class="literal">bigblob</code> → <code class="literal">?LOGTYPE_BLOB</code>
</li></ul></div><p>The most important thing this module does is maintain the
<code class="literal">{FileNum,Offset}</code> storage locations for the private log.  This task
is done with some knowledge of the internal workings of
<code class="literal">gmt_hlog.erl</code>:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Use <code class="literal">gmt_hlog:create_hunk/3</code> to create a fully-serialized hunk.
</li><li class="listitem">
Wrap the serialized hunk in a <code class="literal">{eee,...}</code> tuple and write it to the
   common log.
</li><li class="listitem">
If the common log write was successful, return a reply to the client
   using the <code class="literal">{FileNum,Offset}</code> maintained for the private log, <span class="strong"><strong>not</strong></span>
   the storage location given by the common log.
</li><li class="listitem">
Sometime in the near future, the common log will
   lazily/asynchronously locate all of the recently-written <code class="literal">{eee,...}</code>
   tuples for this brick and copy the serialized hunks to the exact
   storage locations specified by step #3.
</li></ol></div><div class="important" title="Important" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Important"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Important]" src="images/icons/important.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>Step #4 in the outline above has a huge race vulnerability
window.  Any test that tries to write a hunk using
<code class="literal">gmt_hlog_local.erl</code> and then immediately read that hunk will almost
certainly fail.  If you must read something that was very recently
written, you must call <code class="literal">gmt_hlog_common:full_writeback/1</code> before
attempting the read.</p></td></tr></table></div><div class="section" title="Processes created by gmt_hlog_local.erl"><div class="titlepage"><div><div><h5 class="title"><a id="gmt-hlog-local-erl-processes"></a>Processes created by gmt_hlog_local.erl</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
A <code class="literal">gmt_hlog</code> "gen-server" process to handle I/O to and from the
  brick’s "private log".
</li><li class="listitem">
Very short-lived processes to finish <code class="literal">{get_all_seqnums}</code> and
  <code class="literal">{sync}</code> calls.
</li></ul></div></div></div><div class="section" title="mod_admin.erl"><div class="titlepage"><div><div><h4 class="title"><a id="mod-admin-erl"></a>mod_admin.erl</h4></div></div></div><p>This is the callback module for the <code class="literal">inets</code> application’s HTTP server
for the Admin Server’s HTTP status server at <code class="literal">http://localhost:23080/</code>
(default URL).</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"><a id="refactor-mod-admin"></a></th></tr><tr><td align="left" valign="top"><p>There’s room for refactoring here.  This module was written by a
developer who was relatively new to Erlang and learning as he went
along.  Also, there is a large number of administrative tasks that the
Admin Server’s HTTP service does not yet support,
e.g. changing chain length, adding/removing/reweighting chains.</p></td></tr></table></div></div></div><div class="section" title="10.4.&#xA0;Debugging Hibari (clients and servers) using tracing"><div class="titlepage"><div><div><h3 class="title"><a id="debugging-hibari-using-tracing"></a>10.4. Debugging Hibari (clients and servers) using tracing</h3></div></div></div><p>Sooner or later, a Hibari developer will need to do some debugging.
It may be a learning exercise, trying to figure out what existing code
is doing.  Or perhaps it’s new code that needs debugging.  In either
case, there are several sets of tools available to Erlang developers.</p><p>The OTP "debugger" application is useful because it provides a GUI
that many developers find comfortable, particularly the "breakpoint"
feature.  However, "debugger" app doesn’t always work very well with
Hibari, especially on the server side.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
With the large amount of inter-process messaging, it can be
  difficult to identify which modules should be loaded into the
  debugger and where breakpoints should be added.
</li><li class="listitem">
Once a breakpoint is set, multiple processes (e.g. multiple bricks)
  may trigger it, but you are only interested in one specific process.
</li><li class="listitem">
Most of the inter-process messaging uses timeouts on the client
  side.  It’s unlikely that a developer can point-and-click the "Step"
  and "Continue" buttons on the GUI quickly enough to allow a server
  to respond before the client side stub code times out.
</li><li class="listitem">
When a logical brick or write-ahead log server process is stopped by
  a breakpoint, the Admin Server may interpret the break as a
  failure … and then take actions to kill and restart that brick.
</li></ul></div><p>Therefore, we recommend that you use tracing-based tools for debugging
Hibari.  These tools do not require a GUI, so it’s possible to use
them for diagnosing remote systems where a GUI may be impossible to
support.  Also, the tracing tools give much finer control over what
process (or processes) will be traced.</p><div class="section" title="External applications/tools"><div class="titlepage"><div><div><h4 class="title"><a id="_external_applications_tools"></a>External applications/tools</h4></div></div></div><p>The Erlang/OTP runtime system provides an extremely powerful set of
tracing tools.  See the
<a class="ulink" href="http://www.erlang.org/doc/" target="_top">Erlang/OTP documentation</a> in the
"Tools" section for several applications that are built on top of
Erlang’s tracing primitives: "dbg" (in the "runtime_tools"
subsection), "observer", "inviso", and others.</p><p>Gemini has had very positive experience with the "redbug"
application.  "Redbug" is bundled with the commercial packaging of
Hibari and is used frequently by both customer operations staff and
Gemini field engineers to diagnose problems with both Hibari client
applications and the Hibari server.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
The "redbug" tool is part of the
<a class="ulink" href="http://code.google.com/p/eper/" target="_top">"eper" tool suite at Google Code:
<a class="ulink" href="http://code.google.com/p/eper/" target="_top">http://code.google.com/p/eper/</a></a>.
</li></ul></div></div><div class="section" title="Hibari internal tracepoints"><div class="titlepage"><div><div><h4 class="title"><a id="_hibari_internal_tracepoints"></a>Hibari internal tracepoints</h4></div></div></div><p>The Hibari source code has been annotated with over 400 tracepoints
using macros based on the <code class="literal">gmt_elog.erl</code> and <code class="literal">gmt_elog_policy.erl</code>
modules.  These tracepoints give the developer (and even field support
staff) more options for tracing events through Hibari’s code.</p><p>The <code class="literal">gmt_elog</code> tracepoints are designed to be extremely lightweight.
While they can be disabled completely at compile-time, their overhead
is so low that they can remain in production code and be enabled only
when needed for debugging.</p><p>For example, on an x86 laptop with the CPU frequency fixed at 1.33GHz,
a microbenchmark that called a <code class="literal">gmt_elog_policy</code> tracepoint when
system tracing was disabled (i.e. normal system state) executed
88999000 trace calls in 12.925467 seconds, averaging 6.886 million
calls/second.</p><div class="section" title="Major tracepoint types"><div class="titlepage"><div><div><h5 class="title"><a id="_major_tracepoint_types"></a>Major tracepoint types</h5></div></div></div><p>There are two major types of tracepoints that annotate the Hibari
code.  The macros for both types are defined in the <code class="literal">brick.hrl</code> header
file.  The underlying mechanism is provided by macros in the
<code class="literal">gmt_elog.hrl</code> header file.</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
The <code class="literal">?E_</code>* macros, e.g. <code class="literal">?E_INFO/2</code>, <code class="literal">?E_ERROR/2</code>.  These macros are
  similar in spirit to the C library’s <code class="literal">syslog(3)</code> function: free-form
  message text (with formatting by <code class="literal">io_lib:format/2</code>) with a severity
  level.
</p><p class="simpara">These macros actually perform two functions: generate an
application log event via <code class="literal">error_logger</code> and optionally generate a
<code class="literal">gmt_elog</code> trace message.  When examining large traces, it proved
<span class="emphasis"><em>extremely inconvenient</em></span> to try to merge application log messages into
the flow of trace output … so now the macros perform that merging
task automatically.</p></li><li class="listitem"><p class="simpara">
For trace events that do not merit an application log entry using
  <code class="literal">error_logger</code>, the <code class="literal">?DBG_</code>* macros provide a convenient way to
  specify:
</p><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem">
A general category (for trace filtering)
</li><li class="listitem"><p class="simpara">
One of:
</p><div class="itemizedlist"><ul class="itemizedlist" type="square"><li class="listitem">
A generic Erlang term (usually a tuple)
</li><li class="listitem">
<code class="literal">io_lib:format/2</code> style formatted text
</li></ul></div></li></ul></div></li></ul></div><p title="?E_INFO/2 macro&#x2019;s definition:"><b><code class="literal">?E_INFO/2</code> macro’s definition: </b>
</p><pre class="screen">-define(E_INFO(Fmt, Args),
        begin ?ELOG_INFO_C(?CAT_GENERAL, Fmt, Args),
              error_logger:info_msg(Fmt, Args)
        end).</pre><p title="?E_INFO/2 macro&#x2019;s definition:">
</p><p>The <code class="literal">?DBG_</code>* macros use the following filtering categories.  The
categories use integers with C-style bit masks to allow a single trace
message to use multiple categories by bit-wise AND’ing the categories
together.</p><p title="?DBG_* categories from brick.hrl"><b><code class="literal">?DBG_</code>* categories from <code class="literal">brick.hrl</code>. </b>
</p><pre class="screen">%% Any component
-define(CAT_GENERAL,              (1 bsl  0)). % General: init, terminate, ...

%% brick_ets, mostly, except where there's cross-over purpose.
-define(CAT_OP,                   (1 bsl  1)). % Op processing
-define(CAT_ETS,                  (1 bsl  2)). % ETS table
-define(CAT_TLOG,                 (1 bsl  3)). % Txn log
-define(CAT_REPAIR,               (1 bsl  4)). % Repair

%% brick_server, mostly, except where there's cross-over purpose.
-define(CAT_CHAIN,                (1 bsl  5)). % Chain-related
-define(CAT_MIGRATE,              (1 bsl  6)). % Migration-related
-define(CAT_HASH,                 (1 bsl  7)). % Hash-related</pre><p title="?DBG_* categories from brick.hrl">
</p><p>Here are a couple of examples of using these macros.</p><p title="Sample usage of ?E_INFO and ?DBG_ETSx/2"><b>Sample usage of <code class="literal">?E_INFO</code> and <code class="literal">?DBG_ETSx/2</code>. </b>
</p><pre class="screen">?E_INFO("~s: got unknown message ~P\n", [?MODULE, Msg, 20]).

%% Example of ?DBG_ETSx()
?DBG_ETSx({inserted, S#state.tab, Key, size(Val)}).</pre><p title="Sample usage of ?E_INFO and ?DBG_ETSx/2">
</p><p>In the end, the result of both these macros is a call to
<code class="literal">gmt_elog_policy:enabled/6</code>.  By default, this function does not do
anything.  For lowest overhead, it should do nothing.  It doesn’t
<span class="strong"><strong>need</strong></span> to do anything, because the Erlang tracing mechanism will do
what we need if and when we need to activate the tracing.</p><p title="The gmt_elog_policy:enabled/6 function"><b>The <code class="literal">gmt_elog_policy:enabled/6</code> function. </b>
</p><pre class="screen">enabled(_Priority, _Category, _Module, _Line, _Fmt, _ArgList) -&gt;
    false.</pre><p title="The gmt_elog_policy:enabled/6 function">
</p><p>When enabled, the Erlang VM’s tracing mechanism will tell us the
module name, function name, and arguments of any function call that
meets its match specification.  When tracing is not enabled, almost no
computation is performed.</p><p>The arguments for the <code class="literal">enabled/6</code> function are usually generated by
macros for convenience.  The arguments are:</p><div class="variablelist"><dl><dt><span class="term">
Priority, <code class="literal">term()</code>
</span></dt><dd>
The Hibari app macros use an integer for this
argument, using <code class="literal">syslog(3)</code>-like priority numbers (which are defined
in <code class="literal">gmt_applog.hrl</code>, e.g. <code class="literal">?LOG_EMERG_PRI</code> is level 0, <code class="literal">?LOG_INFO_PRI</code>
is level 6.
</dd><dt><span class="term">
Category, <code class="literal">term()</code>
</span></dt><dd>
The Hibari app macros use an integer for this argument, using the
bitmask-style encoding shown above, e.g. <code class="literal">?CAT_ETS</code> → <code class="literal">(1 bsl 2)</code>.
</dd><dt><span class="term">
Module, <code class="literal">atom()</code>
</span></dt><dd>
This is the name of the module that is making the tracing call.
</dd><dt><span class="term">
Line, <code class="literal">integer()</code>
</span></dt><dd>
This is the line number of the source module that is making the
tracing call.
</dd><dt><span class="term">
Fmt, <code class="literal">string()</code>
</span></dt><dd>
An <code class="literal">io_lib:format/2</code> formatting string.
</dd><dt><span class="term">
ArgList, <code class="literal">string()</code>
</span></dt><dd><p class="simpara">
An <code class="literal">io_lib:format/2</code> formatting argument list.
</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The <code class="literal">Fmt</code> and <code class="literal">ArgList</code> arguments are used for the <code class="literal">?DBG_</code>*
style macros, because arguments are used by the log trace formatting
functions to do the actual log trace formatting.</p></td></tr></table></div></dd></dl></div></div><div class="section" title="Trace collection and formatting"><div class="titlepage"><div><div><h5 class="title"><a id="_trace_collection_and_formatting"></a>Trace collection and formatting</h5></div></div></div><p>The <code class="literal">gmt_elog:help/0</code> function provides a quick reference for how to
use the <code class="literal">gmt_elog</code> tracing functions.</p><p title="Example of gmt_elog:help/0 usage."><b>Example of <code class="literal">gmt_elog:help/0</code> usage. </b>
</p><pre class="screen">(hibari_dev@bb3)56&gt; gmt_elog:help().
  gmt_elog:start_tracing().
  gmt_elog:start_tracing("/path/to/trace-file").
  gmt_elog:add_match_spec().         ... to trace everything
  gmt_elog:add_match_spec(dbg:fun2ms(fun([_, target_category, _, _, _, _]) -&gt; return_trace() end)).
  gmt_elog:add_match_spec(dbg:fun2ms(fun([Pri, _, _, _, _, _]) when Prio &gt; 0 -&gt; return_trace() end)).
  gmt_elog:add_match_spec(dbg:fun2ms(fun([_, target_category, target_module, _, _, _]) -&gt; return_trace();
                                        ([_, _, other_module, 88, _, _]) -&gt; return_trace() end)).
  gmt_elog:del_match_spec().
  gmt_elog:stop_tracing().
  gmt_elog:format_file("/path/to/trace-file").
  gmt_elog:format_file("/path/to/trace-file", "/path/to/output").
  gmt_elog:format_file("/path/to/trace-file", "/path/to/output", MatchStr|"").
ok</pre><p title="Example of gmt_elog:help/0 usage.">
</p><p>When we enable tracing, we’re actually tracing calls to the
<code class="literal">gmt_elog_policy:enabled/6</code> function.  As with any tracing match
specification, we can be as general (using <code class="literal">'_'</code> wildcards) or as
specific as we wish in filtering trace events.</p><p>For the examples of <code class="literal">add_match_spec</code> shown above, here is an explanation</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem">
Trace everything, i.e. all calls to <code class="literal">gmt_elog_policy:enabled/6</code>.
</li><li class="listitem">
Trace anything where the <code class="literal">Category</code> arg == <code class="literal">target_category</code>.
   Remember that the Hibari app uses integers, not atoms, for the
   <code class="literal">Category</code> arg, so use an integer here line <code class="literal">8</code> for (1 bsl 3) for
   the <code class="literal">?CAT_TLOG</code> category.
</li><li class="listitem">
Trace anything where the <code class="literal">Prio</code> argument &gt; 0, i.e. everything that
   isn’t emergency priority, <code class="literal">?LOG_EMERG_PRI</code>.
</li><li class="listitem"><p class="simpara">
Trace anything where either of the following conditions is true:
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">Category == target_category</code> and <code class="literal">Module == target_module</code>
</li><li class="listitem">
<code class="literal">Module == other_module</code> and <code class="literal">Line == 88</code>
</li></ul></div></li></ol></div><p title="Outline of a typical tracing session"><b>Outline of a typical tracing session. </b>
</p><pre class="screen">&gt; gmt_elog:start_tracing("/tmp/trace-file1").
&gt; gmt_elog:add_match_spec(dbg:fun2ms(fun([_, Cat, _, _, _, _]) when Cat == 1 -&gt; return_trace() end)).
&gt; %% ... trigger some activity that you wish to trace
&gt; %% ... when you are finished, resume with:
&gt; gmt_elog:del_match_spec().
&gt; gmt_elog:stop_tracing().
&gt; gmt_elog:format_file("/tmp/trace-file1", "/tmp/trace-file1.out").</pre><p title="Outline of a typical tracing session">
</p><p>If you have a low volume of trace messages, it may be convenient to
use <code class="literal">gmt_elog:start_tracing/0</code> to send those messages to the shell
window instead of to a file.</p></div><div class="section" title="For more information about tracing"><div class="titlepage"><div><div><h5 class="title"><a id="_for_more_information_about_tracing"></a>For more information about tracing</h5></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
See the EDoc documentation for the <code class="literal">gmt_elog</code> module for detailed
  information on how to use all the tracing functions in that module.
</li><li class="listitem">
See the
  <a class="ulink" href="http://www.erlang.org/doc/man/dbg.html#fun2ms-1" target="_top">Erlang/OTP
  documentation for the <code class="literal">dbg:fun2ms/1</code> function</a> for an overview of
  the (usually) simpler method of creating a match specification.
</li><li class="listitem">
See the
  <a class="ulink" href="http://www.erlang.org/doc/apps/erts/match_spec.html" target="_top">Erlang/OTP
  documentation "Match specifications in Erlang"</a> for a detailed
  reference of match specifications.
</li></ul></div></div></div></div></div><div class="section" title="11.&#xA0;Appendix: Troubleshooting"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_appendix_troubleshooting"></a>11. Appendix: Troubleshooting</h2></div></div></div><p>The subsections here are an assortment of items that were inconvenient
to add in-line elsewhere in this guide.  Like Erlang’s "let it crash"
philosophy, it’s a bit tidier to let something else handle
exceptions.  This section is the "something else".</p><div class="section" title="11.1.&#xA0;Problem: Cannot run multiple Hibari apps on the same physical machine"><div class="titlepage"><div><div><h3 class="title"><a id="problem-multiple-hibari-apps"></a>11.1. Problem: Cannot run multiple Hibari apps on the same physical machine</h3></div></div></div><p>Although it is possible to run the Hibari app multiple times
simultaneously on the same physical machine (or guest OS instance, if
you’re using virtualization software such as VMware or Xen), it isn’t
always easy.  There are two reasons why Hibari might not be able to
run on a machine:</p><div class="section" title="Multiple Erlang VMs with the same node name"><div class="titlepage"><div><div><h4 class="title"><a id="_multiple_erlang_vms_with_the_same_node_name"></a>Multiple Erlang VMs with the same node name</h4></div></div></div><p>Erlang node names take the form <code class="literal">VM_Name@Host_Name</code>, using the "short"
host naming convention, via "erl -sname VM_Name@Host_Name".  It is not
possible to run two Erlang virtual machines with the same "VM_Name".</p><p title="Example of Erlang node name conflict: duplicate_name"><b>Example of Erlang node name conflict: <code class="literal">duplicate_name</code>. </b>
</p><pre class="screen">{error_logger,{{2010,4,14},{19,41,28}},"Protocol: ~p: register error: ~p~n",["inet_tcp",{{badmatch,{error,duplicate_name}},
[{inet_tcp_dist,listen,1},{net_kernel,start_protos,4},{net_kernel,start_protos,3},{net_kernel,init_node,2},
{net_kernel,init,1},{gen_server,init_it,6},{proc_lib,init_p_do_apply,3}]}]}</pre><p title="Example of Erlang node name conflict: duplicate_name">
</p><p><span class="strong"><strong>If run in developer’s interactive mode</strong></span>,
(e.g. <a class="xref" href="#starting-hibari-1st-time" title="3.3.&#xA0;Starting Hibari for the first time">Section 3.3, “Starting Hibari for the first time”</a>), the node name is defined in
<code class="literal">gdss/src/Makefile</code>.  Edit the <code class="literal">NODENAME1</code> variable in <code class="literal">Makefile</code>, then
re-run your <code class="literal">make</code> command.</p><p><span class="strong"><strong>If run as a daemon</strong></span>,
the Erlang node name is taken from the <code class="literal">central.conf</code>
file, the <code class="literal">application_nodename</code> attribute.  Running multiple
instances of Hibari using the same installation directory will use the
same <code class="literal">central.conf</code> file.  The work-around is to install Hibari
multiple times, one for each Erlang VM instance.  Each installation
will require a different installation prefix,
e.g. <code class="literal">/usr/local/hibari1</code> and <code class="literal">/usr/local/hibari2</code>.  Then the
<code class="literal">application_nodename</code> attribute in each <code class="literal">central.conf</code> file can
contain a unique value.</p><div class="note" title="Note" style="margin-left: 0; margin-right: 10%;"><table border="0" summary="Note"><tr><td rowspan="2" align="center" valign="top" width="25"><img alt="[Note]" src="images/icons/note.png" /></td><th align="left"></th></tr><tr><td align="left" valign="top"><p>The multiple-installation path technique above is not sufficient
for running multiple Hibari daemons/virtual machines on the same box.
See also <a class="xref" href="#multiple-hibari-instances-TCP-conflicts" title="Multiple Hibari instances have TCP port conflicts">the section called “Multiple Hibari instances have TCP port conflicts”</a>.</p></td></tr></table></div></div><div class="section" title="Multiple Hibari instances have TCP port conflicts"><div class="titlepage"><div><div><h4 class="title"><a id="multiple-hibari-instances-TCP-conflicts"></a>Multiple Hibari instances have TCP port conflicts</h4></div></div></div><p title="TCP port conflict: eaddrinuse (with Admin Server HTTP Web server on TCP port 23080)"><b>TCP port conflict: <code class="literal">eaddrinuse</code> (with Admin Server HTTP Web server on TCP port 23080). </b>
</p><pre class="screen">=GMT ERR REPORT==== 14-Apr-2010::19:43:19 ===
std_error: "Failed initiating web server: \nundefined\n{{listen,eaddrinuse},\n {child,undefined,\n        {httpd_acceptor,any,23080},\n....</pre><p title="TCP port conflict: eaddrinuse (with Admin Server HTTP Web server on TCP port 23080)">
</p><p>The error message below may be hidden among other app log messages,
both related to startup as well as the premature shutdown.</p><p>Using a utility like <code class="literal">grep</code> in the <code class="literal">brick.log</code> file (interactive mode)
or <code class="literal">.../var/log/gdss-app.log</code> file (daemon mode) might be more
helpful.  Look for the pattern <code class="literal">eaddrinuse</code>.</p><p>Port conflicts can exist for a number of TCP ports used by Hibari:</p><div class="variablelist"><dl><dt><span class="term">
The Admin HTTP server
</span></dt><dd><p class="simpara">
Configured by an Erlang/OTP configuration file
(and not <code class="literal">central.conf</code>)
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
In developer interactive mode, see the file
<code class="literal">./root/conf/admin.conf</code>, relative to your current working dir
(i.e. the <code class="literal">gdss/src</code> subdirectory).
</li><li class="listitem">
In daemon mode, see <code class="literal">/path/to/hibari-top/gdss/1.0.0/etc/root/conf/admin.conf</code>
</li><li class="listitem">
In either situation above, edit the "Port" line at the top of the file.
</li></ul></div></dd><dt><span class="term">
Other TCP ports
</span></dt><dd><p class="simpara">
Configured by the <code class="literal">central.conf</code> file.
</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
In developer interactive mode, see <code class="literal">../priv/central.conf</code>.
</li><li class="listitem">
In daemon mode, see <code class="literal">/path/to/hibari-top/gdss/1.0.0/etc/central.conf</code>
</li><li class="listitem">
In either situation above, edit the appropriate attribute, e.g.
  <code class="literal">cli_port</code>, <code class="literal">brick_s3_tcp_port</code>, <code class="literal">gdss_ebf_tcp_port</code>, and so on.
</li></ul></div></dd></dl></div></div></div></div><div class="section" title="12.&#xA0;Appendix: Known Warts, Problems, Inefficiencies, Refactoring Opportunities, etc."><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a id="_appendix_known_warts_problems_inefficiencies_refactoring_opportunities_etc"></a>12. Appendix: Known Warts, Problems, Inefficiencies, Refactoring Opportunities, etc.</h2></div></div></div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
Hibari does not yet have a comprehensive backup &amp; restore mechanism,
  in the sense of "dump all contents of the entire cluster to this
  file/files" and "load this file/files back into the cluster".
</li><li class="listitem">
There’s probably room for substantial improvement by refactoring
  the "syncpid" with a new algorithm (see <a class="xref" href="#the-syncpid" title="The syncpid: How it works, room for improvement">the section called “The syncpid: How it works, room for improvement”</a>).
  I suspect that when under high load,
  switching to a fixed time interval would provide better throughput
  with similar latencies.  The problem is determining when to switch
  from one algorithm or another, or when change the size of this fixed
  time interval.
</li><li class="listitem">
The Admin Server needs refactoring for scalability, see
  <a class="link" href="#refactor-admin-monitor" title="Note">"An increase in the size…"</a>
<a class="xref" href="#refactor-admin-monitor" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-brick-bp" title="Note">suggestions for <code class="literal">brick_bp.erl</code></a>
<a class="xref" href="#refactor-brick-bp" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-brick-chainmon" title="Note">suggestions for <code class="literal">brick_chainmon.erl</code></a>
<a class="xref" href="#refactor-brick-chainmon" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-brick-ets" title="Note">suggestions for <code class="literal">brick_ets.erl</code></a>
<a class="xref" href="#refactor-brick-ets" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-brick-ets-state" title="Note">suggestions for the
  <code class="literal">#state</code> record in <code class="literal">brick_ets.erl</code></a>
<a class="xref" href="#refactor-brick-ets-state" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-blob-reading" title="Note">suggestions for blob reading</a>
<a class="xref" href="#refactor-blob-reading" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-scavenger" title="Note">suggestions for the scavenger</a>
<a class="xref" href="#refactor-scavenger" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-scavenger" title="Note">suggestions for the <code class="literal">brick_pingee.erl</code></a>
<a class="xref" href="#refactor-scavenger" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-scoreboard" title="Note">suggestions for the <code class="literal">brick_sb.erl</code></a>
<a class="xref" href="#refactor-scoreboard" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-logging-op-q" title="Note">suggestion the <code class="literal">logging_op_q</code>
  mess shared by <code class="literal">brick_ets.erl</code> and <code class="literal">brick_server.erl</code></a>
<a class="xref" href="#refactor-logging-op-q" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-role-management" title="Note">suggestions for chain role
  manipulations</a>
<a class="xref" href="#refactor-role-management" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-wal" title="Note">suggestions for the write-ahead log</a>
<a class="xref" href="#refactor-wal" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-brick-simple" title="Note">suggestions for <code class="literal">brick_simple.erl</code></a>
<a class="xref" href="#refactor-brick-simple" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-brick-squorum" title="Note">suggestions for <code class="literal">brick_squorum.erl</code></a>
<a class="xref" href="#refactor-brick-squorum" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-my-pread" title="Note">suggestions for the read-ahead
  scheme in <code class="literal">gmt_hlog.erl</code></a>
<a class="xref" href="#refactor-my-pread" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-gmt-hlog" title="Note">suggestions for the public API of
  <code class="literal">gmt_hlog.erl</code></a>
<a class="xref" href="#refactor-gmt-hlog" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-os-sync" title="Important">suggestions for OS-specific file
  flushing operations</a>
<a class="xref" href="#refactor-os-sync" title="Important">Important</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-hunk-writeback" title="Note">suggestions for the
  <code class="literal">write_back_to_local_log/8</code> function</a>
<a class="xref" href="#refactor-hunk-writeback" title="Note">Note</a>.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-scav-mapreduce" title="Note">suggestions for the
  scavenger to be more explicitly map-reduce style</a>
<a class="xref" href="#refactor-scav-mapreduce" title="Note">Note</a>.
</li><li class="listitem">
Admin Server API isn’t fully exposed via HTTP status server, mostly
  due to lack of vision/definition of what it ought to do and look
  like.
</li><li class="listitem">
Refactoring <a class="link" href="#refactor-mod-admin" title="Note">suggestions for the public API of
  <code class="literal">mod_admin.erl</code></a>
<a class="xref" href="#refactor-mod-admin" title="Note">Note</a>.
</li><li class="listitem">
Enhance <code class="literal">brick_admin:get_table_chain_list/{1,2}</code> get the current
  operational chain list, not the healthy chain list.
</li><li class="listitem">
The EDoc for <code class="literal">brick_server:start_scavenger/3</code> for API options
  proplist for the scavenger.  However, that function should be
  removed, because almost all scavenger code from <code class="literal">brick_server.erl</code>
  has been moved over to <code class="literal">gmt_hlog_common.erl</code>.  This inconsistency
  should be fixed.
</li></ul></div></div></div></body></html>
